= 编译器
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 6
:homepage: http://orientye.com
<<<

== 概览

=== 概念
• 用途

    编程语言
    DSL(domain specific language): 例如SQL, Google Protocol Buffers等
    https://en.wikipedia.org/wiki/Domain-specific_language

• 主要数据结构

    Tokens
    The Syntax Tree, Abstract Syntax Tree(AST)
    The Symbol Table: 标识符，变量，函数等
    The Literal Table: 常量，字符串等
    Intermediate Code
    Temporary Files

• 符号表(symbol table)

    符号表是一种供编译器保存有关源程序构造的各种信息的数据结构。
    通常由语法分析器来创建，有些情况下词法分析器在碰到组成一个词素的字符串时也可以立即建立一个符号表条目。

• 自举(bootstraping)

    编译器用自身语言编写(self-compiling)，这是语言迈向成熟的标志。
    当然，在起始阶段，通常还是要借助别的语言来编写。
    https://en.wikipedia.org/wiki/Bootstrapping_(compilers)

• JIT(即时编译)与AOT(提前编译)

    https://www.quora.com/What-is-the-difference-between-JIT-compiler-and-AOT-compiler

• 动态类型与静态类型

    动态类型运行时检查
    静态类型编译期检查

• 引用计数与GC

    引用计数实现比较简单，Perl、PHP、Python一开始都是使用的引用计数；
    但引用计数缺乏全局对象图信息，处理循环引用等情况比较麻烦，需要引入类似"弱引用"等方法来解决。

• argument与parameter

    argument: 实际参数
    parameter: 形式参数

• 闭包

    inner()访问了外部函数中声明的局部变量

• Lambda与匿名函数

    主要是为了方便(真的吗? 例如捕获?)

• 类与原型

    类更简洁明晰，对用户更友好
    原型(例如javascript)更灵活，强大

• REPL

    read–eval–print loop
    https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop

• 虚拟机

    基于堆栈，例如JVM
    基于寄存器(不一定是真正的物理寄存器)，例如Lua

== 词法分析

=== 概念与作用
▪ 词法分析(lexical analysis)也称扫描(scanning)

▪ 词法分析将输入的程序按照构词规则分解成一系列token(词法单元)符号，即字符流->记号流

▪ token通常分为以下类型

    (1) 关键字 是由程序语言定义的具有固定意义的标识符
        从词法分析的角度看，关键字是标识符的一部分
    (2) 标识符 用来表示各种名字，如变量名、函数名等
    (3) 常数 常数的类型一般有整型、实型、布尔型、字符串类型等
    (4) 运算符 如+、-、*、/等
    (5) 界符 如逗号、分号、括号等

▪ 输出
通常表示为二元式列表：[<token-name, attribute-value>]

▪ 词法分析是编译过程中的一个阶段，可以在语法分析前进行独自作为一遍，也可以和语法分析结合在一起作为一遍。

=== 手工构造与自动构造
- 手工构造词法分析器

    特点:
        复杂且容易出错
        灵活可控
            例如GCC, LLVM等
    思想: 状态转换与有限自动机(FA)

- 自动生成词法分析器

    特点:
        快速实现，代码量少
        难以控制细节
    思想: 将正则表达式转换成NFA，然后把NFA转换成DFA

=== 词法单元的识别
状态转换图(transition diagram)
保留字和标识符的识别
基于状态转换图的词法分析器的结构

=== 正则表达式
==== 概念
正则表达式(regular expression)是一种用来描述词素模式的重要表示方法。
虽然正则表达式不能表达出所有可能的模式，但是可以高效地描述在处理词法单元时要用到的模式类型。

如果M和N是正则表达式，则以下也是正则表达式:
(1) 选择: M | N = {M, N} 可能属于M也可能属于N，但只能是其中之一
(2) 连接: MN = {mn | m ∈ M, n ∈ N} 既属于M，也属于N
(3) 闭包: M* = {ε, M, MM, MMM, ...} (Kleene闭包)
闭包分Kleene闭包和正闭包。Kleene闭包是指某一集合的符号重复0～∞多次，可能是空串；正闭包不包含重复0次，即不包含空串。

其它正则表达式可以看作是基本规则的某种语法糖:
例如a?表示零个或一个a, 可以表示为ε|a

==== 用法
https://github.com/cdoco/learn-regex-zh
https://en.wikipedia.org/wiki/Regular_expression

==== 示例
• 保留字(reserved)

    reserved = if|while|do|...

• 标识符(identifier)

    letter = [a-zA-Z]
    digit = [0-9]
    identifier = letter(letter|digit)*

• 数字(number)

    nat = [0-9]+
    signedNat = (+|-)? nat
    number = signedNat("." nat)?(E signedNat)?

• 注释(comment)

    词法分析会忽略注释，但需要识别注释。

    单个界符(delimiter)的注释用正则表达式比较简单，例如:
        {this is a Pascal commment} 其正则表达式: {(~})*}
        -- this is Ada comment 其正则表达式: --(~newline)*
    多个界符的则困难些，例如:
        /* this is a C commment */
        此时即便用正则表达式写对了，也很难具有好的可读性
        因此这种情况下一般会封装一个函数使用状态机

• Ambiguity, White Space and Lookahead

Q: 正则表达式如何匹配3的倍数？
https://www.zhihu.com/question/24824487

56 行代码用 Python 实现一个 Flex/Lex:
https://zhuanlan.zhihu.com/p/663995549

=== 有限自动机
- FA

    Finite Automaton 有限自动机/有穷自动机

- DFA

    Deterministic Finite Automaton 确定的有穷自动机
    在任何一个状态，基于输入的字符串，都能做一个确定的转换。

    优点: 可以避免回溯问题，运行性能较高
    缺点: 不容易直接设计出来，需要通过一系列方案，基于NFA的转换而得到，并且需要占用额外的空间
    适用情况: 状态较为复杂，或者对时间复杂度要求较为严苛的工业级词法分析器

    Q: 如何用DFA描述identifier, 即identifier = letter(letter|digit)*
    Q: 如何用DFA描述number

- NFA

    Nondeterministic Finite Automaton 非确定的有穷自动机
    存在某些状态，针对某些输入，不能做一个确定的转换。
    可以细分成两种情况:
        对于一个输入，它有两个状态可以转换；
        存在ε转换，也就是没有任何输入的情况下，也可以从一个状态迁移到另一个状态。

    优点: 在设计上更简单直观
    缺点: 无法避免回溯问题，在某些极端的情况下可能会造成编译器运行的性能低下
    适用情况: 状态较为简单，且不存在回溯的场景

- NFA与DFA

    NFA与DFA在表达力上是等价的。任何DFA都是某个NFA的一个特例。

- DFA的实现

    有向图(边和节点可能都带有一些信息)

- 有限自动机与状态转换图

    有穷自动机可以看作是状态转换图的形式化表示。
    与状态转换图不同，有穷自动机既可以在输入字符上执行转换，也可以在空输入上执行转换。

- 自动机与文法

    有限自动机是比较简单的一种自动机，对应于正则文法，也叫做3型文法。
    再强大的是下推自动机，对应于上下文无关文法，也叫做2型文法。
    更强大的是线性有界自动机，对应于上下文相关文法，也叫1型文法。
    图灵机的范围更大，对应0型文法。任何能用产生式写出来的文法规则，都属于0型文法。
    参考: https://en.wikipedia.org/wiki/Chomsky_hierarchy

- 例子
https://zh.wikipedia.org/wiki/%E9%9D%9E%E7%A1%AE%E5%AE%9A%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E8%87%AA%E5%8A%A8%E6%9C%BA#%E4%BE%8B%E5%AD%90

=== 正则表达式与有限自动机
可以将任意一个正则表达式转换为一个大小基本相同的NFA；
任何NFA可以转换为一个代表相同模式的DFA，虽然最坏的情况下自动机的大小会以指数级增长，但在常见的程序设计语言中尚未碰到这些情况。

RE->NFA->DFA:
1 RE->NFA: 使用Thompson构造法构建一个识别该RE的NFA
2 NFA->DFA: 使用子集构造法导出一个能够模拟该NFA的DFA
3 最小化DFA: 使用Hopcroft算法来识别该DFA中等价的状态，来构建一个最小DFA

可以将任意一个NFA或DFA会转化为一个正则表达式。

参考:
https://time.geekbang.org/column/article/137286

=== 词法分析器生成工具

=== 基于DFA的模式匹配器的优化

== 语法分析

=== 概念
- 语法分析(syntax analysis)也称解析(parsing)

- 输出: 语法树(syntax tree)
语法分析是把程序的结构识别出来，并形成一棵便于由计算机处理的抽象语法树。

- 终结符与非终结符
https://en.wikipedia.org/wiki/Terminal_and_nonterminal_symbols

- 上下文无关文法(Context-Free Grammar, CFG)
上下文无关文法就是说这个文法中所有的产生式左边只有一个非终结符。
CFG每个文法规则左边都只有一个非终结符，而右边可以由非终结符和终结符组成，意思是，只要出现左边的非终结符，都可以等价替换成右边的那一串表达式。
CFG规定左边有且只有一个非终结符，意味着这个非终结符出现在哪，前后都有啥并不重要，只要出现它都可以等价替换右边的式子，因此叫做上下文无关。上下文指的是左边这个非终结符的上下文。
如何理解上下文无关文法？
上下文无关的意思是，无论在任何情况下，文法的推导规则都是一样的。
例如，在变量声明语句中可能要用到一个算术表达式来做变量初始化，在其他地方可能也会用到算术表达式。但不管在什么地方，算术表达式的语法都一样，都允许用加法和乘法，计算优先级也不变。
大多数计算机语言，都能用上下文无关文法来表达其语法。
https://www.zhihu.com/question/21833944
https://en.wikipedia.org/wiki/Context-free_grammar

- 上下文有关文法(Context-Sensitive Grammar, CSG)
也是一种形式文法，其中任何产生式规则的左手端和右手端都可以被终结符和非终结符构成的上下文所围绕。
https://en.wikipedia.org/wiki/Context-sensitive_grammar

- PEG文法
解析表达文法(Parsing Expression Grammar, PEG)
因为PEG更加严格更加强大，PEG可以成为很好的正则表达式的替代品。例如，一个正则表达式本身是无法匹配嵌套的括号对，因为正则表达式不是递归的，但是PEG却能做到这点。
许多CFG固有的存在二义性，即使它们原本要描述的东西并不具有二义性。C, C++, Java里面著名的悬空else问题就是一个例子。这个问题通常都是应用文法之外的一个规则解决。而在PEG里面，因为使用了优先权，所以根本不存在这种问题。
https://en.wikipedia.org/wiki/Parsing_expression_grammar
https://leafo.net/guides/parsing-expression-grammars.html
https://www.inf.puc-rio.br/~roberto/docs/peg.pdf
https://www.inf.puc-rio.br/%7Eroberto/docs/ry10-01.pdf
http://cuberl.com/2020/06/08/peg/

- 线性文法(linear grammar)
has at most one nonterminal in the right-hand side of each of its productions.
https://en.wikipedia.org/wiki/Linear_grammar

- 正则文法(regular grammar)
称为3型文法。这种文法分为两种类型: 第一类要求生成式的形式必须是A→ωB或A→ω，其中A，B都是变元，ω是终结符串，也称为右线性文法。第二类正则文法称为左线性文法，它要求生成式必须是A→Bω，或A→ω的形式。

- 逆波兰表达式(Reverse Polish Notation)
去掉括号后表达式无歧义
适合用栈操作运算：遇到数字则入栈；遇到算符则取出栈顶两个数字进行计算，并将结果压入栈中。
https://www.zhihu.com/question/41103160

- 方法分类
处理文法的语法分析器大致可以分为三种类型: 通用型，自顶向下型，自底向上型。
像Cocke-Younger-Kasami算法和Earley算法可以对任意文法进行语法分析，但这些通用方法效率比较低，不能用于编译器产品。
自顶向下(top-down): LL(1)
自底向上(bottom-up): LR(0), SLR(1), LALR(1), LR(1)
https://blog.csdn.net/misskanagi/article/details/29852901
https://softwareengineering.stackexchange.com/questions/19541/what-are-the-main-advantages-and-disadvantages-of-ll-and-lr-parsing

- BNF(Backus-Naur form)与EBNF(Extended BNF)
ε(epsilon)表示没有/空产生式: the empty production rule, matching only the empty string
BNF与EBNF的表达力是一样的，但EBNF更简单些。
https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form#Advantages_over_BNF
https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form
https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form

- Chomsky hierarchy
https://en.wikipedia.org/wiki/Chomsky_hierarchy

=== 上下文无关文法
- 定义
一个上下文无关文法由四个元素组成:
(1) 一个终结符号集合，有时也称为词法单元
(2) 一个非终结符号集合，有时也称为语法变量。每个非终结符号表示一个终结符号串的集合。
(3) 一个产生式集合
(4) 指定一个非终结符号为开始符号

- 例如:
stmt -> if (expr) stmt else stmt
其中:
箭头可以读作"可以具有如下形式"，这样的规则称为产生式(production)；
if和括号这样的词法元素称为终结符号(terminal)；
expr和stmt这样的变量表示终结符号的序列，则称为非终结符号(nonterminal)。

- 两种描述形式:
一种是巴科斯范式(BNF)
一种是巴科斯范式的一种扩展形式(EBNF)，其更利于自动化生成语法分析器。
其中，产生式、终结符、非终结符、开始符号是巴科斯范式的基本组成要素。

- 上下文无关文法与正则文法的区别:
上下文无关文法允许递归调用，而正则文法(regular grammar)不允许
上下文无关文法比正则文法的表达能力更强，正则文法是上下文无关文法的一个子集

- 最左推导与最右推导
最左推导: 每次总是选择最左侧的符号进行替换。

=== 设计文法
- 文法能够描述程序设计语言的大部分(但不是全部)语法
例如，标识符必须先声明后使用，但这个要求不能通过一个上下文无关文法来描述。

- vs. 正则表达式
正则表达式适合用来词法分析/扫描，但它不够强大，无法处理任意深度嵌套的表达式。
任何能够使用正则表达式描述的，都可以使用文法描述。但正则表达式规则更简单和易于理解，同时，将一个语言的语法结构分为词法和非词法两部分更容易将编译器前端块化。
正则文法(regular grammar)是上下文无关文法的一个子集。上下文无关文法允许递归调用，而正则文法不允许。

- 什么是二义性问题？

- 如何解决二义性问题？


=== 自顶向下的语法分析
- 递归下降
对于一个非终结符，要从左到右依次匹配其产生式中的每个项，包括非终结符和终结符。
在匹配产生式右边的非终结符时，要下降一层，继续匹配该非终结符的产生式。
如果一个语法规则有多个可选的产生式，那么只要有一个产生式匹配成功就行。如果一个产生式匹配不成功，那就回退回来，尝试另一个产生式（回退，即回溯）。

- LL语法分析
https://en.wikipedia.org/wiki/LL_parser

- LL(1)文法
LL分析法比较简单，主要思想就是可以向前读入一个(常用的LL(1))词素来决定选择哪个语法推导规则。
LL(1)中的第一个L，是Left-to-right的缩写，代表从左向右处理Token串。第二个L，是Leftmost，即最左推导。最左推导就是它总是先把产生式中最左侧的非终结符展开完毕以后，再去展开下一个。这也就相当于对AST从左子节点开始的深度优先遍历。LL(1)中的1，指的是预读一个Token。

- 优点

    容易手工实现
    解读:
        上级文法嵌套下级文法，上级的算法调用下级。
        表现在生成AST中，上级算法生成上级节点，下级算法生成下级节点。这也正是"下降"的含义。
        递归下降的特点是: 程序结构基本上是跟文法规则同构的，比较直观。

- 缺点

    限制较多
    需要解决左递归问题

- Examples
antlr4
https://en.wikipedia.org/wiki/Top-down_parsing#Examples
Recursive descent parser: https://en.wikipedia.org/wiki/Recursive_descent_parser
Pratt Parsing(也称Top Down Operator Precedence Parsing):
https://en.wikipedia.org/wiki/Operator-precedence_parser#Pratt_parsing

- 参考
https://en.wikipedia.org/wiki/Top-down_parsing

=== LL算法
==== 实现方式
用 LL 算法解析语法的时候，可以选择两种实现方式:
第一种，采用递归下降算法，通过预读能判断出选择哪个产生式。
第二种，采用表驱动的方式: 需要基于计算出来的 First 和 Follow 集合构造一张预测分析表，根据这个表，查找在遇到 Token 应该走哪条路径。

这两种方式是等价的。

LL(1)算法解决的问题是: 如何通过只向前看1个词法单元来唯一确定与当前句子匹配的产生式。
LL(1)算法对于文法的要求是: 在向前看1一个词法单元下无推导二义性。

==== 左递归问题
- 什么是左递归问题

    multiplicativeExpression
        :   IntLiteral
        |   multiplicativeExpression Star IntLiteral
        ;
    https://en.wikipedia.org/wiki/Left_recursion

- 解决: 转化为循环

    左递归可以通过改写语法规则来避免，
    而改写后的语法又可以表达成简洁的EBNF格式，从而说明可以使用循环代替右递归。

    multiplicativeExpression
        :   IntLiteral
        |   IntLiteral Star multiplicativeExpression
        ;

==== 回溯问题
解决: 预读后续的一个Token，判断该选择哪个产生式

==== First集合
- 目的

- 计算

- 注意事项
尽量抽取左公因子，这样可以避免 First 集合产生交集。

==== Follow集合
- 目的

- 计算

==== First与Follow的运用

==== 参考
https://zhuanlan.zhihu.com/p/675095121

=== 自底向上的语法分析
- vs. 自顶向下
https://stackoverflow.com/questions/4316385/why-is-bottom-up-parsing-more-common-than-top-down-parsing
https://qntm.org/top

- LR语法分析
https://en.wikipedia.org/wiki/LR_parser
LR 算法是一种自底向上的算法，它能够支持更多的语法，且没有左递归的问题。
第一个字母 L，与 LL 算法的第一个 L 一样，代表从左向右读入程序。第二个字母 R，指的是 RightMost（最右推导），也就是在使用产生式的时候，是从右往左依次展开非终结符。
例如，对于add->add+mul这样一个产生式，是优先把 mul 展开，然后再是 add。

- 优点

    LR语法比LL普适，能够避免左递归问题

- 缺点

    不那么直观，不太容易理解
    手工构造LR分析器的工作量非常大，因此一般会使用工具例如yacc。

- SLR(1): simple LR(1)
https://en.wikipedia.org/wiki/Simple_LR_parser

- LALR(1): look ahead LR(1)
https://en.wikipedia.org/wiki/LALR_parser

- Examples
bison
https://en.wikipedia.org/wiki/Bottom-up_parsing#Examples
Operator-precedence parser: https://en.wikipedia.org/wiki/Operator-precedence_parser

- 参考
https://en.wikipedia.org/wiki/Bottom-up_parsing

=== LR算法
==== vs. LL算法
https://stackoverflow.com/questions/4092280/what-advantages-do-ll-parsers-have-over-lr-parsers

==== 移进(shift)与规约(reduce)

==== LR(0)

==== SLR(k)
k 表示需要在 Token 队列里预读 k 个 Token。

==== LALR(k)

==== LR(k)

==== GLR
https://en.wikipedia.org/wiki/GLR_parser

=== 二义性文法

=== 语法分析器生成工具

== 语义分析
=== 概念
语义分析(semantic analyzer):
使用语法树和符号表中的信息来检查源程序是否和语言定义的语义一致，消除语义模糊，同时也收集类型信息，并把这些信息放在语法树或符号表中，以便在之后的中间代码生成过程中使用。
语义分析获得的一些信息（引用消解信息、类型信息等），会附加到AST上。这样的AST叫做带有标注信息的AST（Annotated AST/Decorated AST），用于更全面地反映源代码的含义。

语义分析也称为类型检查、上下文相关分析，负责检查程序(语法树)的上下文相关的属性。

语义分析根据程序语言的语义规则，输出Yes或者No。

在语义分析过程中，会使用两个数据结构。一个还是AST，会把语义分析时获得的一些信息标注在AST上，形成带有标注的AST。另一个是符号表，用来记录程序中声明的各种标识符，并用于后续各个编译阶段。

=== 语义规则
大多数语言的语义规则都是采取自然语言描述的，是人为规定的，编译器的实现者必须对语言中的语义规定有全面的理解。

语义规则可以分为两大类:
第一类规则与上下文有关。
第二类规则与类型有关。在做类型分析的时候，会用到一个工具，即属性计算。某些与类型有关的处理工作，还必须到运行期才能去做。比如，在多态的情况，调用一个方法时，到底要采用哪个子类的实现，只有在运行时才会知道。

=== 上下文相关的分析处理
==== 场景
- 场景1：控制流检查
例如return、break和continue等语句，都与程序的控制流有关，它们必须符合控制流方面的规则。

- 场景2：闭包分析
要正确地使用闭包，就必须在编译期知道哪些变量是自由变量。这里的自由变量是指在本函数外面定义的变量，但被这个函数中的代码所使用。这样，在运行期，编译器就会用特殊的内存管理机制来管理这些变量。

- 场景3：引用消解
引用消解（Reference Resolution），有时也被称作名称消解（Name Resolution）或者标签消解（Label Resolution）。对变量名称、常量名称、函数名称、类型名称、包名称等的消解，都属于引用消解。因此，引用消解是一种非常重要的上下文相关的语义规则。在做引用消解的时候，为了更好地查找变量、类型等定义信息，编译器会使用一个辅助的数据结构：符号表。

==== 符号表
symbol table
不仅仅是语义分析阶段会用到符号表，其它编译阶段也会用到: 在词法分析阶段，就可以为符号表建立条目；在生成IR、做优化和生成目标代码的时候，都会用到符号表里的信息。

=== 类型相关的分析处理
==== 属性文法
attribute grammer
以上下文无关文法为基础，扩充了:
每个文法符号(终结符或非终结符)有"值"属性
每个产生式有一组属性的语义规则，对属性进行计算和传递

==== S属性与I属性
属性中有两类属性，一种是综合属性，另一种是继承属性。
有些属性是通过子节点计算出来的，这叫做 S属性（Synthesized Attribute，综合出来的属性），比如等号右边的类型。而另一些属性，则要根据父节点或者兄弟节点计算而来，这种属性叫做 I属性（Inherited Attribute，继承到的属性），比如等号左边的变量的类型。

==== 语法制导的翻译
在语法规则上附加一系列动作，在解析语法的时候执行这些动作的方式，是一种编译方法，龙书里有一个专门的名字，叫做语法制导的翻译（Syntax Directed Translation，SDT）。使用语法制导的翻译可以做很多事情，包括做属性计算、填充符号表，以及生成IR。

== 中间代码生成
=== 概念
IR(Intermediate Representation)，中间代码，也称Intermediate Code即IC

中间代码的主要两种形式：抽象语法树与三地址指令。

三地址指令:
https://en.wikipedia.org/wiki/Three-address_code

=== SSA
Static Single Assignment，静态单赋值，它要求一个变量只能被赋值一次。
https://en.wikipedia.org/wiki/Static_single-assignment_form

SSA体现了精确的使用-定义(use-def)关系，并且由于变量的值定义出来以后就不再变化，使得基于SSA更容易运行一些优化算法。

现代语言用于优化的IR，很多都是基于SSA的了，包括Java的JIT编译器、JavaScript的V8编译器、Go语言的gc编译器、以及LLVM工具等。

=== CPS
https://en.wikipedia.org/wiki/Continuation-passing_style
https://matt.might.net/articles/by-example-continuation-passing-style/

== 中间代码优化

== 目标代码生成

== 目标代码优化

== 工具
=== antlr
全名: ANother Tool for Language Recognition

==== 概览
- vs. flex-and-bison
https://tomassetti.me/why-you-should-not-use-flex-yacc-and-bison/
https://stackoverflow.com/questions/212900/advantages-of-antlr-versus-say-lex-yacc-bison

==== 文档
https://github.com/antlr/antlr4/blob/master/doc/index.md
左递归: https://github.com/antlr/antlr4/blob/master/doc/left-recursion.md

==== grammars-v4
https://github.com/antlr/grammars-v4/

规则文件以.g4 结尾，词法规则和语法规则可以放在同一个文件里，也可以分成两个文件这样更清晰。
每个词法规则都是大写字母开头，而语法规则是以小写字母开头的。

针对，词法冲突的问题，如标识符和关键字的规则是有重叠的。Antlr引入了优先级的概念，在规则文件中，在前面声明的规则，优先级越高。因此，可以把关键字的规则放在标识符的规则前面。

==== 源码
https://github.com/antlr/antlr4

==== 示例
https://github.com/antlr/grammars-v4
https://github.com/antlr/grammars-v4/tree/master/sql
https://github.com/mysql/mysql-workbench/tree/8.0/library/parsers/grammars

==== 工具
ANTLRWorks: https://www.antlr3.org/works/

==== 参考
《The Definitive ANTLR 4 Reference》
https://www.antlr.org/

=== flex and bison
lex/yacc发展为flex/bison

flex是一个快速词法分析生成器，它可以将用户用正则表达式写的分词匹配模式构造成一个有限状态自动机（一个C函数）。

Bison is a general-purpose parser generator that converts an annotated context-free grammar into a deterministic LR or generalized LR (GLR) parser employing LALR(1), IELR(1) or canonical LR(1) parser tables.

示例:
flex:  https://pandolia.net/tinyc/ch8_flex.html
bison: https://pandolia.net/tinyc/ch13_bison.html

示例:
https://github.com/stardust95/TinyCompiler

文档:
https://westes.github.io/flex/manual/
https://www.gnu.org/software/bison/manual/bison.html

源码:
flex:  https://github.com/westes/flex
bison: https://github.com/akimd/bison

参考:
https://epaperpress.com/lexandyacc/download/flex.pdf
https://www.gnu.org/software/bison/manual/bison.pdf
https://web.iitd.ac.in/~sumeet/flex__bison.pdf

=== AST
clang -ast-dump: https://clang.llvm.org/docs/IntroductionToTheClangAST.html
https://github.com/fkling/astexplorer
Javascript: https://esprima.org/demo/parse.html

=== LLVM
https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html

=== ASM(JAVA字节码工具)
https://asm.ow2.io/

=== lemon
http://www.hwaci.com/sw/lemon/
https://www.sqlite.org/lemon.html
https://github.com/sqlite/sqlite/blob/master/tool/lemon.c

=== jison
An API for creating parsers in JavaScript:
https://github.com/zaach/jison
https://gerhobbelt.github.io/jison/docs/
EBNF: https://gist.github.com/zaach/1659274
https://npm-compare.com/chevrotain,jison,nearley,peggy

=== lua-parser
https://github.com/andremm/lua-parser

=== peg相关
https://github.com/roberto-ieru/LPeg
https://github.com/pegjs/pegjs
https://brynne8.github.io/blog/post/lpeg-and-peg-practices.html

=== 小结
词法分析的工具通常以DFA为主
语法分析的工具通常以LR(1), LALR(1)等为主，不过像antlr也在使用LL(*)
参考: https://en.wikipedia.org/wiki/Comparison_of_parser_generators

== 语言特性
=== 垃圾回收

=== 异常

=== 面向对象

=== 函数式语言

=== CPS(Continuation-Passing Style)
https://en.wikipedia.org/wiki/Continuation-passing_style

== project

=== json
https://www.zhihu.com/question/24640264

=== PeachCompiler
C语言编写, 实现C语言子集

https://www.bilibili.com/video/BV1Jy4y1d7nq/
p1-p4: 介绍与工程
p5-p22: 词法分析
p23-p101: 语法分析

https://github.com/nibblebits/PeachCompiler

=== Tiny C Compiler(Fabrice Bellard)
https://bellard.org/tcc/
https://bellard.org/tcc/tcc-doc.html

=== A small C compiler
https://www.sigbus.info/compilerbook
https://github.com/rui314/chibicc

=== lcc
https://github.com/drh/lcc

=== Writing a C Compiler
OCaml语言编写
https://norasandler.com/archive/
https://github.com/nlsandler/nqcc

=== write-a-C-interpreter
https://github.com/rswier/c4
https://github.com/lotabout/write-a-C-interpreter

=== 自己动手用java写编译器
https://study.163.com/course/courseLearn.htm?courseId=1002830012#

=== The TINY Sample Language
C语言编写，实现类Pascal子集
http://www.cs.sjsu.edu/~louden/cmptext/loucomp.zip

=== Cb
java语言编写，C的变化子集
https://www.ituring.com.cn/book/1308 随书下载

=== PL
js编写 一个示例语言
https://lisperator.net/pltut/

=== 参考
http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf[An Incremental Approach to Compiler Construction]

== 参考
《Compiler Construction Principles and Practice》 (编译原理及实践)
《Engineering a Compiler》2nd (编译器设计)
《Compilers, Principles, Techniques and Tools》2nd (龙书)
《Modern Compiler Implementation in C》(虎书)
《Advanced Compiler Design and Implementation》(鲸书)
《Optimizing compilers for modern architectures - a dependency based approach》(现代体系结构的优化编译器)
编译原理 华保健 https://www.bilibili.com/video/BV1m7411d7iS/
http://web.stanford.edu/class/cs143/
Stanford CS143: https://www.bilibili.com/video/BV17K4y147Bz
Harvard CS153: https://www.bilibili.com/video/BV1cT4y197hW
https://www.cs.cmu.edu/afs/cs/academic/class/15745-s19/www/lectures/
《编译原理之美》 https://time.geekbang.org/column/intro/100034101
《编译原理实战课》https://time.geekbang.org/column/intro/100052801
《Introduction to the Theory of Computation》3rd (计算理论导引) 正则表达式，自动机，上下文无关文法等相关理论
http://staff.ustc.edu.cn/~bjhua/courses/compiler/2014/
https://compilers.iecc.com/crenshaw/
《crafting-interpreters》
https://github.com/aalhour/awesome-compilers