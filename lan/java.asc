= java
:revnumber: 0.0.1
:author: orient
:homepage: http://orientye.com
:toc:
:toclevels: 5
:hardbreaks-option:
<<<

== 概念
- 历史
    https://en.wikipedia.org/wiki/Java_version_history

- 分层编译(TieredCompilation)

- JIT

- AOT(Ahead-of-Time Compilation)

    直接将字节码编译成机器代码，避免了JIT预热等各方面的开销
    例如Oracle JDK 9就引入了实验性的AOT特性，并且增加了新的jaotc工具
    https://openjdk.org/jeps/295

== 基础
=== 核心
- String、StringBuffer、StringBuilder

    String是final class，且所有属性也都是final的
    由于它的不可变性，类似拼接、裁剪字符串等操作，均会产生新的String对象
    String str1 = "abc123"; //通过直接量赋值方式，放入字符串常量池
    String str2 = new String("abc123"); //通过new方式赋值方式，不放入字符串常量池
    在字符串内容不经常发生变化的场景优先使用String类。如: 常量声明、少量的字符串拼接操作等。

    StringBuffer线程安全

    StringBuilder非线程安全，性能较好，优先考虑

- final、finally、finalize

    final可以用来修饰类、方法、变量
    final的类不可以继承
    final的方法不可以override
    final的变量不可以修改

    finally是保证代码一定要被执行的一种机制
    使用try-finally或者try-catch-finally来进行类似关闭连接、unlock锁等动作
    Q: 一定能被执行吗？
    A: 不一定，例如try块里调用了System.exit(1)

    finalize是java.lang.Object的一个方法
    保证对象在被垃圾收集前完成特定资源的回收
    从JDK 9起被标记为deprecated:
    https://docs.oracle.com/javase%2F9%2Fdocs%2Fapi%2F%2F/java/lang/Object.html
    推荐使用java.lang.ref.Cleaner, 不过也存在问题

- 强引用、软引用、弱引用、幻象引用

    不同的引用类型，主要体现的是对象不同的可达性(reachable)状态和对垃圾收集的影响。

    强引用Strong Reference，即最常见的普通对象引用
    只要还有强引用指向一个对象，就能表明对象还活着，垃圾收集器不会碰这种对象。
    对于一个普通的对象，如果没有其他的引用关系，
    只要超过了引用的作用域或者显式地将相应(强)引用赋值为null，就是可以被垃圾收集的了，
    当然具体回收时机还是要看垃圾收集策略。

    软引用SoftReference，是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集
    只有当JVM认为内存不足时，才会去试图回收软引用指向的对象。
    JVM会确保在抛出OutOfMemoryError之前，清理软引用指向的对象。
    软引用通常用来实现内存敏感的缓存，
    如果还有空闲内存，就可以暂时保留缓存，
    当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。

    弱引用WeakReference并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。
    可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系
    如果试图获取时对象还在，就使用它，否则重现实例化。
    它同样是很多缓存实现的选择。

    幻象引用，也叫虚引用，不能通过它访问对象。
    幻象引用仅仅是提供了一种确保对象被finalize以后，做某些事情的机制
    比如，通常用来做所谓的Post-Mortem清理机制，Java平台自身Cleaner机制等
    也可以利用幻象引用监控对象的创建和销毁

- 反射机制

    赋予程序在运行时自省(introspect)的能力
    通过反射可以直接操作类或者对象，例如:
    获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义
    https://docs.oracle.com/javase/tutorial/reflect/index.html

- 动态代理

    一种方便运行时动态构建代理、动态处理代理方法调用的机制
    使用场景: RPC调用、面向切面(AOP)的编程等
    实现动态代理的方式很多，例如JDK自身提供的动态代理，其主要利用了反射机制。
    其它的实现方式，例如ASM、cglib(基于ASM)、Javassist等。

- int和Integer有何区别

    8个原始数据类型(Primitive Types): boolean、byte、short、char、int、float、double、long
    Integer是int对应的包装类，其它同理
    Java 5中引入了自动装箱和自动拆箱功能(boxing/unboxing)，可以根据上下文自动进行转换

    使用原始数据类型在性能极度敏感的场景往往具有优势
    原始数据类型操作非线程安全
    原始数据类型和Java泛型并不能配合使用
        因为Java的泛型某种程度上可以算作伪泛型，是一种编译期的技巧
        Java编译期会自动将类型转换为对应的特定类型
    对象类型无法高效地表达数据，例如vector
        Java的对象都是引用类型，如果是一个原始数据类型数组，它在内存里是一段连续的内存
        而对象数组则不然，数据存储的是引用，对象往往分散地存储在堆的不同位置
        这种设计虽然带来了极大灵活性，但是也导致了数据操作的低效，尤其是无法充分利用现代CPU缓存机制

- Vector、ArrayList、LinkedList有何区别

    Vector是Java早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择
    Vector内部是使用对象数组来保存数据，可以根据需要自动的增加容量
    当数组已满时，会创建新的数组，并拷贝原有数组数据

    ArrayList是应用更加广泛的动态数组，非线程安全，因此性能要好很多
    Vector在扩容时会提高1倍，而ArrayList则是增加50%

    LinkedList是双向链表，非线程安全

- Hashtable、HashMap、LinkedHashMap、TreeMap有何区别

    Hashtable是早期Java类库提供的一个哈希表实现，本身是同步的，不支持null键和值
    由于同步导致的性能开销，已经很少被推荐使用

    HashMap基于哈希表，通常是首选
    与HashTable主要区别在于HashMap不是同步的，支持null键和值等
    通常情况下，put或者get操作可以达到常数时间的性能

    LinkedHashMap使用了双链表，能维护插入顺序

    TreeMap基于红黑树，提供顺序访问
    和HashMap不同，get、put、remove之类操作都是O(log(n))的时间复杂度

- HashMap

    数组(Node<K,V>[] table)和链表结合组成的复合结构
    数组被分为一个个桶(bucket)，通过哈希值决定了键值对在这个数组的寻址
    哈希值相同的键值对，则以链表形式存储

    rehashed: that is, internal data structures are rebuilt
    https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html
    如果链表大小超过阈值(TREEIFY_THRESHOLD, 8)，链表就会被改造为树形结构(即树化)。
    树化是为了性能与安全:
        如果对象哈希冲突都被放置到同一个桶里，则会形成一个链表
        链表查询是线性的，会严重影响存取的性能
        恶意制造哈希冲突，导致服务器端CPU大量占用，构成了哈希碰撞拒绝服务攻击
    
    树化改造，对应逻辑主要在putVal()和treeifyBin()中:
    如果容量小于MIN_TREEIFY_CAPACITY(默认64)，只会进行简单的扩容；
    否则，进行树化改造。

    扩容: resize()方法
    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/HashMap.java

    hashCode和equals的一些基本约定:
        equals相等，hashCode一定要相等
        重写了hashCode也要重写equals
        hashCode需要保持一致性，状态改变返回的哈希值仍然要一致
        equals的对称、反射、传递等特性

    同步:
    Map m = Collections.synchronizedMap(new HashMap(...));

- ConcurrentHashMap

    Hashtable比较低效，其实现基本就是将put、get、size等各种方法加上synchronized
    HashMap非线程安全的，而Collections提供的同步包装器同样低效:
    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/Collections.java
    private static class SynchronizedMap<K,V> implements Map<K,V>, Serializable {
        //...
        @SuppressWarnings("serial") // Conditionally serializable
        private final Map<K,V> m;     // Backing Map
        @SuppressWarnings("serial") // Conditionally serializable
        final Object      mutex;        // Object on which to synchronize
        //...
        public V get(Object key) {
            synchronized (mutex) {return m.get(key);}
        }
        //
        public V put(K key, V value) {
            synchronized (mutex) {return m.put(key, value);}
        }
        //...
    }

    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/concurrent/ConcurrentHashMap.java

    Java8:
    依然是桶(bucket)数组 + 链表结构(bin)，但同步的粒度要更细
    内部仍然有Segment定义，但仅仅是为了保证序列化时的兼容性
    由于不再使用Segment，初始化操作得以大大简化，修改为lazy-load形式，避免初始化开销
    利用volatile来保证可见性
    使用CAS等操作，在特定场景进行无锁并发操作
    使用Unsafe、LongAdder等底层手段，进行极端情况的优化

- 排序
原始数据类型:
https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/DualPivotQuicksort.java
对象数据类型:
https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/TimSort.java
参考: https://mail.openjdk.org/pipermail/core-libs-dev/2018-January/051000.html
参考: https://en.wikipedia.org/wiki/Timsort

- Direct vs. non-direct buffers
The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory footprint of an application might not be obvious. It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system's native I/O operations. In general it is best to allocate direct buffers only when they yield a measureable gain in program performance.

=== OOP

=== 泛型

=== 注解
https://www.geeksforgeeks.org/annotations-in-java/
https://docs.oracle.com/javase/tutorial/java/annotations/index.html

=== 异常
==== 分类
Exception: https://docs.oracle.com/javase/8/docs/api/java/lang/Exception.html
Error: https://docs.oracle.com/javase/8/docs/api/java/lang/Error.html

Exception和Error都继承了Throwable类。

Exception是程序正常运行中，可以预料的意外情况，可能并且应该被捕获。

Error是指在正常情况下，不大可能出现的情况，绝大部分的Error都会导致程序(比如JVM自身)处于非正常的、不可恢复状态。Error是非正常情况，不便于也不需要捕获，常见的Error如OutOfMemoryError。

Exception又分为可检查(checked)异常和不检查(unchecked)异常:
可检查异常必须显式地进行捕获处理，是编译期检查的一部分。
不检查异常即运行时异常，例如NullPointerException、ArrayIndexOutOfBoundsException，通常是编码可以避免的逻辑错误，根据需要决定是否进行捕获，不会在编译期强制要求。

==== Checked Exception之争
反对Java语言的Checked Exception的原因:
Checked Exception假设捕获了异常，然后恢复程序，然而大多数情况下是不能恢复的；
Checked Exception不兼容functional编程。

很多开源项目，已经采纳了这种实践，如Spring、Hibernate等，以及新的编程语言如Scala等。
参考: http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/

另一方面，有一些异常，比如和环境相关的IO、网络等，其实是存在可恢复性的。
参考: https://v.qq.com/x/page/d0635rf5x0o.html[Failing at Failing: How and Why We’ve Been Nonchalantly Moving Away From Exception Handling]

==== 实践
- 尽量不要捕获类似Exception这样的通用异常，而是应该捕获特定异常

- 不要生吞(swallow)异常，否则可能导致非常难以诊断的诡异情况
e.printStackTrace()也不合适，这是因为它prints this throwable and its backtrace to the standard error stream，而生产环境中，标准错误(stderr)不是一个合适的输出选项，很难判断错误输出到哪里了。

- throw early, catch late原则
在更高层面，具有更完整清晰的context，往往可以选择更合理的处理方式。

- 捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层使用者，必须处理异常。

- 事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。

- finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。JDK7及以上，可以使用try-with-resources方式。

- 不要在finally块中使用return
解读: try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存在return语句，则在此直接返回，将会丢弃掉try块中的返回点。
反例:
[source, java]
----
private int x = 0;
    public int checkReturn() {
    try {
        // x等于1，此处不返回
        return ++x;
    } finally {
        // 返回的结果是2
        return ++x;
    }
}
----

- 在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable类来进行拦截。
解读: 通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，或者在字节码修改框架(比如ASM)动态创建或修改类时，修改了相应的方法签名。这些情况，即使代码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。

- 防止NPE(NullPointerException)是调用者的责任。

- 对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、errorMessage；而应用内部直接抛出异常即可。
解读: 关于RPC方法返回方式使用Result方式的理由:
1）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。
2）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。

参考: 《Java开发手册》异常处理

==== 性能
Java每实例化一个Exception，都会对当时的栈进行快照。如果发生的非常频繁，此开销不能被忽略。

建议仅捕获有必要的代码段，尽量不要一个大的try包住整段的代码；也不要利用异常控制代码流程。

=== 反射

=== SPI
Service Provider Interface

== 内存

=== 堆外内存和堆内内存
- 堆内内存

    JVM GC自动回收
    新生代与老年代

- 堆外内存

    不受JVM管理，需要手动释放
    当进行网络I/O操作、文件读写时，堆内内存都需要转换为堆外内存，然后再与底层设备进行交互
    堆外内存可以实现进程之间、JVM多实例之间的数据共享

=== GC

== concurrency
=== 介绍
Threads are sometimes called lightweight processes, and most modern operating systems treat threads, not processes, as the basic units of scheduling.

Benefits of threads:
1. Exploiting multiple processors
2. Simplicity of modeling
A complicated, asynchronous workflow can be decomposed into a number of simpler, synchronous workflows each running in a separate thread, interacting only with each other at specific synchronization points.
3. Simplified handling of asynchronous events
4. More responsive user interfaces

Risks of threads:
1. Safety hazards
Thread safety can be unexpectedly subtle because, in the absence of sufficient synchronization, the ordering of operations in multiple threads is unpredictable and sometimes surprising.
2. Liveness hazards
safety means "nothing bad ever happens"
liveness concerns the complementary goal that "something good eventually happens"
For example, if thread A is waiting for a resource that thread B holds exclusively, and B never releases it, A will wait forever.
3. Performance hazards
When threads share data, they must use synchronization mechanisms that can inhibit compiler optimizations, flush or invalidate memory caches, and create synchronization traffic on the shared memory bus. All these factors introduce additional performance costs.

Threads are everywhere:
When the JVM starts, it creates threads for JVM housekeeping tasks (garbage collection, finalization) and a main thread for running the main method.
The AWT (Abstract Window Toolkit) and Swing user interface frameworks create threads for managing user interface events.
Timer creates threads for executing deferred tasks.
Component frameworks, such as servlets and RMI create pools of threads and invoke component methods in these threads.

=== 线程安全
If multiple threads access the same mutable state variable without appropriate synchronization, your program is broken. There are three ways to fix it:
• Don’t share the state variable across threads;
• Make the state variable immutable; or
• Use synchronization whenever accessing the state variable.

什么是线程安全:
Thread-safe classes encapsulate any needed synchronization so that clients need not provide their own.
Example: a stateless servlet
[source, java]
----
@ThreadSafe
public class StatelessFactorizer implements Servlet {
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        encodeIntoResponse(resp, factors);
    }
}
----
Stateless objects are always thread-safe.

Atomicity原子性:
[source, java]
----
@NotThreadSafe
public class UnsafeCountingFactorizer implements Servlet {
    private long count = 0;
    public long getCount() { return count; }
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        ++count; //not thread safe
        encodeIntoResponse(resp, factors);
    }
}
----
race conditions:
[source, java]
----
@NotThreadSafe
public class LazyInitRace {
    private ExpensiveObject instance = null;
    public ExpensiveObject getInstance() {
        if (instance == null)
        instance = new ExpensiveObject();
        return instance;
    }
}
----

[source, java]
----
@ThreadSafe
public class CountingFactorizer implements Servlet {
    private final AtomicLong count = new AtomicLong(0);
    public long getCount() { return count.get(); }
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        count.incrementAndGet();
        encodeIntoResponse(resp, factors);
    }
}
----
Where practical, use existing thread-safe objects, like AtomicLong, to manage your class’s state.

Locking:
[source, java]
----
public class Widget {
    public synchronized void doSomething() {
        ...
    }
}
public class LoggingWidget extends Widget {
    public synchronized void doSomething() {
        System.out.println(toString() + ": calling doSomething");
        super.doSomething();
    }
}
----
Code that would deadlock if intrinsic locks were not reentrant.

Guarding state with locks

Liveness and performance:
There is frequently a tension between simplicity and performance. When implementing a synchronization policy, resist the temptation to prematurely sacrifice simplicity (potentially compromising safety) for the sake of performance.
Avoid holding locks during lengthy computations or operations at risk of not completing quickly such as network or console I/O.

=== Sharing Objects
==== Visibility
可见性
always use the proper synchronization whenever data is shared across threads.
Locking is not just about mutual exclusion; it is also about memory visibility. To ensure that all threads see the most up-to-date values of shared mutable variables, the reading and writing threads must synchronize on a common lock.

Volatile variables:
Use volatile variables only when they simplify implementing and verifying your synchronization policy; avoid using volatile variables when veryfing correctness would require subtle reasoning about visibility. Good uses of volatile variables include ensuring the visibility of their own state, that of the object they refer to, or indicating that an important lifecycle event (such as initialization or shutdown) has occurred.
Locking can guarantee both visibility and atomicity; volatile variables can only guarantee visibility.
You can use volatile variables only when all the following criteria are met:
• Writes to the variable do not depend on its current value, or you can ensure that only a single thread ever updates the value;
• The variable does not participate in invariants with other state variables;
and
• Locking is not required for any other reason while the variable is being accessed.

==== Publication and escape
Publishing an object means making it available to code outside of its current scope, such as by storing a reference to it where other code can find it, returning it from a nonprivate method, or passing it to a method in another class ...
An object that is published when it should not have been is said to have escaped.

==== Thread confinement
线程约束
• Ad-hoc thread confinement(特定目的线程约束)
The decision to use thread confinement is often a consequence of the decision to implement a particular subsystem, such as the GUI, as a single-threaded subsystem.
A special case of thread confinement applies to volatile variables.
建议:
Because of its fragility, ad-hoc thread confinement should be used sparingly; if possible, use one of the stronger forms of thread confinment (stack confinement or ThreadLocal) instead.
• Stack confinement
Stack confinement is a special case of thread confinement in which an object can only be reached through local variables.
Stack confinement (also called within-thread or thread-local usage, but not to be confused with the ThreadLocal library class) is simpler to maintain and less fragile than ad-hoc thread confinement.
• ThreadLocal
ThreadLocal provides get and set accessor methods that maintain a separate copy of the value for each thread that uses it, so a get returns the most recent value passed to set from the currently executing thread.
[source, java]
----
private static ThreadLocal<Connection> connectionHolder
    = new ThreadLocal<Connection>() {
        public Connection initialValue() {
            return DriverManager.getConnection(DB_URL);
        }
    };

public static Connection getConnection() {
    return connectionHolder.get();
}
----

==== Immutability
An object is immutable if:
• Its state cannot be modified after construction;
• All its fields are final;
• It is properly constructed (the this reference does not escape during construction).
[source, java]
.Immutable class built out of mutable underlying objects.
----
@Immutable
public final class ThreeStooges {
    private final Set<String> stooges = new HashSet<String>();
        public ThreeStooges() {
        stooges.add("Moe");
        stooges.add("Larry");
        stooges.add("Curly");
    }

    public boolean isStooge(String name) {
        return stooges.contains(name);
    }
}
----

Final fields:
Even if an object is mutable, making some fields final can still simplify reasoning about its state, since limiting the mutability of an object restricts its set of possible states. An object that is “mostly immutable” but has one or two mutable state variables is still simpler than one that has many mutable variables.
it is a good practice to make all fields private unless they need greater visibility, it is a good practice to make all fields final unless they need to be mutable.

==== Safe publication
Immutable objects can be used safely by any thread without additional synchronization, even when synchronization is not used to publish them.
To publish an object safely, both the reference to the object and the object’s state must be made visible to other threads at the same time. A properly constructed object can be safely published by:
• Initializing an object reference from a static initializer;
• Storing a reference to it into a volatile field or AtomicReference;
• Storing a reference to it into a final field of a properly constructed object; or
• Storing a reference to it into a field that is properly guarded by a lock.

Effectively immutable objects:
Objects that are not technically immutable, but whose state will not be modified after publication, are called effectively immutable.
Safely published effectively immutable objects can be used safely by any thread without additional synchronization.

Mutable objects:
The publication requirements for an object depend on its mutability:
• Immutable objects can be published through any mechanism;
• Effectively immutable objects must be safely published;
• Mutable objects must be safely published, and must be either thread-safe or guarded by a lock.

=== Composing Objects
Designing a thread-safe class
Instance confinement
Delegating thread safety
Adding functionality to existing thread-safe classes
Documenting synchronization policies

=== Building Blocks
==== Synchronized collections
java.util.Collections.synchronizedXxx factory methods

Problems with synchronized collections
Iterators and ConcurrentModificationException
Hidden iterators

==== Concurrent collections
Java 5.0 improves on the synchronized collections by providing several concurrent collection classes. Synchronized collections achieve their thread safety by serializing all access to the collection’s state. The cost of this approach is poor concurrency; when multiple threads contend for the collection-wide lock, throughput suffers.

Replacing synchronized collections with concurrent collections can offer dramatic scalability improvements with little risk.

==== Blocking queues and the producer-consumer pattern
Work stealing can be more scalable than a traditional producer-consumer design because workers don’t contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another’s queue, it does so from the tail rather than the head, further reducing contention.
Work stealing is well suited to problems in which consumers are also producers—when performing a unit of work is likely to result in the identification of more work. For example, processing a page in a web crawler usually results in the identification of new pages to be crawled. Similarly, many graph-exploring algorithms, such as marking the heap during garbage collection, can be efficiently parallelized using work stealing. When a worker identifies a new unit of work, it places it at the end of its own deque (or alternatively, in a work sharing design, on that of another worker); when its deque is empty, it looks for work at the end of someone else’s deque, ensuring that each worker stays busy.

==== Blocking and interruptible methods
Interruption is a cooperative mechanism.

When your code calls a method that throws InterruptedException, then your method is a blocking method too, and must have a plan for responding to interruption. For library code, there are basically two choices:
1. Propagate the InterruptedException. This is often the most sensible policy if you can get away with it—just propagate the InterruptedException to your caller. This could involve not catching InterruptedException, or catching it and throwing it again after performing some brief activity-specific cleanup.
2. Restore the interrupt. Sometimes you cannot throw InterruptedException, for instance when your code is part of a Runnable. In these situations, you must catch InterruptedException and restore the interrupted status by calling interrupt on the current thread, so that code higher up the call stack can see that an interrupt was issued, as demonstrated:
[source, java]
.Restoring the interrupted status so as not to swallow the interrupt.
----
public class TaskRunnable implements Runnable {
    BlockingQueue<Task> queue;
    ...
    public void run() {
        try {
            processTask(queue.take());
        } catch (InterruptedException e) {
            // restore interrupted status
            Thread.currentThread().interrupt();
        }
    }
}
----
But there is one thing you should not do with InterruptedException—catch it and do nothing in response. This deprives code higher up on the call stack of the opportunity to act on the interruption, because the evidence that the thread was interrupted is lost. The only situation in which it is acceptable to swallow an interrupt is when you are extending Thread and therefore control all the code higher up on the call stack.

==== Synchronizers
CountDownLatch: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CountDownLatch.html
FutureTask: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/FutureTask.html
Semaphore: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Semaphore.html
CyclicBarrier: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CyclicBarrier.html
Phaser: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Phaser.html
Exchanger: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Exchanger.html

=== Task Execution
==== Executing tasks in threads
Ideally, tasks are independent activities: work that doesn’t depend on the state, result, or side effects of other tasks.

==== The Executor framework
Executor may be a simple interface, but it forms the basis for a flexible and powerful framework for asynchronous task execution that supports a wide variety of task execution policies. It provides a standard means of decoupling task submission from task execution, describing tasks with Runnable. The Executor implementations also provide lifecycle support and hooks for adding statistics gathering, application management, and monitoring.
Executor is based on the producer-consumer pattern, where activities that submit tasks are the producers (producing units of work to be done) and the threads that execute tasks are the consumers (consuming those units of work).

Execution policies:
• In what thread will tasks be executed?
• In what order should tasks be executed (FIFO, LIFO, priority order)?
• How many tasks may execute concurrently?
• How many tasks may be queued pending execution?
• If a task has to be rejected because the system is overloaded, which task should be selected as the victim, and how should the application be notified?
• What actions should be taken before or after executing a task?

Whenever you see code of the form: new Thread(runnable).start()
and you think you might at some point want a more flexible execution policy, seriously consider replacing it with the use of an Executor.

Thread pools

Executor lifecycle

Delayed and periodic tasks

==== Finding exploitable parallelism
Result-bearing tasks: Callable and Future

CompletionService: Executor meets BlockingQueue

Placing time limits on tasks

=== Cancellation and Shutdown
Java does not provide any mechanism for safely forcing a thread to stop what it is doing. Instead, it provides interruption, a cooperative mechanism that lets one thread ask another to stop what it is doing.

==== Task cancellation
There are a number of reasons why you might want to cancel an activity: user-requested, cancellation, time-limited activities, application events, errors, shutdown.

There is no safe way to preemptively stop a thread in Java, and therefore no safe way to preemptively stop a task. There are only cooperative mechanisms, by which the task and the code requesting cancellation follow an agreed-upon protocol.

=== virtual thread
==== 概念
==== 历史
since JDK19, JDK 21(September 2023) release.
https://openjdk.org/jeps/444 JEP 444: Virtual Threads
https://openjdk.org/jeps/436 JEP 436: Virtual Threads (Second Preview)
https://openjdk.org/jeps/425 JEP 425: Virtual Threads (Preview)

=== API
- java.util.concurrent
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/package-summary.html

- java.util.concurrent.locks
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/locks/package-summary.html

- java.util.concurrent.atomic
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/atomic/package-summary.html

=== Q&A
==== synchronized与ReentrantLock
synchronized是Java内建的同步机制，也称Intrinsic Locking，它提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他试图获取的线程只能等待或者阻塞在那里。Java 5以前synchronized是仅有的同步手段。

Java 5提供的ReentrantLock，语义与synchronized基本相同。
ReentrantLock能够实现更多细节控制，比如可以控制fairness，或者利用定义条件等。
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/ReentrantLock.html

早期版本的synchronized在很多场景下与ReentrantLock性能相差较大，在后续版本进行了较多改进，在低竞争场景中表现可能优于ReentrantLock。

关于公平性:
公平性是指在竞争场景中，当公平性为真时，会倾向于将锁赋予等待时间最久的线程。公平性会引入额外开销，只有确实有公平性需要的时候，才有必要指定。
指定方式: ReentrantLock(boolean fair)

==== synchronized
synchronized代码块是由monitorenter/monitorexit指令实现的，Monitor对象是同步的基本实现单元。

Java 6之前，Monitor的实现完全依靠操作系统内部的互斥锁，需要进行用户态到内核态的切换，是一个重量级操作。

现在JVM提供了三种不同的Monitor实现，即: 偏斜锁(Biased Locking)、轻量级锁和重量级锁。

锁的升级、降级，就是JVM优化synchronized运行的机制，当JVM检测到不同的竞争状况时，会自动切换到适合的锁实现:
没有竞争出现时，默认会使用偏斜锁。JVM会利用CAS操作(compare and swap)，在对象头上的Mark Word部分设置线程ID，表示该对象偏向于当前线程，因此并不涉及真正的互斥锁。其假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。
如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM就需要撤销(revoke)偏斜锁，并切换到轻量级锁实现。轻量级锁依赖CAS操作Mark Word来试图获取锁，如果重试成功，就使用普通的轻量级锁；否则，进一步升级为重量级锁。

==== 条件变量
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/Condition.html

==== StampedLock
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/StampedLock.html
https://stackoverflow.com/questions/26094200/what-is-stampedlock-in-java

==== 线程状态
https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.State.html

    NEW
        A thread that has not yet started is in this state.
    RUNNABLE
        A thread executing in the Java virtual machine is in this state.
    BLOCKED
        A thread that is blocked waiting for a monitor lock is in this state.
    WAITING
        A thread that is waiting indefinitely for another thread to perform a particular action is in this state.
    TIMED_WAITING
        A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state.
    TERMINATED
        A thread that has exited is in this state.

Q: 一个线程两次调用start()方法会出现什么情况？
A: Java的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException(运行时异常)。因为在第二次调用 start()方法的时候，线程可能处于终止或者其它(非NEW)状态。

守护线程:

    Thread daemonThread = new Thread();
    daemonThread.setDaemon(true);
    daemonThread.start();

==== ThreadLocal
https://docs.oracle.com/javase/8/docs/api/java/lang/ThreadLocal.html

==== servlet
https://stackoverflow.com/questions/3106452/how-do-servlets-work-instantiation-sessions-shared-variables-and-multithreadi

=== 最佳实践

=== 参考
《Java Concurrency in Practice》

== 热更新
- Javassist(Java Programming Assistant)
https://github.com/jboss-javassist/javassist

- Byte Buddy
https://github.com/raphw/byte-buddy

- java.lang.instrument.Instrumentation redefineClasses()

- 参考
https://www.zhihu.com/question/61040749

== JVM

== 性能优化

=== 参考
《Java性能优化权威指南》

== 工具
=== lombok
https://projectlombok.org/
https://projectlombok.org/features/

=== maven
https://maven.apache.org/

=== 监控与分析
自带命令: jps、jstat、jstack、jmap
visualvm: https://visualvm.github.io/download.html

第三方在线监控工具:
arthas: https://github.com/alibaba/arthas/blob/master/README_CN.md
skywalking: https://github.com/apache/skywalking

=== 代码分析
https://github.com/pmd/pmd

== 实战
=== 日志
https://tech.meituan.com/2022/07/29/tips-for-avoiding-log-blocking-threads.html

== 参考
https://github.com/akullpp/awesome-java
https://docs.oracle.com/en/java/javase/index.html
极客时间《Java 核心技术面试精讲》