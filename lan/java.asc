= java
:revnumber: 0.0.1
:author: orient
:homepage: http://orientye.com
:toc:
:toclevels: 5
:hardbreaks-option:
<<<

== 概念
- 历史
    https://en.wikipedia.org/wiki/Java_version_history

- 分层编译(TieredCompilation)

- JIT
    JIT是指将热点代码以方法为单位转换成机器码，直接运行在底层硬件之上。它采用了多种优化方式，包括静态编译器可以使用的如方法内联、逃逸分析，也包括基于程序运行profile的投机性优化(speculative/optimistic optimization)。

- AOT(Ahead-of-Time Compilation)
    直接将字节码编译成机器代码，避免了JIT预热等各方面的开销
    例如Oracle JDK 9就引入了实验性的AOT特性，并且增加了新的jaotc工具
    https://openjdk.org/jeps/295

== 基础
=== 核心
- String、StringBuffer、StringBuilder

    String是final class，且所有属性也都是final的
    由于它的不可变性，类似拼接、裁剪字符串等操作，均会产生新的String对象
    String str1 = "abc123"; //通过直接量赋值方式，放入字符串常量池
    String str2 = new String("abc123"); //通过new方式赋值方式，不放入字符串常量池
    在字符串内容不经常发生变化的场景优先使用String类，如常量声明、少量的字符串拼接操作等

    StringBuffer线程安全

    StringBuilder非线程安全，性能较好，优先考虑

- final、finally、finalize

    final可以用来修饰类、方法、变量
    final的类不可以继承
    final的方法不可以override
    final的变量不可以修改
        https://en.wikipedia.org/wiki/Java_concurrency#Final_fields

    finally是保证代码一定要被执行的一种机制
    使用try-finally或者try-catch-finally来进行类似关闭连接、unlock锁等动作
    Q: 一定能被执行吗？
    A: 不一定，例如try块里调用了System.exit(1)

    finalize是java.lang.Object的一个方法
    保证对象在被垃圾收集前完成特定资源的回收
    从JDK 9起被标记为deprecated:
    https://docs.oracle.com/javase%2F9%2Fdocs%2Fapi%2F%2F/java/lang/Object.html
    推荐使用java.lang.ref.Cleaner, 不过也存在问题

- 强引用、软引用、弱引用、幻象引用

    不同的引用类型，主要体现的是对象不同的可达性(reachable)状态和对垃圾收集的影响。

    强引用Strong Reference，即最常见的普通对象引用
    只要还有强引用指向一个对象，就能表明对象还活着，垃圾收集器不会碰这种对象。
    对于一个普通的对象，如果没有其他的引用关系，
    只要超过了引用的作用域或者显式地将相应(强)引用赋值为null，就是可以被垃圾收集的了，
    当然具体回收时机还是要看垃圾收集策略。

    软引用SoftReference，是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集
    只有当JVM认为内存不足时，才会去试图回收软引用指向的对象。
    JVM会确保在抛出OutOfMemoryError之前，清理软引用指向的对象。
    软引用通常用来实现内存敏感的缓存，
    如果还有空闲内存，就可以暂时保留缓存，
    当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。

    弱引用WeakReference并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。
    可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系
    如果试图获取时对象还在，就使用它，否则重现实例化。
    它同样是很多缓存实现的选择。

    幻象引用，也叫虚引用，不能通过它访问对象。
    幻象引用仅仅是提供了一种确保对象被finalize以后，做某些事情的机制
    比如，通常用来做所谓的Post-Mortem清理机制，Java平台自身的Cleaner机制等
    也可以利用幻象引用监控对象的创建和销毁

- 反射机制

    赋予程序在运行时自省(introspect)的能力
    通过反射可以直接操作类或者对象，例如:
    获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义
    https://docs.oracle.com/javase/tutorial/reflect/index.html

- 动态代理

    一种方便运行时动态构建代理、动态处理代理方法调用的机制
    使用场景: RPC调用、面向切面(AOP)的编程等
    实现动态代理的方式很多，例如JDK自身提供的动态代理，其主要利用了反射机制
    其它的实现方式，例如ASM、cglib(基于ASM)、Javassist等

- int和Integer有何区别

    8个原始数据类型(Primitive Types): boolean、byte、short、char、int、float、double、long
    Integer是int对应的包装类，其它同理
    Java 5中引入了自动装箱和自动拆箱功能(boxing/unboxing)，可以根据上下文自动进行转换

    使用原始数据类型在性能极度敏感的场景往往具有优势
    原始数据类型操作非线程安全
    原始数据类型和Java泛型并不能配合使用
        因为Java的泛型某种程度上可以算作伪泛型，是一种编译期的技巧
        Java编译期会自动将类型转换为对应的特定类型
    对象类型无法高效地表达数据，例如vector
        Java的对象都是引用类型，如果是一个原始数据类型数组，它在内存里是一段连续的内存
        而对象数组则不然，数据存储的是引用，对象往往分散地存储在堆的不同位置
        这种设计虽然带来了极大灵活性，但是也导致了数据操作的低效，尤其是无法充分利用现代CPU缓存机制

- Vector、ArrayList、LinkedList有何区别

    Vector是Java早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择
    Vector内部是使用对象数组来保存数据，可以根据需要自动的增加容量
    当数组已满时，会创建新的数组，并拷贝原有数组数据

    ArrayList是应用更加广泛的动态数组，非线程安全，因此性能要好很多
    Vector在扩容时会提高1倍，而ArrayList则是增加50%

    LinkedList是双向链表，非线程安全

- Hashtable、HashMap、LinkedHashMap、TreeMap有何区别

    Hashtable是早期Java类库提供的一个哈希表实现，本身是同步的，不支持null键和值
    由于同步导致的性能开销，已经很少被推荐使用

    HashMap基于哈希表，通常是首选
    与HashTable主要区别在于HashMap不是同步的，支持null键和值等
    通常情况下，put或者get操作可以达到常数时间的性能

    LinkedHashMap使用了双链表，能维护插入顺序

    TreeMap基于红黑树，提供顺序访问
    和HashMap不同，get、put、remove之类操作都是O(log(n))的时间复杂度

- HashMap

    数组(Node<K,V>[] table)和链表结合组成的复合结构
    数组被分为一个个桶(bucket)，通过哈希值决定了键值对在这个数组的寻址
    哈希值相同的键值对，则以链表形式存储

    rehashed: that is, internal data structures are rebuilt
    https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html
    如果链表大小超过阈值(TREEIFY_THRESHOLD, 8)，链表就会被改造为树形结构(即树化)。
    树化是为了性能与安全:
        如果对象哈希冲突都被放置到同一个桶里，则会形成一个链表
        链表查询是线性的，会严重影响存取的性能
        恶意制造哈希冲突，导致服务器端CPU大量占用，构成了哈希碰撞拒绝服务攻击
    
    树化改造，对应逻辑主要在putVal()和treeifyBin()中:
    如果容量小于MIN_TREEIFY_CAPACITY(默认64)，只会进行简单的扩容；
    否则，进行树化改造。

    扩容: resize()方法
    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/HashMap.java

    hashCode和equals的一些基本约定:
        equals相等，hashCode一定要相等
        重写了hashCode也要重写equals
        hashCode需要保持一致性，状态改变返回的哈希值仍然要一致
        equals的对称、反射、传递等特性

    同步:
    Map m = Collections.synchronizedMap(new HashMap(...));

- ConcurrentHashMap

    Hashtable比较低效，其实现基本就是将put、get、size等各种方法加上synchronized
    HashMap非线程安全的，而Collections提供的同步包装器同样低效:
    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/Collections.java
    private static class SynchronizedMap<K,V> implements Map<K,V>, Serializable {
        //...
        @SuppressWarnings("serial") // Conditionally serializable
        private final Map<K,V> m;     // Backing Map
        @SuppressWarnings("serial") // Conditionally serializable
        final Object      mutex;        // Object on which to synchronize
        //...
        public V get(Object key) {
            synchronized (mutex) {return m.get(key);}
        }
        //
        public V put(K key, V value) {
            synchronized (mutex) {return m.put(key, value);}
        }
        //...
    }

    https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/concurrent/ConcurrentHashMap.java

    Java8:
    依然是桶(bucket)数组 + 链表结构(bin)，但同步的粒度要更细
    内部仍然有Segment定义，但仅仅是为了保证序列化时的兼容性
    由于不再使用Segment，初始化操作得以大大简化，修改为lazy-load形式，避免初始化开销
    利用volatile来保证可见性
    使用CAS等操作，在特定场景进行无锁并发操作
    使用Unsafe、LongAdder等底层手段，进行极端情况的优化

- 排序
原始数据类型:
https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/DualPivotQuicksort.java
对象数据类型:
https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/TimSort.java
参考: https://mail.openjdk.org/pipermail/core-libs-dev/2018-January/051000.html
参考: https://en.wikipedia.org/wiki/Timsort

- Direct vs. non-direct buffers
The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory footprint of an application might not be obvious. It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system's native I/O operations. In general it is best to allocate direct buffers only when they yield a measureable gain in program performance.

- SPI
Java SPI实际上是"基于接口的编程＋策略模式＋约定配置文件"的组合实现的动态加载机制，在JDK中提供了java.util.ServiceLoader来实现服务查找。

=== 异常
==== 分类
Exception: https://docs.oracle.com/javase/8/docs/api/java/lang/Exception.html
Error: https://docs.oracle.com/javase/8/docs/api/java/lang/Error.html

Exception和Error都继承了Throwable类。

Exception是程序正常运行中，可以预料的意外情况，可能并且应该被捕获。

Error是指在正常情况下，不大可能出现的情况，绝大部分的Error都会导致程序(比如JVM自身)处于非正常的、不可恢复状态。Error是非正常情况，不便于也不需要捕获，常见的Error如OutOfMemoryError。

Exception又分为可检查(checked)异常和不检查(unchecked)异常:
可检查异常必须显式地进行捕获处理，是编译期检查的一部分。
不检查异常即运行时异常，例如NullPointerException、ArrayIndexOutOfBoundsException，通常是编码可以避免的逻辑错误，根据需要决定是否进行捕获，不会在编译期强制要求。

关于Checked Exception:
反对Java语言的Checked Exception的原因:
    Checked Exception假设捕获了异常，然后恢复程序，然而大多数情况下是不能恢复的；
    Checked Exception不兼容functional编程。
很多开源项目，已经采纳了这种实践，如Spring、Hibernate等，以及新的编程语言如Scala等。
参考: http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/
另一方面，有一些异常，比如和环境相关的IO、网络等，其实是存在可恢复性的。
参考: https://v.qq.com/x/page/d0635rf5x0o.html[Failing at Failing: How and Why We’ve Been Nonchalantly Moving Away From Exception Handling]

==== 实践
- 尽量不要捕获类似Exception这样的通用异常，而是应该捕获特定异常

- 不要生吞(swallow)异常，否则可能导致非常难以诊断的诡异情况
e.printStackTrace()也不合适，这是因为它prints this throwable and its backtrace to the standard error stream，而生产环境中，标准错误(stderr)不是一个合适的输出选项，很难判断错误输出到哪里了。

- throw early, catch late原则
在更高层面，具有更完整清晰的context，往往可以选择更合理的处理方式。

- 捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层使用者，必须处理异常。

- 事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。

- finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。JDK7及以上，可以使用try-with-resources方式。

- 不要在finally块中使用return
解读: try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存在return语句，则在此直接返回，将会丢弃掉try块中的返回点。
反例:
[source, java]
----
private int x = 0;
    public int checkReturn() {
    try {
        // x等于1，此处不返回
        return ++x;
    } finally {
        // 返回的结果是2
        return ++x;
    }
}
----

- 在调用RPC、二方包(一般指公司内部的依赖库)、或动态生成类的相关方法时，捕捉异常必须使用Throwable类来进行拦截。
解读: 通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，或者在字节码修改框架(比如ASM)动态创建或修改类时，修改了相应的方法签名。这些情况，即使代码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。

- 防止NPE(NullPointerException)是调用者的责任。

- 对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、errorMessage；而应用内部直接抛出异常即可。
解读: 关于RPC方法返回方式使用Result方式的理由:
1)使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。
2)如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。

参考: 《Java开发手册》异常处理

==== 性能
Java每实例化一个Exception，都会对当时的栈进行快照。如果发生的非常频繁，此开销不能被忽略。

建议仅捕获有必要的代码段，尽量不要一个大的try包住整段的代码；也不要利用异常控制代码流程。

=== 注解
https://www.geeksforgeeks.org/annotations-in-java/
https://docs.oracle.com/javase/tutorial/java/annotations/index.html.

== 内存

=== 内存区域
https://docs.oracle.com/javase/specs/jvms/se21/html/jvms-2.html#jvms-2.5

- 程序计数器(PC，Program Counter Register)
在 JVM 规范中，每个线程都有它自己的程序计数器，并且任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的 Java 方法的 JVM 指令地址；或者，如果是在执行本地方法，则是未指定值(undefined)。

- Java 虚拟机栈(Java Virtual Machine Stack)
早期也叫 Java 栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame)，对应着一次次的 Java 方法调用。前面谈程序计数器时，提到了当前方法；同理，在一个时间点，对应的只会有一个活动的栈帧，通常叫作当前帧，方法所在的类叫作当前类。如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，成为新的当前帧，一直到它返回结果或者执行结束。JVM 直接对 Java 栈的操作只有两个，就是对栈帧的压栈和出栈。栈帧中存储着局部变量表、操作数(operand)栈、动态链接、方法正常退出或者异常退出的定义等。

- 堆(Heap)
是 Java 内存管理的核心区域，用来放置 Java 对象实例，几乎所有创建的 Java 对象实例都是被直接分配在堆上。堆被所有的线程共享，在虚拟机启动时指定的"Xmx"之类参数就是用来指定最大堆空间等指标。理所当然，堆也是垃圾收集器重点照顾的区域，因此堆内空间还会被不同的垃圾收集器进行进一步的细分，最有名的就是新生代、老年代的划分。

- 方法区(Method Area)
也是所有线程共享的一块内存区域，用于存储所谓的元(Meta)数据，例如类结构信息，以及对应的运行时常量池、字段、方法代码等。由于早期的 Hotspot JVM 实现，很多人习惯于将方法区称为永久代(Permanent Generation)。Oracle JDK 8 中将永久代移除，同时增加了元数据区(Metaspace)。

- 运行时常量池(Run-Time Constant Pool)
是方法区的一部分。如果仔细分析过反编译的类文件结构，能看到版本号、字段、方法、超类、接口等各种信息，还有一项信息就是常量池。Java 的常量池可以存放各种常量信息，不管是编译期生成的各种字面量，还是需要在运行时决定的符号引用，因此它比一般语言的符号表存储的信息更加宽泛。

- 本地方法栈(Native Method Stack)
与 Java 虚拟机栈是非常相似的，支持对本地方法的调用，也是每个线程都会创建一个。在 Oracle Hotspot JVM 中，本地方法栈和Java虚拟机栈是在同一块区域，这完全取决于技术实现的决定，并未在规范中强制。

=== 堆外内存和堆内内存
- 堆内内存

    JVM GC自动回收
    新生代与老年代
    在JDK1.8版本废弃了永久代，替代的是元空间(MetaSpace)
    元空间与永久代上类似，最大区别是: 元空间并不在JVM中，而是使用本地内存。

- 堆外内存

    不受JVM管理，需要手动释放
    当进行网络I/O操作、文件读写时，堆内内存都需要转换为堆外内存，然后再与底层设备进行交互
    堆外内存可以实现进程之间、JVM多实例之间的数据共享
    分配: ByteBuffer#allocateDirect和Unsafe#allocateMemory
    https://docs.oracle.com/javase/8/docs/api/java/nio/ByteBuffer.html#allocateDirect-int-

    JVM参数-XX:MaxDirectMemorySize指定堆外内存的上限大小:
        当堆外内存的大小超过该阈值时，就会触发一次Full GC进行清理回收
        如果在Full GC之后还是无法满足堆外内存的分配，那么程序将会抛出OOM异常

=== OOM
从数据区的角度，除了程序计数器，其他区域都有可能会因为可能的空间不足发生 OutOfMemoryError：

- 堆内存不足是最常见的 OOM 原因之一，抛出的错误信息是"java.lang.OutOfMemoryError:Java heap space"，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理；或者出现 JVM 处理引用不及时，导致堆积起来，内存无法释放等。

- 对于 Java 虚拟机栈和本地方法栈，如果写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。

- 对于老版本的 Oracle JDK，因为永久代的大小是有限的，并且 JVM 对永久代垃圾回收(如，常量池回收、卸载不再需要的类型)非常不积极，所以不断添加新类型的时候，永久代出现 OutOfMemoryError 也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似 Intern 字符串缓存占用太多空间，也会导致 OOM 问题。对应的异常信息，会标记出来和永久代相关："java.lang.OutOfMemoryError: PermGen space"。

- 随着元数据区的引入，方法区内存已经不再那么窘迫，相应的 OOM 有所改观，出现 OOM，异常信息则变成了："java.lang.OutOfMemoryError: Metaspace"。

- 直接内存不足，也会导致 OOM。

=== GC

==== 原理
===== 内存释放的判定
主要就是两个方面，最主要的部分是对象实例，都是存储在堆上的；
还有就是方法区中的元数据等信息，例如类型不再使用，卸载该Java类似乎是很合理的。
对于对象实例收集，主要是两种基本算法，引用计数和可达性分析。
引用计数算法，顾名思义，就是为对象添加一个引用计数，用于记录对象被引用的情况，如果计数为0，即表示对象可回收。这是很多语言的资源回收选择，例如Python，它更是同时支持引用计数和垃圾收集机制。具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。Java并没有选择引用计数，是因为很难处理循环引用关系。
另外就是Java选择的可达性分析，Java的各种引用关系，在某种程度上，将可达性问题还进一步复杂化，这种类型的垃圾收集通常叫作追踪性垃圾收集(Tracing Garbage Collection)。其原理简单来说，就是将对象及其引用关系看作一个图，选定活动的对象作为GC Roots，然后跟踪引用链条，如果一个对象和GC Roots之间不可达，也就是不存在引用链条，那么即可认为是可回收对象。JVM会把虚拟机栈和本地方法栈中正在引用的对象、静态属性引用的对象和常量，作为GC Roots。
方法区无用元数据的回收比较复杂，一般来说初始化类加载器加载的类型是不会进行类卸载(unload)的；而普通的类型的卸载，往往是要求相应自定义类加载器本身被回收，因此大量使用动态类型的场合，需要防止元数据区(或者早期的永久代)不会OOM。

===== 常见的垃圾收集算法
主要分为三类：

- 复制(Copying)算法
例如新生代GC，基本都是基于复制算法，将活着的对象复制到to区域，拷贝过程中将对象顺序放置，就可以避免内存碎片化。代价是，既然要进行复制，既要提前预留内存空间，有一定的浪费；另外，对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，这个开销也不小，不管是内存占用或者时间开销。

- 标记-清除(Mark-Sweep)算法
首先进行标记工作，标识出所有要回收的对象，然后进行清除。这么做除了标记、清除过程效率有限，另外就是不可避免的出现碎片化问题，这就导致其不适合特别大的堆；否则，一旦出现Full GC，暂停时间可能根本无法接受。

- 标记-整理(Mark-Compact)
类似于标记-清除，但为了避免内存碎片化，它会在清理过程中将对象移动，以确保移动后的对象占用连续的内存空间。

实际GC实现过程要复杂的多，目前还在发展中的前沿GC都是复合算法，并且并行和并发兼备。

==== 垃圾收集器
垃圾收集器(GC，Garbage Collector)与具体的JVM实现紧密相关，不同厂商不同版本的JVM，提供的选择也不同。

以Oracle JDK为例:

- Serial GC
最古老的垃圾收集器，"Serial"体现在其收集工作是单线程的，并且在进行垃圾收集过程中，会进入臭名昭著的"Stop-The-World"状态。当然，其单线程设计也意味着精简的 GC 实现，无需维护复杂的数据结构，初始化也简单，因此一直是 Client 模式下 JVM 的默认选项。从年代的角度，通常将其老年代实现单独称作 Serial Old，它采用了标记-整理(Mark-Compact)算法，区别于新生代的复制算法。
对应 JVM 参数: -XX:+UseSerialGC

- ParNew GC
新生代 GC 实现，实际是 Serial GC 的多线程版本，最常见的应用场景是配合老年代的 CMS GC 工作
对应 JVM 参数: -XX:+UseConcMarkSweepGC -XX:+UseParNewGC

- CMS(Concurrent Mark Sweep) GC
基于标记-清除(Mark-Sweep)算法，设计目标是尽量减少停顿时间，适合Web等反应时间敏感的应用，一直到今天，仍然有很多系统使用 CMS GC。但是，CMS 采用的标记-清除算法，存在着内存碎片化问题，难以避免在长时间运行等情况下发生 full GC，导致恶劣的停顿。另外，既然强调了并发(Concurrent)，CMS 会占用更多 CPU 资源，并和用户线程争抢。

- Parallel GC
在早期 JDK 8 等版本中，它是 server 模式 JVM 的默认 GC 选择，也被称作是吞吐量优先的 GC。它的算法和 Serial GC 比较相似，尽管实现要复杂的多，其特点是新生代和老年代 GC 都是并行进行的，在常见的服务器环境中更加高效。开启选项是：-XX:+UseParallelGC
另外，Parallel GC 引入了开发者友好的配置项，可以直接设置暂停时间或吞吐量等目标，JVM 会自动进行适应性调整，例如参数: 
-XX:MaxGCPauseMillis=value
-XX:GCTimeRatio=N // GC时间和用户时间比例 = 1 / (N+1)

- G1 GC
是一种兼顾吞吐量和停顿时间的 GC 实现，是 Oracle JDK 9 以后的默认 GC 选项。G1 可以直观的设定停顿时间的目标，相比于 CMS GC，G1 未必能做到 CMS 在最好情况下的延时停顿，但是最差情况要好很多。G1 GC 仍然存在着年代的概念，但是其内存结构并不是简单的条带式划分，而是类似棋盘的一个个 region。Region 之间是复制算法，但整体上实际可看作是标记-整理(Mark-Compact)算法，可以有效地避免内存碎片，尤其是当 Java 堆非常大的时候，G1 的优势更加明显。G1 吞吐量和停顿表现都非常不错，并且仍然在不断地完善，与此同时 CMS 已经在 JDK 9 中被标记为废弃(deprecated)。

==== JVM GC事件
把GC清除堆不同区域的触发事件分为以下几种:

    Minor GC 从年轻代空间回收称为次要GC
    Major GC 从年老代空间回收主要GC
    Full GC 清理整个堆空间，包括年轻代和年老代

==== 命令
查看: jinfo -flags $PID

== concurrency
=== 介绍
Threads are sometimes called lightweight processes, and most modern operating systems treat threads, not processes, as the basic units of scheduling.

Benefits of threads:
1. Exploiting multiple processors
2. Simplicity of modeling
A complicated, asynchronous workflow can be decomposed into a number of simpler, synchronous workflows each running in a separate thread, interacting only with each other at specific synchronization points.
3. Simplified handling of asynchronous events
4. More responsive user interfaces

Risks of threads:
1. Safety hazards
Thread safety can be unexpectedly subtle because, in the absence of sufficient synchronization, the ordering of operations in multiple threads is unpredictable and sometimes surprising.
2. Liveness hazards
safety means "nothing bad ever happens"
liveness concerns the complementary goal that "something good eventually happens"
For example, if thread A is waiting for a resource that thread B holds exclusively, and B never releases it, A will wait forever.
3. Performance hazards
When threads share data, they must use synchronization mechanisms that can inhibit compiler optimizations, flush or invalidate memory caches, and create synchronization traffic on the shared memory bus. All these factors introduce additional performance costs.

Threads are everywhere:
When the JVM starts, it creates threads for JVM housekeeping tasks (garbage collection, finalization) and a main thread for running the main method.
The AWT (Abstract Window Toolkit) and Swing user interface frameworks create threads for managing user interface events.
Timer creates threads for executing deferred tasks.
Component frameworks, such as servlets and RMI create pools of threads and invoke component methods in these threads.

=== 线程安全
If multiple threads access the same mutable state variable without appropriate synchronization, your program is broken. There are three ways to fix it:
• Don’t share the state variable across threads;
• Make the state variable immutable; or
• Use synchronization whenever accessing the state variable.

什么是线程安全:
Thread-safe classes encapsulate any needed synchronization so that clients need not provide their own.
Example: a stateless servlet
[source, java]
----
@ThreadSafe
public class StatelessFactorizer implements Servlet {
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        encodeIntoResponse(resp, factors);
    }
}
----
Stateless objects are always thread-safe.

Atomicity原子性:
[source, java]
----
@NotThreadSafe
public class UnsafeCountingFactorizer implements Servlet {
    private long count = 0;
    public long getCount() { return count; }
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        ++count; //not thread safe
        encodeIntoResponse(resp, factors);
    }
}
----
race conditions:
[source, java]
----
@NotThreadSafe
public class LazyInitRace {
    private ExpensiveObject instance = null;
    public ExpensiveObject getInstance() {
        if (instance == null)
        instance = new ExpensiveObject();
        return instance;
    }
}
----

[source, java]
----
@ThreadSafe
public class CountingFactorizer implements Servlet {
    private final AtomicLong count = new AtomicLong(0);
    public long getCount() { return count.get(); }
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        count.incrementAndGet();
        encodeIntoResponse(resp, factors);
    }
}
----
Where practical, use existing thread-safe objects, like AtomicLong, to manage your class’s state.

Locking:
[source, java]
----
public class Widget {
    public synchronized void doSomething() {
        ...
    }
}
public class LoggingWidget extends Widget {
    public synchronized void doSomething() {
        System.out.println(toString() + ": calling doSomething");
        super.doSomething();
    }
}
----
Code that would deadlock if intrinsic locks were not reentrant.

Guarding state with locks

Liveness and performance:
There is frequently a tension between simplicity and performance. When implementing a synchronization policy, resist the temptation to prematurely sacrifice simplicity (potentially compromising safety) for the sake of performance.
Avoid holding locks during lengthy computations or operations at risk of not completing quickly such as network or console I/O.

=== Sharing Objects
==== Visibility
可见性
always use the proper synchronization whenever data is shared across threads.
Locking is not just about mutual exclusion; it is also about memory visibility. To ensure that all threads see the most up-to-date values of shared mutable variables, the reading and writing threads must synchronize on a common lock.

Volatile variables:
Use volatile variables only when they simplify implementing and verifying your synchronization policy; avoid using volatile variables when veryfing correctness would require subtle reasoning about visibility. Good uses of volatile variables include ensuring the visibility of their own state, that of the object they refer to, or indicating that an important lifecycle event (such as initialization or shutdown) has occurred.
Locking can guarantee both visibility and atomicity; volatile variables can only guarantee visibility.
You can use volatile variables only when all the following criteria are met:
• Writes to the variable do not depend on its current value, or you can ensure that only a single thread ever updates the value;
• The variable does not participate in invariants with other state variables;
and
• Locking is not required for any other reason while the variable is being accessed.

==== Publication and escape
Publishing an object means making it available to code outside of its current scope, such as by storing a reference to it where other code can find it, returning it from a nonprivate method, or passing it to a method in another class ...
An object that is published when it should not have been is said to have escaped.

==== Thread confinement
线程约束
• Ad-hoc thread confinement(特定目的线程约束)
The decision to use thread confinement is often a consequence of the decision to implement a particular subsystem, such as the GUI, as a single-threaded subsystem.
A special case of thread confinement applies to volatile variables.
建议:
Because of its fragility, ad-hoc thread confinement should be used sparingly; if possible, use one of the stronger forms of thread confinment (stack confinement or ThreadLocal) instead.
• Stack confinement
Stack confinement is a special case of thread confinement in which an object can only be reached through local variables.
Stack confinement (also called within-thread or thread-local usage, but not to be confused with the ThreadLocal library class) is simpler to maintain and less fragile than ad-hoc thread confinement.
• ThreadLocal
ThreadLocal provides get and set accessor methods that maintain a separate copy of the value for each thread that uses it, so a get returns the most recent value passed to set from the currently executing thread.
[source, java]
----
private static ThreadLocal<Connection> connectionHolder
    = new ThreadLocal<Connection>() {
        public Connection initialValue() {
            return DriverManager.getConnection(DB_URL);
        }
    };

public static Connection getConnection() {
    return connectionHolder.get();
}
----

==== Immutability
An object is immutable if:
• Its state cannot be modified after construction;
• All its fields are final;
• It is properly constructed (the this reference does not escape during construction).
[source, java]
.Immutable class built out of mutable underlying objects.
----
@Immutable
public final class ThreeStooges {
    private final Set<String> stooges = new HashSet<String>();
        public ThreeStooges() {
        stooges.add("Moe");
        stooges.add("Larry");
        stooges.add("Curly");
    }

    public boolean isStooge(String name) {
        return stooges.contains(name);
    }
}
----

Final fields:
Even if an object is mutable, making some fields final can still simplify reasoning about its state, since limiting the mutability of an object restricts its set of possible states. An object that is "mostly immutable" but has one or two mutable state variables is still simpler than one that has many mutable variables.
it is a good practice to make all fields private unless they need greater visibility, it is a good practice to make all fields final unless they need to be mutable.

==== Safe publication
Immutable objects can be used safely by any thread without additional synchronization, even when synchronization is not used to publish them.
To publish an object safely, both the reference to the object and the object’s state must be made visible to other threads at the same time. A properly constructed object can be safely published by:
• Initializing an object reference from a static initializer;
• Storing a reference to it into a volatile field or AtomicReference;
• Storing a reference to it into a final field of a properly constructed object; or
• Storing a reference to it into a field that is properly guarded by a lock.

Effectively immutable objects:
Objects that are not technically immutable, but whose state will not be modified after publication, are called effectively immutable.
Safely published effectively immutable objects can be used safely by any thread without additional synchronization.

Mutable objects:
The publication requirements for an object depend on its mutability:
• Immutable objects can be published through any mechanism;
• Effectively immutable objects must be safely published;
• Mutable objects must be safely published, and must be either thread-safe or guarded by a lock.

=== Composing Objects
Designing a thread-safe class
Instance confinement
Delegating thread safety
Adding functionality to existing thread-safe classes
Documenting synchronization policies

=== Building Blocks
==== Synchronized collections
java.util.Collections.synchronizedXxx factory methods

Problems with synchronized collections
Iterators and ConcurrentModificationException
Hidden iterators

==== Concurrent collections
Java 5.0 improves on the synchronized collections by providing several concurrent collection classes. Synchronized collections achieve their thread safety by serializing all access to the collection’s state. The cost of this approach is poor concurrency; when multiple threads contend for the collection-wide lock, throughput suffers.

Replacing synchronized collections with concurrent collections can offer dramatic scalability improvements with little risk.

==== Blocking queues and the producer-consumer pattern
Work stealing can be more scalable than a traditional producer-consumer design because workers don’t contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another’s queue, it does so from the tail rather than the head, further reducing contention.
Work stealing is well suited to problems in which consumers are also producers—when performing a unit of work is likely to result in the identification of more work. For example, processing a page in a web crawler usually results in the identification of new pages to be crawled. Similarly, many graph-exploring algorithms, such as marking the heap during garbage collection, can be efficiently parallelized using work stealing. When a worker identifies a new unit of work, it places it at the end of its own deque (or alternatively, in a work sharing design, on that of another worker); when its deque is empty, it looks for work at the end of someone else’s deque, ensuring that each worker stays busy.

==== Blocking and interruptible methods
Interruption is a cooperative mechanism.

When your code calls a method that throws InterruptedException, then your method is a blocking method too, and must have a plan for responding to interruption. For library code, there are basically two choices:
1. Propagate the InterruptedException. This is often the most sensible policy if you can get away with it—just propagate the InterruptedException to your caller. This could involve not catching InterruptedException, or catching it and throwing it again after performing some brief activity-specific cleanup.
2. Restore the interrupt. Sometimes you cannot throw InterruptedException, for instance when your code is part of a Runnable. In these situations, you must catch InterruptedException and restore the interrupted status by calling interrupt on the current thread, so that code higher up the call stack can see that an interrupt was issued, as demonstrated:
[source, java]
.Restoring the interrupted status so as not to swallow the interrupt.
----
public class TaskRunnable implements Runnable {
    BlockingQueue<Task> queue;
    ...
    public void run() {
        try {
            processTask(queue.take());
        } catch (InterruptedException e) {
            // restore interrupted status
            Thread.currentThread().interrupt();
        }
    }
}
----
But there is one thing you should not do with InterruptedException—catch it and do nothing in response. This deprives code higher up on the call stack of the opportunity to act on the interruption, because the evidence that the thread was interrupted is lost. The only situation in which it is acceptable to swallow an interrupt is when you are extending Thread and therefore control all the code higher up on the call stack.

==== Synchronizers
CountDownLatch: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CountDownLatch.html
FutureTask: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/FutureTask.html
Semaphore: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Semaphore.html
CyclicBarrier: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CyclicBarrier.html
Phaser: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Phaser.html
Exchanger: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Exchanger.html

=== Task Execution
==== Executing tasks in threads
Ideally, tasks are independent activities: work that doesn’t depend on the state, result, or side effects of other tasks.

==== The Executor framework
Executor may be a simple interface, but it forms the basis for a flexible and powerful framework for asynchronous task execution that supports a wide variety of task execution policies. It provides a standard means of decoupling task submission from task execution, describing tasks with Runnable. The Executor implementations also provide lifecycle support and hooks for adding statistics gathering, application management, and monitoring.
Executor is based on the producer-consumer pattern, where activities that submit tasks are the producers (producing units of work to be done) and the threads that execute tasks are the consumers (consuming those units of work).

Execution policies:
• In what thread will tasks be executed?
• In what order should tasks be executed (FIFO, LIFO, priority order)?
• How many tasks may execute concurrently?
• How many tasks may be queued pending execution?
• If a task has to be rejected because the system is overloaded, which task should be selected as the victim, and how should the application be notified?
• What actions should be taken before or after executing a task?

Whenever you see code of the form: new Thread(runnable).start()
and you think you might at some point want a more flexible execution policy, seriously consider replacing it with the use of an Executor.

Thread pools

Executor lifecycle

Delayed and periodic tasks

Executors提供了5种不同的线程池创建配置:
newCachedThreadPool()，它是一种用来处理大量短时间工作任务的线程池：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过60秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。
newFixedThreadPool(int nThreads)，重用指定数目nThreads的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目nThreads。
newSingleThreadExecutor()，工作线程数目被限制为1，操作一个无界的工作队列，它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。
newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。
newWorkStealingPool(int parallelism)，Java 8才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。

==== Finding exploitable parallelism
Result-bearing tasks: Callable and Future

CompletionService: Executor meets BlockingQueue

Placing time limits on tasks

=== Cancellation and Shutdown
Java does not provide any mechanism for safely forcing a thread to stop what it is doing. Instead, it provides interruption, a cooperative mechanism that lets one thread ask another to stop what it is doing.

==== Task cancellation
There are a number of reasons why you might want to cancel an activity: user-requested, cancellation, time-limited activities, application events, errors, shutdown.

There is no safe way to preemptively stop a thread in Java, and therefore no safe way to preemptively stop a task. There are only cooperative mechanisms, by which the task and the code requesting cancellation follow an agreed-upon protocol.

=== Applying Thread Pools
==== Implicit couplings between tasks and execution policies
While the Executor framework offers substantial flexibility in specifying and modifying execution policies, not all tasks are compatible with all execution policies. Types of tasks that require specific execution policies include:
    Dependent tasks
    Tasks that exploit thread confinement
    Response-time-sensitive tasks
    Tasks that use ThreadLocal

Thread pools work best when tasks are homogeneous and independent.

==== Sizing thread pools
Sizing thread pools is not an exact science, but fortunately you need only
avoid the extremes of "too big" and "too small".

    Given these definitions:
        Ncpu = number of CPUs
        Ucpu = target CPU utilization, 0 ≤ Ucpu ≤ 1
        W/C = ratio of wait time to compute time
    The optimal pool size for keeping the processors at the desired utilization is:
    Nthreads = Ncpu ∗ Ucpu ∗ (1 + W/C)
    int N_CPUS = Runtime.getRuntime().availableProcessors();

=== Java-Memory-Model-and-Thread
==== 概念
- 内存模型
可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。

- JSR-133
Java Memory Model and Thread Specification Revision(Java内存模型和线程规范修订)
https://download.oracle.com/otndocs/jcp/memory_model-1.0-prd-oth-G-F/

==== Java内存模型
===== 主内存与工作内存
Java内存模型规定了所有的变量都存储在主内存(Main Memory)中(此处的主内存与介绍物理硬件时提到的主内存名字一样，两者也可以类比，但物理上它仅是虚拟机内存的一部分)。

每条线程还有自己的工作内存(Working Memory，可与前面讲的处理器高速缓存类比)，线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的数据。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

===== 内存间交互操作

===== volatile
====== 作用
volatile是Java虚拟机提供的最轻量级的同步机制，但是它并不容易被正确、完整地理解。

- 保证变量的可见性
线程读变量能读到它在内存中的最新的值，也就是说不同的线程看到的一个变量的值是相同的。CPU都是有行缓存的，volatile能让行缓存无效，因此能读到内存中最新的值。

- 保证赋值操作的原子性
有些变量的赋值本身就是原子性的，例如boolean，int，但是对于long或者double则不一定，例如32位的处理器，对于64位的变量的操作可能会被分解成为高32位和低32位，从而导致线程不安全。如果变量声明为volatile，那么虚拟机会保证赋值是原子的，是不可被打断的。

- 禁止指令重排
正常情况下，虚拟机会对指令进行重排，当然是在不影响程序结果的正确性的前提下。volatile能够在一定程度上禁止虚拟机进行指令重排。还有就是对于volatile变量的写操作，保证是在读操作之前完成，假设线程A来读变量，刚好线程B正在写变量，那么虚拟机会保证写在读之前完成。

====== 注意事项
由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，仍然要通过加锁来保证原子性：

  运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值
  变量不需要与其它的状态变量共同参与不变约束

  例如volatile int race，执行race++操作，并不线程安全

====== 实现
[source, cpp]
.https://github.com/openjdk/jdk/blob/master/src/hotspot/os_cpu/linux_x86/orderAccess_linux_x86.hpp
----
// A compiler barrier, forcing the C++ compiler to invalidate all memory assumptions
static inline void compiler_barrier() {
  __asm__ volatile ("" : : : "memory");
}

inline void OrderAccess::loadload()   { compiler_barrier(); }
inline void OrderAccess::storestore() { compiler_barrier(); }
inline void OrderAccess::loadstore()  { compiler_barrier(); }
inline void OrderAccess::storeload()  { fence();            }

inline void OrderAccess::acquire()    { compiler_barrier(); }
inline void OrderAccess::release()    { compiler_barrier(); }

inline void OrderAccess::fence() {
   // always use locked addl since mfence is sometimes expensive
#ifdef AMD64
  __asm__ volatile ("lock; addl $0,0(%%rsp)" : : : "cc", "memory");
#else
  __asm__ volatile ("lock; addl $0,0(%%esp)" : : : "cc", "memory");
#endif
  compiler_barrier();
}

inline void OrderAccess::cross_modify_fence() {
  int idx = 0;
#ifdef AMD64
  __asm__ volatile ("cpuid " : "+a" (idx) : : "ebx", "ecx", "edx", "memory");
#else
  // On some x86 systems EBX is a reserved register that cannot be
  // clobbered, so we must protect it around the CPUID.
  __asm__ volatile ("xchg %%esi, %%ebx; cpuid; xchg %%esi, %%ebx " : "+a" (idx) : : "esi", "ecx", "edx", "memory");
#endif
}
----

===== 针对long和double型变量的特殊规则
对于64位的数据类型(long和double)，在模型中特别定义了一条宽松的规定：允许虚拟机将没有
被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性，这就是所谓的"long和double的非原子性协定"(Non-Atomic Treatment of double and long Variables)。

如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既不是原值，也不是其他线程修改值的代表了"半个变量"的数值。不过这种读取到"半个变量"的情况是非常罕见的，经过实际测试，在目前主流平台下商用的64位Java虚拟机中并不会出现非原子性访问行为，但是对于32位的Java虚拟机，譬如比较常用的32位x86平台下的HotSpot虚拟机，对long类型的数据确实存在非原子性访问的风险。

在实际开发中，除非该数据有明确可知的线程竞争，否则在编写代码时一般不需要因为这个原因刻意把用到的long和double变量专门声明为volatile。

===== 原子性、可见性与有序性
====== 原子性
基本数据类型的访问、读写都是具备原子性的(例外就是long和double的非原子性协定)。
更大范围的原子性保证，Java内存模型提供了lock和unlock操作，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，反映到代码中就是同步块-synchronized关键字，即在synchronized块之间的操作也具备原子性。

====== 可见性
可见性就是指当一个线程修改了共享变量的值时，其它线程能够立即得知这个修改。

Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此。普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。

除了volatile之外，Java还有两个关键字能实现可见性，它们是synchronized和final。同步块的可见性是由对一个变量执行unlock操作之前，必须先把此变量同步回主内存中(执行store、write操作)的规则获得的。而final关键字的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把"this"的引用传递出去(this引用逃逸是一件很危险的事情，其它线程有可能通过这个引用访问到"初始化了一半"的对象)，那么在其它线程中就能看见final字段的值。
参考: https://en.wikipedia.org/wiki/Java_concurrency#Final_fields

====== 有序性
Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指"线程内似表现为串行的语义"(Within-Thread As-If-SerialSemantics)，后半句是指"指令重排序"现象和"工作内存与主内存同步延迟"现象。

Java提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由"一个变量在同一个时刻只允许一条线程对其进行lock操作"这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。

===== 先行发生(Happens-Before)
happen-before关系，是Java内存模型中保证多线程操作可见性的机制，也是对早期语言规范中含糊的可见性概念的一个精确定义。

先行发生是Java内存模型中定义的两项操作之间的偏序关系，比如说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，"影响"包括修改了内存中共享变量的值、发送了消息、调用了方法等。

Java语言无须任何同步手段保障就能成立的先行发生规则有且只有:

- 程序次序规则(Program Order Rule)
在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。

- 管程锁定规则(Monitor Lock Rule)
一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是"同一个锁"，而"后面"是指时间上的先后。

- volatile变量规则(Volatile Variable Rule)
对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的"后面"同样是指时间上的先后。

- 线程启动规则(Thread Start Rule)
Thread对象的start()方法先行发生于此线程的每一个动作。

- 线程终止规则(Thread Termination Rule)
线程中的所有操作都先行发生于对此线程的终止检测，可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。

- 线程中断规则(Thread Interruption Rule)
对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。

- 对象终结规则(Finalizer Rule)
一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。

- 传递性(Transitivity)
如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

// 以下操作在同一个线程中执行
int i = 1;
int j = 2;
两条赋值语句在同一个线程之中，根据程序次序规则，int i = 1的操作先行发生于int j = 2，但是int j = 2的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为在这条线程之中没有办法感知到这一点。

注意，时间先后顺序与先行发生原则之间基本没有因果关系，衡量并发安全问题的时候不要受时间顺序的干扰，一切必须以先行发生原则为准。

==== Java与线程

===== 实现
实现线程主要有三种方式:

    使用内核线程实现(1：1实现)
    使用用户线程实现(1：N实现)
    使用用户线程加轻量级进程混合实现(N：M实现)

早期的Classic虚拟机上(JDK 1.2以前)，是基于一种被称为绿色线程(Green Threads)的用户线程实现的
从JDK 1.3起，主流平台上的商用Java虚拟机的线程模型普遍都被替换为基于操作系统原生线程模型来实现，即采用1：1的线程模型。以HotSpot为例，其每一个Java线程都是直接映射到一个操作系统原生线程来实现的，中间没有额外的间接结构，调度等都是由操作系统全权决定。

===== 调度
线程调度是指系统为线程分配处理器使用权的过程，调度主要方式有两种:
协同式Cooperative Threads-Scheduling线程调度与抢占式Preemptive Threads-Scheduling线程调度。

Java线程调度是系统自动完成的，应用可以设置线程优先级，通常优先级越高的线程越容易被系统选择执行。

===== 状态
https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.State.html

    NEW
        A thread that has not yet started is in this state.
    RUNNABLE
        A thread executing in the Java virtual machine is in this state.
    BLOCKED
        A thread that is blocked waiting for a monitor lock is in this state.
    WAITING
        A thread that is waiting indefinitely for another thread to perform a particular action is in this state.
    TIMED_WAITING
        A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state.
    TERMINATED
        A thread that has exited is in this state.

Q: 一个线程两次调用start()方法会出现什么情况？
A: Java的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException(运行时异常)。因为在第二次调用 start()方法的时候，线程可能处于终止或者其它(非NEW)状态。

守护线程:

    Thread daemonThread = new Thread();
    daemonThread.setDaemon(true);
    daemonThread.start();

==== 参考
https://en.wikipedia.org/wiki/Java_concurrency#Memory_model
《深入理解Java虚拟机: JVM高级特性与最佳实践(第3版)》第12章 Java内存模型与线程
https://download.oracle.com/otndocs/jcp/memory_model-1.0-prd-oth-G-F/
https://en.wikipedia.org/wiki/Java_memory_model
http://gee.cs.oswego.edu/dl/jmm/cookbook.html

=== virtual thread
==== 概念
==== 历史
since JDK19, JDK 21(September 2023) release.
https://openjdk.org/jeps/444 JEP 444: Virtual Threads
https://openjdk.org/jeps/436 JEP 436: Virtual Threads (Second Preview)
https://openjdk.org/jeps/425 JEP 425: Virtual Threads (Preview)

==== 参考
https://mail.openjdk.org/pipermail/loom-dev/2019-November/000876.html

=== API
- java.util.concurrent
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/package-summary.html

- java.util.concurrent.locks
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/locks/package-summary.html

- java.util.concurrent.atomic
https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/atomic/package-summary.html

并发包也就是java.util.concurrent及其子包，集中了Java并发的各种基础工具类，主要包括：
1. 提供了比synchronized更加高级的各种同步结构，包括CountDownLatch、CyclicBarrier、Semaphore等，可以实现更加丰富的多线程操作。
2. 各种线程安全的容器，比如ConcurrentHashMap、有序的ConcurrentSkipListMap，或者通过类似快照机制，实现线程安全的动态数组CopyOnWriteArrayList等。
3. 各种并发队列实现，如各种BlockingQueue实现，比较典型的ArrayBlockingQueue、SynchronousQueue或针对特定场景的 PriorityBlockingQueue等。
4. Executor框架，可以创建各种不同类型的线程池，调度任务运行等，绝大部分情况下，不再需要自己实现线程池和任务调度器。

Q: 为什么并发容器里面没有ConcurrentTreeMap？
A: 基于红黑树的TreeMap要实现高效的线程安全是非常困难的。

Q: ConcurrentLinkedQueue与LinkedBlockingQueue有什么区别？
A: ConcurrentLinkedQueue等Concurrent类型基于lock-free，在常见的多线程访问场景，一般可以提供较高吞吐量。而LinkedBlockingQueue则是基于锁，并提供了BlockingQueue的等待性方法。

java.util.concurrent包提供的容器Queue、List、Set、Map，从命名上可以大概区分为Concurrent、CopyOnWrite和Blocking三类，同样是线程安全容器，Concurrent类型没有类似CopyOnWrite之类容器相对较重的修改开销，但是Concurrent只能提供较低的遍历一致性，即所谓的弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历。与弱一致性对应的，就是同步容器常见的fail-fast，即当检测到容器在遍历过程中发生了修改，则抛出ConcurrentModificationException，不再继续遍历。弱一致性还有其它的体现，例如size等操作的准确性是有限的。

=== Q&A
==== synchronized与ReentrantLock
synchronized是Java内建的同步机制，也称Intrinsic Locking，它提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他试图获取的线程只能等待或者阻塞在那里。Java 5以前synchronized是仅有的同步手段。

Java 5提供的ReentrantLock，语义与synchronized基本相同。
ReentrantLock能够实现更多细节控制，比如可以控制fairness，或者利用定义条件等。
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/ReentrantLock.html

早期版本的synchronized在很多场景下与ReentrantLock性能相差较大，在后续版本进行了较多改进，在低竞争场景中表现可能优于ReentrantLock。

关于公平性:
公平性是指在竞争场景中，当公平性为真时，会倾向于将锁赋予等待时间最久的线程。公平性会引入额外开销，只有确实有公平性需要的时候，才有必要指定。
指定方式: ReentrantLock(boolean fair)

==== synchronized
synchronized代码块是由monitorenter/monitorexit指令实现的，Monitor对象是同步的基本实现单元。

Java 6之前，Monitor的实现完全依靠操作系统内部的互斥锁，需要进行用户态到内核态的切换，是一个重量级操作。

现在JVM提供了三种不同的Monitor实现，即: 偏斜锁(Biased Locking)、轻量级锁和重量级锁。

锁的升级、降级，就是JVM优化synchronized运行的机制，当JVM检测到不同的竞争状况时，会自动切换到适合的锁实现:
没有竞争出现时，默认会使用偏斜锁。JVM会利用CAS操作(compare and swap)，在对象头上的Mark Word部分设置线程ID，表示该对象偏向于当前线程，因此并不涉及真正的互斥锁。其假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。
如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM就需要撤销(revoke)偏斜锁，并切换到轻量级锁实现。轻量级锁依赖CAS操作Mark Word来试图获取锁，如果重试成功，就使用普通的轻量级锁；否则，进一步升级为重量级锁。

==== 条件变量
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/Condition.html

==== StampedLock
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/StampedLock.html
https://stackoverflow.com/questions/26094200/what-is-stampedlock-in-java

==== ThreadLocal
https://docs.oracle.com/javase/8/docs/api/java/lang/ThreadLocal.html

==== 死锁
https://github.com/orientye/understand/blob/main/high/concurrency/lock.asc#dead-lock

==== BlockingQueue
是否有界(Bounded、Unbounded)
ArrayBlockingQueue是典型的的有界队列，其内部以final的数组保存数据，数组的大小就决定了队列的边界。
LinkedBlockingQueue容易被误解为无边界，但其实是基于有界的逻辑实现的，如果没有在创建队列时就指定容量，则默认为Integer.MAX_VALUE，变成了无界队列。
SynchronousQueue是一个非常奇葩的队列实现，每个删除操作都要等待插入操作，反之每个插入操作也都要等待删除动作。其队列的容量是0。
PriorityBlockingQueue是无边界的优先队列。
DelayedQueue和LinkedTransferQueue同样是无边界的队列。
对于无边界的队列，put操作永远也不会发生其它BlockingQueue的那种等待情况。

参考: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/BlockingQueue.html

==== AbstractQueuedSynchronizer
https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/AbstractQueuedSynchronizer.html

AbstractQueuedSynchronizer(AQS)是Java并发包中实现各种同步结构与部分其它组成单元(如线程池中的Worker)的基础。
AbstractQueuedSynchronizer(AQS) provides common underlying functionality:
- Expressed in terms of acquire/release operations
Implements a concrete synch scheme 
- Structured using a variant of GoF template-method pattern
Synchronizer classes define only the code expressing rules for when it is permitted to acquire and release. 
- Doesn't try to work for all possible synchronizers, but enough to be both efficient and widely useful
Phasers, Exchangers don't use AQS

参考: http://www.sti.uniurb.it/events/sfm15mp/slides/lea.2.pdf[The Design and Engineering of Concurrency Libraries]

实现:
https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/concurrent/locks/AbstractQueuedSynchronizer.java

AQS内部数据和方法，可以简单拆分为：
状态，private volatile int state;
一个等待线程队列，以实现多线程间竞争和等待，这是AQS机制的核心之一;
各种基于CAS的基础操作方法，以及各种期望具体同步结构去实现的acquire/release方法。

==== servlet
https://stackoverflow.com/questions/3106452/how-do-servlets-work-instantiation-sessions-shared-variables-and-multithreadi

=== 最佳实践

=== 参考
《Java Concurrency in Practice》

== 热更新
- Javassist(Java Programming Assistant)
https://github.com/jboss-javassist/javassist

- Byte Buddy
https://github.com/raphw/byte-buddy

- java.lang.instrument.Instrumentation redefineClasses()

- 参考
https://www.zhihu.com/question/61040749

== JVM

=== Loading, Linking, and Initializing
加载阶段将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构(Class 对象)，这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。加载阶段是用户参与的阶段，可以自定义类加载器，去实现自己的类加载过程。

链接是把原始的类定义信息平滑地转化入JVM运行的过程中。可进一步细分为三个步骤：验证(Verification)，防止恶意信息或者不合规的信息危害JVM的运行，验证阶段有可能触发更多class的加载。准备(Preparation)，创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的"初始化"和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。解析(Resolution)，在这一步会将常量池中的符号引用(symbolic reference)替换为直接引用。

初始化真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。

https://docs.oracle.com/javase/specs/jvms/se21/html/jvms-5.html

双亲委派机制:
JDK8:
启动类加载器(Bootstrap Class-Loader)，加载jre/lib下面的jar文件，如rt.jar
扩展类加载器(Extension or Ext Class-Loader)，加载jre/lib/ext/目录下面的jar包
应用类加载器(Application or App Class-Loader)，加载classpath的内容
JDK9:
由于Jigsaw项目引入了Java平台模块化系统(JPMS)，Java SE的源代码被划分为一系列模块，类加载器等都发生了非常大的变化。

=== GraalVM

=== 参考
https://docs.oracle.com/javase/specs/

== 性能优化

=== GC优化
GC调优通常关注三个方面: 内存占用(footprint)、延时(latency)和吞吐量(throughput)，大多数情况下调优会侧重于其中一个或者两个方面的目标，很少有情况可以兼顾三个不同的角度。也可能需要考虑其它GC相关的场景，例如，OOM/应用启动速度等。

参考:
https://docs.oracle.com/en/java/javase/21/gctuning/garbage-first-garbage-collector-tuning.html
https://tech.meituan.com/2017/12/29/jvm-optimize.html

=== JIT

=== 参考
《Java性能优化权威指南》

== 工具
=== lombok
https://projectlombok.org/
https://projectlombok.org/features/

=== maven
https://maven.apache.org/

=== Java Agent
https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/package-summary.html

=== 监控与分析
自带命令: jps、jstat、jstack、jmap
visualvm: https://visualvm.github.io/download.html

第三方在线监控工具:
arthas: https://github.com/alibaba/arthas/blob/master/README_CN.md
skywalking: https://github.com/apache/skywalking

jmc:
https://www.oracle.com/java/technologies/jdk-mission-control.html
一般不建议生产系统进行Profiling，大多数是在性能测试阶段进行。当生产系统确实存在这种需求时，建议使用JFR配合JMC来做Profiling，因为它是从Hotspot JVM内部收集底层信息，并经过了大量优化，性能开销非常低，通常低于2%。
https://github.com/openjdk/jmc

jfr(Java Flight Recorder):
https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm

=== 代码分析
https://github.com/pmd/pmd

=== jlink
https://docs.oracle.com/en/java/javase/11/tools/jlink.html

=== 反编译
https://github.com/skylot/jadx

== 实战
=== 日志
https://tech.meituan.com/2022/07/29/tips-for-avoiding-log-blocking-threads.html

=== docker

== 参考
https://github.com/akullpp/awesome-java
https://docs.oracle.com/en/java/javase/index.html
极客时间《Java 核心技术面试精讲》
《深入理解Java虚拟机: JVM高级特性与最佳实践(第3版)》