:hardbreaks-option:

=== 线程安全
==== 定义
线程安全有不止一种定义，而且互不兼容。
《Java Concurrency in Practice》里定义，一个线程安全的class应当满足以下三个条件:
• 多个线程同时访问时，其表现出正确的行为
• 无论操作系统如何调度这些线程，无论这些线程的执行顺序如何交织(interleaving)
• 调用端代码无须额外的同步或其他协调动作

依据这个定义，C++标准库里的大多数class都不是线程安全的，包括std::string、std::vector、std::map、std::shared_ptr等等

而C系统库大多数函数是线程安全的，包括malloc/free/printf/gettimeofday等等。
gethostbyname通常不是线程安全，但FreeBSD的实现用了thread local storage，因此是安全的。
至于read/write同一个fd是不是线程安全，按POSIX定义是，按程序语义则不一定(因为有可能出现short read/short write); 从实现看，Linux 3.14之前的write不是线程安全，多线程写有overlap的可能，3.14之后才是安全的。

另外一种定义，同一类型的多个对象能分别被各自所属的不同线程并发访问，就算是线程安全的。在这个定义下，C++标准库容器和基本类型都是"线程安全的"。为了与前一种定义区别，这个一般叫做thread compatible。

线程安全需要保证几个基本特性:

        原子性: 相关操作不会中途被其它线程干扰
        可见性: 一个线程修改了某个共享变量，其状态能够被其它线程知晓，通常被解释为将线程本地状态反映到主内存上
        有序性: 保证线程内串行语义，避免指令重排等
    或者说:
        原子性: 确保一个线程的操作不会因另一个线程的干扰而只完成一半
        可见性: 更改最终会被看到
        有序性: 更改以可预测的顺序被看到

thread safe的级别(其实意义不大):
按照 https://docs.oracle.com/cd/E19683-01/806-6867/6jfpgdco5/index.html 的划分
假设有一个公共卫生间：
Unsafe：没有门锁，任何人可随时进入 → 混乱
Serializable：整个卫生间一把大锁，一次只进一人 → 安全但低效
MT-Safe：每个隔间有自己的锁，多人可同时使用不同隔间 → 既安全又高效

参考:
https://en.wikipedia.org/wiki/Thread_safety
https://www.zhihu.com/question/23244293/answer/24032098

==== race condition
https://en.wikipedia.org/wiki/Race_condition
多个进程或线程同时操作共享资源，且最终执行结果依赖于它们执行的相对时序。如果程序没有进行正确的同步控制，就会导致不可预测、不一致的结果。

==== DRF-SC
DRF-SC (Data-Race-Free with Sequential Consistency) 是指在没有数据竞争（Data-Race）的情况下，程序执行能表现得像顺序一致性（Sequential Consistency, SC）一样，让多线程/异构编程更简单，它结合了高效的硬件优化（例如面向众核的内存模型）和软件层对开发者友好的模型，确保能实现高效且安全的并发编程。

Data-Race-Free (DRF): 在多线程环境中，当两个线程访问同一内存位置，至少一个写操作，且没有同步机制时，就发生数据竞争。

Sequential Consistency (SC): 一种理想的内存模型，保证所有操作看起来是按程序顺序串行执行的。

DRF-SC 目标: 在保证不发生数据竞争的前提下，允许底层硬件进行宽松的优化（比如乱序执行、缓存），从而提高性能，同时又向程序员呈现出简单的顺序一致性视图。

==== atomicity(原子性)
原子性定义了一个操作相对于其他线程（或系统其他部分）的不可分割性。一个原子操作要么完全执行，要么完全不执行，其他线程无法观察到该操作执行到一半的中间状态。

硬件支持：现代处理器提供了一些指令，如 x86 上的 LOCK XADD、LOCK CMPXCHG，或 ARM 上的 LDREX/STREX，这些指令在执行读取、计算和写回的整个序列期间，会通过锁定缓存行或使用总线锁等方式，确保该内存位置不会被其他处理器核心访问。

软件抽象：高级编程语言（如 C++11、Java、Rust）提供了原子类型（例如 std::atomic<int>、AtomicInteger）。对这类变量的操作（如加载、存储、递增、交换）被编译器保证会映射到底层硬件的原子指令上，或者在没有硬件直接支持时，通过适当的同步机制（如互斥锁）来模拟原子性。

==== visibility(可见性)
可见性决定了其他线程何时能够看到当前线程所做的更改，以及是否能够看到这些更改。
可以通过特殊操作（如设置内存屏障）来确保可见性。不过，在实践中，可见性是最无需费心的特性，因为在缓存一致性架构上（即所有现代商用架构——IA-32、Intel 64、SPARC、POWER），可见性是自动保证的，每个写入操作都会以尽力而为的方式自动传播到所有其他处理器/核心。
也有一些例外情况，例如在 x86 架构中，非临时存储（使用 MOVNTDQ 等指令实现）以及对内存的 WC（写合并）区域进行的存储实际上是非缓存一致性的。也就是说，它们只有在执行 SFENCE 指令、MFENCE 指令、LOCKed 指令或其他序列化操作之前，才会传播到其他处理器/核心。

https://web.archive.org/web/20150530204245/http://www.1024cores.net/home/lock-free-algorithms/so-what-is-a-memory-model-and-how-to-cook-it/visibility

==== ordering(有序性)
有序性定义了内存操作（如读取和写入）在单个线程内及多个线程之间被观察到的顺序。

编译器优化和处理器乱序执行都可能改变程序代码中指定的操作顺序。对于单线程程序，这些优化是安全的，因为它们会保持“按顺序执行”的错觉。但对于多线程程序，特别是在无锁编程中，这可能导致反直觉且难以调试的问题。

内存屏障（或内存栅栏）是一种硬件指令，用于在特定点强制实施排序约束。它们主要有几种类型：
加载-加载屏障：确保该屏障之前的所有加载操作，在屏障之后的任何加载操作之前变得可见（即完成）。
存储-存储屏障：确保该屏障之前的所有存储操作，在屏障之后的任何存储操作之前变得可见。
加载-存储屏障和存储-加载屏障：限制不同类操作之间的重排。

获得语义与释放语义是更细粒度的、成对使用的屏障概念：
获得操作（Acquire）：确保该操作之后的所有内存操作（读和写）不会被重排到该操作之前。它像一扇“门”，阻止内部操作溜到门外。
典型的获得操作包括：带获得语义的原子加载、互斥锁的加锁操作。
释放操作（Release）：确保该操作之前的所有内存操作不会被重排到该操作之后。它像另一扇“门”，阻止内部操作溜到门外。
典型的释放操作包括：带释放语义的原子存储、互斥锁的解锁操作。

https://web.archive.org/web/20150530233431/http://www.1024cores.net/home/lock-free-algorithms/so-what-is-a-memory-model-and-how-to-cook-it/ordering