= netty
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:homepage: http://orientye.com
<<<

== 概览

=== 特点
参考: https://netty.io/index.html

netty5.0已经废弃:
主要原因: The major change of using a ForkJoinPool increases complexity and has not demonstrated a clear performance benefit. Also keeping all the branches in sync is quite some work without a real need for it as there is nothin in current master which I think justifies a new major release.
参考: https://github.com/netty/netty/issues/4466

说明: 本文基于netty最新稳定版本4.1。

=== java nio
since 1.4, the new non-blocking API
https://docs.oracle.com/javase/8/docs/api/java/nio/package-summary.html

- Buffer
- Channel
- Selector

nio2:
since java7
主要变化:
1. 加入了一种异步IO模式，利用事件回调机制(CompletionHandler等接口)，处理Accept、Read等操作，例如AsynchronousServerSocketChannel(对应ServerSocketChannel)及AsynchronousSocketChannel(对应SocketChannel)。
2. introduced better file management(java.nio.file package).
参考: https://stackoverflow.com/questions/25537675/java-what-exactly-is-the-difference-between-nio-and-nio-2

== 线程模型
=== 类型
- 单线程模型

    EventLoopGroup只包含一个EventLoop
    Boss和Worker使用同一个EventLoopGroup

- 多线程模型

    EventLoopGroup包含多个EventLoop
    Boss和Worker使用同一个EventLoopGroup

- 主从多线程模型

    EventLoopGroup包含多个EventLoop
    Boss是主Reactor，Worker是从Reactor，分别使用不同的EventLoopGroup
    主Reactor负责新的网络连接Channel的创建，然后把Channel注册到从Reactor

=== reactor单线程
- 所有IO操作在同一个NIO线程上完成

[source, java]
----
EventLoopGroup bossGroup = new NioEventLoopGroup(1);
ServerBootstrap b = new ServerBootstrap();
b.group(bossGroup)
 .channel(NioServerSocketChannel.class)
 ...
----

=== reactor多线程
- 一个连接只对应一个NIO线程

[source, java]
----
EventLoopGroup bossGroup = new NioEventLoopGroup(4);
ServerBootstrap b = new ServerBootstrap();
b.group(bossGroup)
 .channel(NioServerSocketChannel.class)
 ...
----
如果NioEventLoopGroup()构造时没有设置线程数目，则线程数是CPU核数的2倍?

=== 主从reactor多线程
- 主reactor线程池: acceptor线程池
- 从reactor线程池(sub reactor线程池)
- acceptor线程池仅用于客户端的登录，握手和安全认证，一旦连接建立成功，便将链路注册到subreactor线程池的IO线程上，由IO线程负责后续的IO操作

[source, java]
----
EventLoopGroup bossGroup = new NioEventLoopGroup(4);
EventLoopGroup workerGroup = new NioEventLoopGroup();
ServerBootstrap b = new ServerBootstrap();
b.group(bossGroup, workerGroup)
 .channel(NioServerSocketChannel.class)
 ...
----

=== Netty线程开发最佳实践
- 时间可控的简单业务直接在IO线程上处理
    如果业务非常简单，执行时间非常短，不需要与外部交互、访问数据库和磁盘，不需要等待其它资源，则建议直接在业务ChannelHandler中执行，不需要再启业务的线程或者线程池。避免线程上下文切换，也不存在线程并发问题。

- 复杂和时间不可控业务建议投递到后端业务线程池统一处理
    对于此类业务，不建议直接在业务ChannelHandler中启动线程或者线程池处理，建议将不同的业务统一封装成Task，统一投递到后端的业务线程池中进行处理。
    过多的业务ChannelHandler会带来开发效率和可维护性问题，不要把Netty当作业务容器，对于大多数复杂的业务产品，仍然需要集成或者开发自己的业务容器，做好和Netty的架构分层。

- 业务线程避免直接操作ChannelHandler
    对于ChannelHandler，IO线程和业务线程都可能会操作，因为业务通常是多线程模型，这样就会存在多线程操作ChannelHandler。为了尽量避免多线程并发问题，建议按照Netty自身的做法，通过将操作封装成独立的Task由NioEventLoop统一执行，而不是业务线程直接操作。

参考: https://www.infoq.cn/article/netty-threading-model

=== 参考
https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf[Doug Lea 《scalable io in java》]

== BootStrap与ServerBootStrap
引导器主要负责整个Netty程序的启动、初始化、服务器连接等过程，相当于一条主线，串联了Netty的其他核心组件。

引导器共分为两种类型:
用于客户端引导的Bootstrap，用于服务端引导 ServerBootStrap，均继承自抽象类AbstractBootstrap。

== EventLoop和EventLoopGroup
=== 概念
- EventLoop与EventLoopGroup:
    NioEventLoopGroup实际上是个线程池
    一个EventLoopGroup包含一个或者多个EventLoop

- EventLoop与Thread:
    一个EventLoop在它的生命周期内只有一个Thread绑定
    EnventLoop处理的I/O事件都将在它专有的Thread上进行

- EventLoop与Channel:
    一个Channel在它的生命周期内只注册于一个EventLoop
    每个EventLoop负责处理一个或多个Channel

也就是说，一个TCP连接是与一个固定的线程绑定的。

=== EventLoopGroup
class NioEventLoopGroup:
https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/nio/NioEventLoopGroup.java

BossEventLoopGroup与WorkerEventLoopGroup包含一个或者多个NioEventLoop。

BossEventLoopGroup负责监听客户端的Accept事件，当事件触发时，将事件注册至WorkerEventLoopGroup中的一个NioEventLoop上。每新建一个Channel，只选择一个NioEventLoop与其绑定，因此Channel生命周期的所有事件处理都是线程独立的，不同的NioEventLoop线程之间不会发生任何交集。

NioEventLoop完成数据读取后，会调用绑定的ChannelPipeline进行事件传播，ChannelPipeline也是线程安全的，数据会被传递到ChannelPipeline的第一个ChannelHandler中。数据处理完成后，将加工完成的数据再传递给下一个ChannelHandler，整个过程是串行化执行，不会发生线程上下文切换的问题。

=== NioEventLoop
==== run()
核心方法: run()
[source, java]
.https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/nio/NioEventLoop.java
----
@Override
    protected void run() {
        int selectCnt = 0;
        for (;;) {
            try {
                int strategy;
                try {
                    strategy = selectStrategy.calculateStrategy(selectNowSupplier, hasTasks());
                    switch (strategy) {
                    case SelectStrategy.CONTINUE:
                        continue;

                    case SelectStrategy.BUSY_WAIT:
                        // fall-through to SELECT since the busy-wait is not supported with NIO

                    case SelectStrategy.SELECT:
                        long curDeadlineNanos = nextScheduledTaskDeadlineNanos();
                        if (curDeadlineNanos == -1L) {
                            curDeadlineNanos = NONE; // nothing on the calendar
                        }
                        nextWakeupNanos.set(curDeadlineNanos);
                        try {
                            if (!hasTasks()) {
                                strategy = select(curDeadlineNanos);
                            }
                        } finally {
                            // This update is just to help block unnecessary selector wakeups
                            // so use of lazySet is ok (no race condition)
                            nextWakeupNanos.lazySet(AWAKE);
                        }
                        // fall through
                    default:
                    }
                } catch (IOException e) {
                    // If we receive an IOException here its because the Selector is messed up. Let's rebuild
                    // the selector and retry. https://github.com/netty/netty/issues/8566
                    rebuildSelector0();
                    selectCnt = 0;
                    handleLoopException(e);
                    continue;
                }

                selectCnt++;
                cancelledKeys = 0;
                needsToSelectAgain = false;
                final int ioRatio = this.ioRatio;
                boolean ranTasks;
                if (ioRatio == 100) {
                    try {
                        if (strategy > 0) {
                            processSelectedKeys();
                        }
                    } finally {
                        // Ensure we always run tasks.
                        ranTasks = runAllTasks();
                    }
                } else if (strategy > 0) {
                    final long ioStartTime = System.nanoTime();
                    try {
                        processSelectedKeys();
                    } finally {
                        // Ensure we always run tasks.
                        final long ioTime = System.nanoTime() - ioStartTime;
                        ranTasks = runAllTasks(ioTime * (100 - ioRatio) / ioRatio);
                    }
                } else {
                    ranTasks = runAllTasks(0); // This will run the minimum number of tasks
                }

                if (ranTasks || strategy > 0) {
                    if (selectCnt > MIN_PREMATURE_SELECTOR_RETURNS && logger.isDebugEnabled()) {
                        logger.debug("Selector.select() returned prematurely {} times in a row for Selector {}.",
                                selectCnt - 1, selector);
                    }
                    selectCnt = 0;
                } else if (unexpectedSelectorWakeup(selectCnt)) { // Unexpected wakeup (unusual case)
                    selectCnt = 0;
                }
            } catch (CancelledKeyException e) {
                // Harmless exception - log anyway
                if (logger.isDebugEnabled()) {
                    logger.debug(CancelledKeyException.class.getSimpleName() + " raised by a Selector {} - JDK bug?",
                            selector, e);
                }
            } catch (Error e) {
                throw e;
            } catch (Throwable t) {
                handleLoopException(t);
            } finally {
                // Always handle shutdown even if the loop processing threw an exception.
                try {
                    if (isShuttingDown()) {
                        closeAll();
                        if (confirmShutdown()) {
                            return;
                        }
                    }
                } catch (Error e) {
                    throw e;
                } catch (Throwable t) {
                    handleLoopException(t);
                }
            }
        }
    }
----

NioEventLoop每次循环的处理流程都包含事件轮询select、事件处理processSelectedKeys、任务处理runAllTasks几个步骤，并且提供了一个参数ioRatio，可以调整I/O事件处理和任务处理的时间比例。

==== select()与JDK空轮询Bug
https://solthx.github.io/2020/10/15/JDK%E7%A9%BA%E8%BD%AE%E8%AF%A2Bug%E5%8F%8A%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0/

==== 任务处理
NioEventLoop不仅负责处理I/O 事件，还兼顾执行任务队列中的任务。

任务队列遵循FIFO规则，可以保证任务执行的公平性。

NioEventLoop处理的任务类型基本可以分为三类:

- 普通任务
通过NioEventLoop的execute()向任务队列taskQueue中添加的任务。
例如Netty在写数据时会封装WriteAndFlushTask提交给taskQueue。
taskQueue的实现类是多生产者单消费者队列MpscChunkedArrayQueue，在多线程并发添加任务时，可以保证线程安全。

- 定时任务
通过调用NioEventLoop的schedule()向定时任务队列scheduledTaskQueue添加一个定时任务，用于周期性执行该任务。
例如心跳消息发送等。
定时任务队列scheduledTaskQueue采用优先队列PriorityQueue实现。

- 尾部任务
tailTasks相比于普通任务队列优先级较低，在每次执行完taskQueue中任务后会去获取尾部队列中任务执行。尾部任务并不常用，主要用于做一些收尾工作，例如统计事件循环的执行时间、监控信息上报等。

[source, java]
.https://github.com/netty/netty/blob/4.1/common/src/main/java/io/netty/util/concurrent/SingleThreadEventExecutor.java
----
protected boolean runAllTasks() {
    assert inEventLoop();
    boolean fetchedAll;
    boolean ranAtLeastOne = false;

    do {
        fetchedAll = fetchFromScheduledTaskQueue();
        if (runAllTasksFrom(taskQueue)) {
            ranAtLeastOne = true;
        }
    } while (!fetchedAll); // keep on processing until we fetched all scheduled tasks.

    if (ranAtLeastOne) {
        lastExecutionTime = getCurrentTimeNanos();
    }
    afterRunningAllTasks();
    return ranAtLeastOne;
}
----

==== EventLoop最佳实践
- 网络连接建立过程中三次握手、安全认证的过程会消耗不少时间。建议采用Boss和Worker两个EventLoopGroup，有助于分担Reactor线程的压力。

- 由于Reactor线程模式适合处理耗时短的任务场景，对于耗时较长的ChannelHandler可以考虑维护一个业务线程池，将编解码后的数据封装成Task进行异步处理，避免ChannelHandler阻塞而造成EventLoop不可用。

- 如果业务逻辑执行时间较短，建议直接在ChannelHandler中执行。例如编解码操作，这样可以避免过度设计而造成架构的复杂性。

- 不宜设计过多的ChannelHandler。对于系统性能和可维护性都会存在问题，在设计业务架构的时候，需要明确业务分层和Netty分层之间的界限。不要一味地将业务逻辑都添加到ChannelHandler中。

== Channel
Channel(通道)是网络通信的载体。
Channel提供了基本的API用于网络I/O操作，例如register、bind、connect、read、write、flush等。
Netty的Channel以JDK NIO Channel为基础，相比较于JDK NIO，提供了更高层次的抽象，屏蔽了底层Socket的复杂性，赋予了Channel更强大的功能。

== ChannelPipeline
ChannelPipeline是Netty的核心编排组件，负责组装各种ChannelHandler。
ChannelPipeline通过双向链表将不同的ChannelHandler链接在一起。
当读写事件触发时，ChannelPipeline会依次调用ChannelHandler列表对Channel的数据进行拦截和处理。

ChannelPipeline是线程安全的。
每一个新的Channel都会对应绑定一个新的ChannelPipeline。
一个ChannelPipeline关联一个EventLoop。

客户端和服务端都有各自的ChannelPipeline。

https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelPipeline.java
https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/DefaultChannelPipeline.java

ChannelPipeline的双向链表分别维护了HeadContext和TailContext的头尾节点。
程序自定义的ChannelHandler会插入到Head和Tail之间，即HeadContext与TailContext。

HeadContext是Inbound处理器，也是Outbound处理器。
实现了ChannelInboundHandler和ChannelOutboundHandler。
网络数据写入操作的入口就是由HeadContext节点完成的。
HeadContext作为Pipeline的头结点负责读取数据并开始传递InBound事件，当数据处理完成后，数据会反方向经过Outbound处理器，最终传递到HeadContext，因此HeadContext又是处理Outbound事件的最后一站。此外HeadContext在传递事件之前，还会执行一些前置操作。

TailContext只实现了ChannelInboundHandler接口。
它会在ChannelInboundHandler调用链路的最后一步执行，主要用于终止Inbound 件传播，例如释放Message数据资源等。TailContext节点作为OutBound事件传播的第一站，仅仅是将OutBound事件传递给上一个节点。

HeadContext与TailContext:
https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/DefaultChannelPipeline.java


从整个ChannelPipeline调用链路来看，如果由Channel直接触发事件传播，那么调用链路将贯穿整个ChannelPipeline。然而也可以在其中某一个ChannelHandlerContext触发同样的方法，这样只会从当前的ChannelHandler开始执行事件传播，该过程不会从头贯穿到尾，在一定场景下，可以提高程序性能。

== ChannelHandler
=== 概念
数据的编解码工作以及其他转换工作都是通过ChannelHandler处理的。
一般来说，开发者最关注的是ChannelHandler(很少会直接操作Channel，都是通过ChannelHandler间接完成)。

https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelHandler.java

https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelInboundHandler.java
https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelOutboundHandler.java

=== ChannelHandlerContext
每创建一个Channel都会绑定一个新的ChannelPipeline，ChannelPipeline中每加入一个ChannelHandler都会绑定一个ChannelHandlerContext。

ChannelHandlerContext用于保存ChannelHandler上下文，ChannelHandlerContext可以实现ChannelHandler之间的交互，ChannelHandlerContext包含了ChannelHandler生命周期的所有事件，如connect、bind、read、flush、write、close等。

https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelHandlerContext.java

=== 事件传播
Inbound事件和Outbound事件的传播方向是不一样的。
Inbound事件的传播方向为Head -> Tail，而Outbound事件传播方向是Tail -> Head，两者相反。
推荐在系统设计时模拟客户端和服务端的场景画出ChannelPipeline的内部结构图，以避免搞混调用关系。

=== 异常处理
异常事件的处理顺序与ChannelHandler的添加顺序相同，会依次向后传播，与Inbound事件和Outbound事件无关。

Netty中TailContext提供了兜底的异常处理逻辑，但是在很多场景下，不一定能满足应用的需求。

异常处理的最佳实践:
推荐对异常进行统一拦截(在ChannelPipeline自定义处理器的末端添加统一的异常处理器)，然后根据场景实现更加完善的异常处理机制。
示例代码:
[source, java]
----
public class ExceptionHandler extends ChannelDuplexHandler {
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {
        if (cause instanceof RuntimeException) {
            System.out.println("Handle Business Exception Success.");
        }
    }
}
----

== 编解码器
编解码器可以分为一次解码器和二次解码器:
一次解码器用于解决TCP拆包/粘包问题，按协议解析后得到字节数据。如果需要对解析后的字节数据做对象模型的转换，便需要用到二次解码器。编码器同理。

一次编解码器: MessageToByteEncoder/ByteToMessageDecoder
二次编解码器: MessageToMessageEncoder/MessageToMessageDecoder

长度域解码器LengthFieldBasedFrameDecoder是解决TCP拆包/粘包问题最常用的解码器。它基本上可以覆盖大部分基于长度拆包场景。LengthFieldBasedFrameDecoder比FixedLengthFrameDecoder和DelimiterBasedFrameDecoder要稍微复杂一点，但是功能比较强大。

== Bytebuf
网络通信中的数据载体。

== Unsafe

== 优化
https://www.infoq.cn/article/netty-million-level-push-service-design-points

== 参考
https://netty.io/
https://netty.io/wiki/index.html
https://github.com/netty/netty
