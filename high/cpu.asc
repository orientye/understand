= CPU
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:homepage: http://orientye.com

<<<

== 概览
https://www.lighterra.com/papers/modernmicroprocessors/

== 概念
- CPU频率
CPU频率指的是CPU内核工作时的时钟频率，也就是CPU每秒内能产生多少个同步脉冲信号，单位是赫兹（Hz），通常以兆赫（MHz）或吉赫（GHz）为单位。它表示CPU的运行速度，频率越高，CPU每秒处理的脉冲数量就越多，通常意味着更快的运算能力，但整体性能也受到其他因素（如架构、缓存、核心数）的影响。

== 流水线(pipelining)
指令是如何被执行的？首先，它被取出，然后被解码，接着由相应的功能单元执行，最后结果被写入到相应的地方。
现代处理器在一个流水线中将这些阶段重叠，就像装配线一样。当一条指令在执行时，下一条指令正在被解码，而后面的那条指令正在被取出。

每个流水线阶段都包含组合逻辑电路，并可能访问寄存器组和/或某种形式的高速缓存存储器。流水线阶段之间通过锁存器进行分隔。统一的时钟信号对各级锁存器进行同步控制，使得所有锁存器能够同时捕获各流水线阶段产生的处理结果。实际上，正是时钟信号驱动着指令在流水线中逐级传递。
在每个时钟周期开始时，承载着部分处理完成指令的数据和控制信息会被暂存于流水线锁存器中，这些信息将作为下一级流水线阶段逻辑电路的输入。在时钟周期运行期间，电信号会通过该阶段的组合逻辑电路进行传播，最终生成的输出结果将在周期结束时被下一级流水线锁存器精准捕获...

由于每条指令的执行结果在完成执行阶段后即可获取，后续指令理应能够立即使用该结果值，而无需等待该结果在写回阶段被提交到目标寄存器。为实现这一机制，需增设称为"旁路"的数据前向通路——这些通路沿着流水线逆向延伸。

流水线深度(pipeline depth):
Modern x86 CPU pipeline depth varies, but common architectures like Intel's Core series have around a 14-stage pipeline.
https://softwareengineering.stackexchange.com/questions/210818/how-long-is-a-typical-modern-microprocessor-pipeline

Since the clock speed is limited by (among other things) the length of the longest, slowest stage in the pipeline, the logic gates that make up each stage can be subdivided, especially the longer ones, converting the pipeline into a deeper super-pipeline with a larger number of shorter stages. Then the whole processor can be run at a higher clock speed! Of course, each instruction will now take more cycles to complete (latency), but the processor will still be completing 1 instruction per cycle (throughput), and there will be more cycles per second, so the processor will complete more instructions per second (actual performance)...

Today, modern processors strive to keep the number of gate delays down to just a handful for each pipeline stage, about 12-25 gates deep (not total!) plus another 3-5 for the latch itself, and most have quite deep pipelines...

== 多发射与超标量(Multiple Issue - Superscalar)
发射宽度(issue width)

== 超长指令集/超长指令字(VLIW即Very Long Instruction Word)
在一条超长的指令中，包含了多个可以并行执行的操作（例如算术运算、内存访问、分支等）。 处理器在单个时钟周期内，取出这条长指令，并将其中的多个操作分发到多个独立的功能单元（如ALU、FPU、加载/存储单元）中同时执行。

核心思想: 将并行性从硬件转移到编译器。

VLIW的工作原理:

    编译时：编译器对高级语言代码进行极致优化。
        它进行指令级并行分析，找出没有数据依赖关系的操作。
        它将这些可以并行执行的操作组合在一起，形成一条VLIW指令。
        一条典型的VLIW指令可能看起来像这样：
        [ 操作码: ADD R1, R2, R3 | 操作码: LOAD R4, [R5] | 操作码: MUL R6, R7, R8 | 无操作 NOP ]
        这条指令告诉处理器，在同一周期内，ALU1执行加法，加载/存储单元执行内存读取，ALU2执行乘法。
        如果找不到足够的操作来填满所有槽位，编译器必须插入NOP（无操作）指令，这会浪费指令空间。
    执行时：
        取指：处理器从指令缓存中取出一条完整的VLIW长指令。
        译码：译码逻辑非常简单，几乎不需要动态分析，直接将指令的不同字段分发到对应的功能单元。
        执行：所有功能单元同时开始执行各自的操作。
        写回：将结果写回到寄存器堆。

== 参考
《Performance Analysis and Tuning on Modern CPUS》2nd: https://github.com/dendibakh/perf-book