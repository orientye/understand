:toc:
:toclevels: 5
:hardbreaks-option:

=== memory order

==== 概念
in-order: 顺序
out-of-order: 乱序

==== Why Memory Barriers
memory barriers are a necessary evil that is required to enable good performance and scalability, an evil that stems from the fact that CPUs are orders of magnitude faster than are both the interconnects between them and the memory they are attempting to access.
- 《perfbook》 Appendix C Unknown Why Memory Barriers?

===== Cache Structure
===== Cache-Coherence Protocols
====== 概念
- 背景
在现代多核CPU中，每个核心通常都有自己的私有缓存（如L1、L2缓存）。当一个程序在运行时，它需要的数据可能会被复制到多个核心的缓存中。
这就引发了一个问题：如果其中一个核心修改了自己缓存里的数据，其他核心的缓存副本就会变成“过时”的，从而导致程序运行错误。
MESI协议就是为了解决这个问题而生的。它通过维护缓存行（Cache Line）的状态，并在不同核心之间进行通信，来保证所有缓存中的数据副本都是一致的。

- 机制
每个缓存行都有 M、E、S、I 四种状态，通过核心间的“总线嗅探”和消息传递来触发状态转换。

- 性能
MESI协议减少了对主内存的直接访问。例如，在 M 状态的数据只有在必要时才写回内存；在 S 状态的数据可以直接从其他缓存获取，这比访问内存快得多。

====== MESI States
MESI stands for “modified”, “exclusive”, “shared”, and “invalid”, the four states a given cache line can take on using this protocol. Caches using this protocol therefore maintain a two-bit state “tag” on each cacheline in addition to that line’s physical address and data.

- M - Modified (已修改)
    ** 当前缓存行中的数据已经被修改，与主内存中的数据不一致。
    ** 这个缓存是拥有该数据最新、唯一正确副本的缓存。
    ** 在某个时间点，这个被修改的数据必须被写回主内存。

- E - Exclusive (独占)
    ** 当前缓存行中的数据与主内存中的数据一致。
    ** 只有我这一个缓存拥有该数据的副本。
    ** 如果我要修改它，我可以直接进行，无需通知其他核心，因为我是唯一的拥有者。

- S - Shared (共享)
    ** 当前缓存行中的数据与主内存中的数据一致。
    ** 可能有多个缓存中都存在该数据的相同副本。
    ** 因为副本是共享的，所以我不能直接修改它。如果我想修改，必须先通知其他缓存，让它们的副本失效。

- I - Invalid (无效)
    ** 这个缓存行中的数据是过时的、不可用的。
    ** 它可能是因为其他核心修改了数据，导致本地的副本失效。
    ** 当CPU需要读取这个数据时，它不能使用这个无效的副本，而必须从其他缓存或主内存中重新获取。

====== MESI Protocol Messages
MESI 协议的消息，是缓存之间、缓存与主内存之间进行通信的“语言”，通过它们来协调状态的变化和数据的传输。
MESI 协议通过一个总线嗅探 机制工作，每个缓存控制器都监听总线上的所有消息。当它看到某个消息与它缓存的数据相关时，就会采取相应的行动。

Read:
The “read” message contains the physical address of the cache line to be read.

Read Response:
The “read response” message contains the data requested by an earlier “read” message. This “read response” message might be supplied either by memory or by one of the other caches. For example, if one of the caches has the desired data in “modified” state, that cache must supply the “read response” message.

Invalidate:
The “invalidate” message contains the physical address of the cache line to be invalidated. All other caches must remove the corresponding data from their caches and respond.

Invalidate Acknowledge:
A CPU receiving an “invalidate” message must respond with an “invalidate acknowledge” message after removing the specified data from its cache.

Read Invalidate:
The “read invalidate” message contains the physical address of the cache line to be read, while at the same time directing other caches to remove the data.
Hence, it is a combination of a “read” and an “invalidate”, as indicated by its name. A “read invalidate” message requires both a “read response” and a set of
“invalidate acknowledge” messages in reply.

Writeback:
The “writeback” message contains both the address and the data to be written back to memory (and perhaps “snooped” into other CPUs’ caches along the way). This message permits caches to eject lines in the “modified” state as needed to make room for other data.

Q: Where does a writeback message originate from and where does it go to?
回写消息从何而来，去往何处？
回写消息可能源自某个特定的CPU，或者在某些设计中也可能源自某个CPU特定层级的缓存——甚至可能源自多个CPU共享的缓存。关键在于，某个缓存中已没有空间存放特定数据项，因此必须将其他数据驱逐出去以腾出空间。如果存在其他数据副本（位于其他缓存或内存中），那么可以直接丢弃该数据，无需发出回写消息。
然而，如果每个可能被驱逐的数据都已被修改，导致唯一的最新副本就在当前缓存中，那么就必须将这些数据项之一复制到其他地方。这个复制操作就是通过"回写消息"来完成的。
回写消息的目的地必须是能够存储新值的位置。这可能是主内存，但也可能是其他缓存。如果是其他缓存，通常会是同一CPU的更高层级缓存（例如，一级缓存可能回写到二级缓存）。不过，有些硬件设计允许跨CPU的回写操作，因此CPU 0的缓存可能会向CPU 1发送回写消息。这通常发生在CPU 1以某种方式表明了对该数据的兴趣时（例如，最近曾发出过读取请求）。
简而言之，回写消息从系统中空间不足的组件发出，由系统中能够容纳该数据的其他组件接收。

Q: What happens if two CPUs attempt to invalidate the same cache line concurrently?
One of the CPUs gains access to the shared bus first, and that CPU “wins”. The other CPU must invalidate its copy of the cache line and transmit an “invalidate acknowledge” message to the other CPU.
Of course, the losing CPU can be expected to immediately issue a “read invalidate” transaction, so the winning CPU’s victory will be quite ephemeral.

Q: When an “invalidate” message appears in a large multiprocessor, every CPU must give an “invalidate acknowledge” response. Wouldn’t the resulting “storm” of
“invalidate acknowledge” responses totally saturate the system bus?
如果大规模多处理器确实以这种方式实现，这种情况确实可能发生。但大型多处理器（特别是NUMA架构机器）往往采用所谓的"基于目录"的缓存一致性协议，正是为了避免此类问题及其他相关问题。

Q: If SMP machines are really using message passing anyway, why bother with SMP at all?
若SMP机器实际上也在使用消息传递，那为何还要大费周章地发展SMP技术？
过去几十年来，这个话题始终争议不断。一种解释是：缓存一致性协议本身相当简洁，因此能够直接通过硬件实现，从而获得软件消息传递无法企及的带宽与延迟优势。另一种观点认为，真正原因在于经济性——大型SMP设备与小型SMP集群的成本差异决定了技术路线。亦有见解指出SMP编程模型比分布式系统更易用，但反对声音会举出HPC集群与MPI的成功案例。这场争论，至今仍在持续。

====== MESI State Diagram
12种状态转换

- (a) M->E
A cache line is written back to memory, but the CPU retains it in its cache and further retains the right to modify it. This transition requires a “writeback” message.
缓存行被写回内存，但CPU仍将其保留在缓存中，并保留修改权限。这一状态转换需要发送“写回”消息。

- (b) E->M
The CPU writes to the cache line that it already had exclusive access to. This transition does not require any messages to be sent or received.
CPU对其已有独占权的缓存行执行写入操作。此状态转换无需发送或接收任何消息。

- (c) M->I
The CPU receives a “read invalidate” message for a cache line that it has modified. The CPU must
invalidate its local copy, then respond with both a “read response” and an “invalidate acknowledge” message, both sending the data to the requesting CPU and indicating that it no longer has a local copy.
当CPU收到针对其已修改缓存行的"读无效"消息时，必须执行以下操作：首先使本地副本失效，随后同时发出"读响应"和"无效确认"消息：将数据传送至请求方CPU，表明自身不再持有本地副本。

- (d) I->M
The CPU does an atomic read-modify-write operation on a data item that was not present in its cache. It transmits a “read invalidate”, receiving the data via a “read response”. The CPU can complete the transition once it has also received a full set of “invalidate acknowledge” responses.
CPU对其缓存中不存在的数据项执行原子性的读写修改操作。它首先发出“读无效”指令，并通过“读响应”接收数据。只有在收到完整的“无效确认”响应集合后，CPU才能完成该状态转换。

- (e) S->M
The CPU does an atomic read-modify-write operation on a data item that was previously read-only in its cache. It must transmit “invalidate” messages, and
must wait for a full set of “invalidate acknowledge” responses before completing the transition.
CPU对其缓存中原本处于只读状态的数据项执行原子性读写修改操作。它必须发送"无效"消息，并且需要收齐所有"无效确认"响应后才能完成状态转换。

- (f) M->S
Some other CPU reads the cache line, and it is supplied from this CPU’s cache, which retains a readonly copy, possibly also writing it back to memory.
This transition is initiated by the reception of a “read” message, and this CPU responds with a “read response” message containing the requested data.
当其他CPU读取该缓存行时，本cpu必须以其local cacheline的数据回应，并以read response回应之前总线上的read请求。这时候该cacheline状态从Modified状态变成shared状态（有可能也会进行写回的动作）。

- (g) E->S
Some other CPU reads a data item in this cache line, and it is supplied either from this CPU’s cache or from memory. In either case, this CPU retains a readonly copy. This transition is initiated by the reception of a “read” message, and this CPU responds with a “read response” message containing the requested data.
当其他CPU读取此缓存行中的数据项时，数据可能由此CPU的缓存提供，也可能由内存提供。无论哪种情况，此CPU都会保留一份只读副本。该状态转换由接收到的"读取"消息触发，此CPU会返回包含所请求数据的"读取响应"消息。
与(f)不同，不存在写回的问题。

- (h) S->E
This CPU realizes that it will soon need to write to some data item in this cache line, and thus transmits an “invalidate” message. The CPU cannot complete the transition until it receives a full set of “invalidate acknowledge” responses, indicating that no other CPU has this cacheline in its cache. In other words, this CPU is the only CPU caching it.
此CPU预判其不久将需要修改该缓存行中的某个数据项，因而主动发出"无效"消息。在收到完整的"无效确认"响应集之前，CPU无法完成状态转换，一旦收到所有的响应，表明其他CPU的缓存中均已不存在该缓存行。换言之，此时该CPU已成为唯一缓存此数据的处理器。

- (i) E->I
Some other CPU does an atomic read-modify-write operation on a data item in a cache line held only in this CPU’s cache, so this CPU invalidates it from its cache. This transition is initiated by the reception of a “read invalidate” message, and this CPU responds with both a “read response” and an “invalidate acknowledge” message.
当其他CPU对仅存在于本CPU缓存中的缓存行内的数据项执行原子性读-修改-写操作时，本CPU会将该缓存行从自身缓存中置为无效。此状态转换由接收到“读-无效”消息触发，本CPU将同时回复“读响应”与“无效确认”消息作为响应。

- (j) I->E
This CPU does a store to a data item in a cache line that was not in its cache, and thus transmits a “read invalidate” message. The CPU cannot complete the transition until it receives the “read response” and a full set of “invalidate acknowledge” messages. The cache line will presumably transition to “modified” state via transition (b) as soon as the actual store completes.
本CPU对不在自身缓存中的缓存行数据项执行存储操作，因此发送“读-无效”消息。该CPU必须接收到“读响应”及完整的(所有其他cpu的)“无效确认”消息集合后才能完成状态转换。在实际存储操作完成后，该缓存行预计将通过(b)转换路径进入“已修改”状态。

- (k) I->S
This CPU loads a data item in a cache line that was not in its cache. The CPU transmits a “read” message, and completes the transition upon receiving the corresponding “read response”.
本CPU对不在自身缓存中的缓存行执行数据加载操作，因此发送"读"请求消息，之后接收到其他的cpu local cache或者memory的"读响应"消息，于是完成此状态转换，即将该cacheline从Invalid状态迁移到shared状态。

- (l) S->I
Some other CPU does a store to a data item in this cache line, but holds this cache line in read-only state due to its being held in other CPUs’ caches (such as the current CPU’s cache). This transition is initiated by the reception of an “invalidate” message, and this CPU responds with an “invalidate acknowledge” message.
当cacheline处于shared状态时，说明在多个cpu的local cache中存在只读副本，一旦其中一个cpu想要执行数据写入操作，必须先通过invalidate获取该数据的独占权，而其他的CPU会以invalidate acknowledge回应，并将其cacheline从shared状态修改成invalid状态。

Q: How does the hardware handle the delayed transitions described above?
A: Usually by adding additional states, though these additional states need not be actually stored with the cache line, due to the fact that only a few lines at a time will be transitioning. The need to delay transitions is but one issue that results in real-world cache coherence protocols being much more complex than the over-simplified MESI protocol described in this appendix. Hennessy and Patterson’s classic introduction to computer architecture [HP95](即《Computer Architecture: A Quantitative Approach》) covers many of these issues.

====== MESI Protocol Example
perfbook C2.4

Q: What sequence of operations would put the CPUs’ caches all back into the “invalid” state?
A: There is no such sequence, at least in absence of special “flush my cache” instructions in the CPU’s instruction set. Most CPUs do have such instructions.
问：需要怎样的操作序列才能让所有CPU缓存回到“无效”状态？
答：至少在没有CPU指令集提供的特殊“清空缓存”指令时，不存在这样的操作序列。目前大多数CPU都配备了这类专用指令。

====== 参考
《Parallel Computer Architecture A Hardware / Software Approach》
《A Primer on Memory Consistency and Cache Coherence》2nd

==== reorder
考虑如下情形:
(1) 编译器在编译程序的过程中，对代码会进行调整；
(2) CPU在执行指令的过程中，对指令会进行重排。
编译器重排序: 在将源代码编译成机器码时，编译器会进行优化，调整指令顺序，前提是保证在单线程上下文中的最终结果不变。
CPU指令级重排序: CPU在执行时，动态地调整指令的执行顺序。这是最核心的重排序。由于存在多级缓存，一个CPU核心对数据的修改，在最终写入主内存并被其他核心看到之前，其顺序可能对其他核心来说是被打乱的。
显然，有时候这些优化并不符合预期(第一种情况可能发生编译乱序，第二种情况可能发生执行乱序)，为了防止这两种情况，这就需要compiler barrier和memory barrier。

Q: 单线程会发生指令重排吗(同理，运行在单个CPU core上的多线程)
A: 会，但不会影响结果

Q: 什么情况下肯定不会重排?
处理器必须能正确处理指令依赖情况保证程序能得出正确的执行结果。
例如指令1把地址A中的值加100，指令2把地址A中的值乘以7，指令3把地址B中的值减去60，则指令1和指令2是有依赖的，它们之间的顺序不能重排: (A+100)*7与A*7+100显然不相等，但指令3可以重排到指令1或指令2之前。

==== compile-time memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Compile-time_memory_ordering
编译器重排序是指编译器在将源代码翻译成目标代码（如汇编或机器码）的过程中，为了优化性能，在不改变程序单线程语义的前提下，重新排列指令的执行顺序。

==== runtime memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Runtime_memory_ordering

CPU在什么情况下会reorder呢？

对于有前后有依赖的指令，CPU一般不会reorder(Alpha架构除外)。
例如: a = 5; b = a + 1; 这两条指令存在依赖关系，不会被cpu重排顺序。

对于没有前后依赖关系的指令，CPU就有可能对这些指令进行重排(除非使用memory barrier进行一些显示控制)，具体的力度则与CPU体系结构相关:

    x86是一种strong order(也叫TSO，total store order):
        同一CPU执行的load指令后接load指令(L-L)，store指令后接store指令(S-S)，load指令后接store指令(L-S):
            均不能交换指令的执行顺序
        仅store指令后接load指令(S-L)才可以

    ARM则是一种weak order:
        只要没有依赖关系，load指令和store指令就可任意交换。

==== Store Buffer（存储缓冲区/写缓冲区）
是CPU核心内部的一个小型、高速的硬件队列，用于临时存放CPU核心想要写入到缓存（Cache）中的数据。
https://developer.arm.com/documentation/ddi0489/f/memory-system/l1-caches/store-buffer
https://community.intel.com/t5/Software-Tuning-Performance/Purpose-of-Load-Buffer-in-x86/td-p/1091736

==== 示例

    // 初始： x = 0, y = 0
    // CPU 0 (Thread 1)        // CPU 1 (Thread 2)
    x = 1;                    y = 1;
    int r1 = y;               int r2 = x;
    可能的结果：从逻辑上看，(r1, r2) 不可能是 (0, 0)，但实际情况却有可能。

- 为什么
    ** 在CPU 0上：
        *** x = 1; 被执行。这个写操作被放入了CPU 0的Store Buffer，但还没提交到缓存。此时，对于其他核心（包括CPU 1）来说，x 的值仍然是 0。
        *** int r1 = y; 被执行。CPU 0去读 y。假设此时CPU 1的 y=1 也还在它的Store Buffer里，那么CPU 0读到的 y 就是旧值 0。所以 r1 = 0。
    ** 在CPU 1上：发生着对称的过程。
        *** y = 1; 进入Store Buffer。
        *** int r2 = x; 读 x，此时CPU 0的 x=1 还在Store Buffer里，所以读到 0。r2 = 0。
    ** 最终，两个线程都读到了对方的旧值 0。
    ** 从程序顺序看：每个线程都是先Store后Load。
    ** 从实际结果看：仿佛是Load操作越过了还在Store Buffer中的Store操作先执行了。这就是 StoreLoad 重排序。

- 解决方案：内存屏障
    ** 为了解决Store Buffer带来的可见性和顺序问题，CPU提供了内存屏障指令。
    ** 写屏障（Store Barrier / SFENCE）：
        *** 清空Store Buffer。
        *** 在写屏障之前的所有Store操作，都必须被刷入Store Buffer（并开始提交流程）。
        *** 在写屏障之后的Store操作，必须等到写屏障执行完后才能进入Store Buffer。
        *** 这保证了写屏障之前的Store操作，一定先于之后的Store操作对其他核心可见。（解决了StoreStore重排序）
    ** 全能屏障（Full Barrier / MFENCE）：
        *** 功能更强，通常包括清空Store Buffer和等待Load Buffer（另一个用于优化读的组件）。
        *** 它能防止StoreLoad重排序，即确保屏障之前的所有Store操作都对其他核心可见之后，才执行屏障之后的Load操作。

==== memory barrier
memory barrier就像一个栅栏一样，隔开了在其前面和后面的指令。
"barrier"前面的指令不能与后面的指令进行调换；
如果指令均处在其前面，或者均处在其后面，只要没有违反当前CPU的memory order的规则，则是可以调换的。

memory barrier约束了CPU的行为，同时也约束了编译器的行为，即memory barrier也隐含了compiler barrier语义。

==== Q&A
Q: memory order vs. cache coherence
https://course.ece.cmu.edu/~ece847c/S15/lib/exe/fetch.php?media=part2_2_sorin12.pdf

Q: memory order vs. atomic
https://stackoverflow.com/questions/15056237/which-is-more-efficient-basic-mutex-lock-or-atomic-integer

==== 可见性问题

==== cpu视角
x86: https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.html

chapter8 multi-processor management
8.2 memory ordering
8.2.5 strengthening or weakening the memory-order model:

• SFENCE — Serializes all store (write) operations that occurred prior to the SFENCE instruction in the program instruction stream, but does not affect load operations.

• LFENCE — Serializes all load (read) operations that occurred prior to the LFENCE instruction in the program instruction stream, but does not affect store operations.

• MFENCE — Serializes all store and load operations that occurred prior to the MFENCE instruction in the program instruction stream.

==== kernel视角
https://github.com/orientye/understanding-the-linux-kernel/blob/main/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E5%86%85%E6%A0%B8/%E8%BF%9B%E7%A8%8B/%E5%90%8C%E6%AD%A5.asc#barrier

==== c++

===== 概念
https://en.cppreference.com/w/cpp/atomic/memory_order

Acquire semantics is a property that can only apply to operations that read from shared memory, whether they are read-modify-write operations or plain loads. The operation is then considered a read-acquire. Acquire semantics prevent memory reordering of the read-acquire with any read or write operation that follows it in program order.

Release semantics is a property that can only apply to operations that write to shared memory, whether they are read-modify-write operations or plain stores. The operation is then considered a write-release. Release semantics prevent memory reordering of the write-release with any read or write operation that precedes it in program order.

Fence Semantics
A fence semantics combines both acquire and release semantics behavior.

- Sequenced-before

- Carries dependency

- Modification order

- Release sequence

- Dependency-ordered before

- Inter-thread happens-before

- Happens-before

- Visible side-effects

- Consume operation

- Acquire opertation

- Release operation

- Synchronizes-with

===== 本质
本质上两个问题:

    【1】______不可以重排到______的前面/后面
    【2】______对谁______可见

===== Q&A
Q: 如果变量是函数的参数呢？

===== relaxed

===== release acquire

===== release consume

===== sequentially consistent
Q: 上述例子如果换成acquire/release，结果?
Q: seq_cst做了什么? 什么情况下使用?

===== thread_fence
std::atomic_thread_fence

extern "C" void atomic_thread_fence( std::memory_order order ) noexcept;

Establishes memory synchronization ordering of non-atomic and relaxed atomic accesses, as instructed by order, without an associated atomic operation.

===== implement
以memory_order_seq_cst为例:
Ubuntu(g++, VM, Intel i5 4 core):    汇编指令mfence
Mac OSX(g++,  Intel i5 2 core):      汇编指令xchgl(= lock xchgl)
Win10(VS2015, Intel i5 4 core):      _ReadWriteBarrier, _InterlockedExchange

is_lock_free

===== 应用示例
https://github.com/facebook/rocksdb/blob/master/memtable/skiplist.h
https://github.com/apache/incubator-brpc/blob/master/src/bthread/work_stealing_queue.h

===== 参考
https://en.cppreference.com/w/cpp/language/memory_model

==== java
https://github.com/orientye/understand/blob/main/lan/java.asc#Java-Memory-Model-and-Thread

==== 正确性
===== ThreadSanitizer
https://clang.llvm.org/docs/ThreadSanitizer.html

===== relacy
https://github.com/dvyukov/relacy

===== cppmem
http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/

===== 形式化验证

==== 参考
perfbook: Chapter 15 Advanced Synchronization: Memory Ordering
