:toc:
:toclevels: 5
:hardbreaks-option:

=== memory order

==== reorder
in-order: 顺序
out-of-order: 乱序
reorder: 重排
memory barrier: 字面意思: 内存栅栏，粗暴且不准确的理解是，隔开了在其前面和后面的指令。
memory barrier约束了CPU的行为，同时也约束了编译器的行为，即memory barrier也隐含了compiler barrier语义。

考虑如下情形:
(1) 编译器在编译程序的过程中，对代码会进行调整；
(2) CPU在执行指令的过程中，对指令会进行重排。
编译器重排序: 在将源代码编译成机器码时，编译器会进行优化，调整指令顺序，前提是保证在单线程上下文中的最终结果不变。
CPU指令级重排序: CPU在执行时，动态地调整指令的执行顺序。这是最核心的重排序。由于存在多级缓存，一个CPU核心对数据的修改，在最终写入主内存并被其他核心看到之前，其顺序可能对其他核心来说是被打乱的。
显然，有时候这些优化并不符合预期(第一种情况可能发生编译乱序，第二种情况可能发生执行乱序)，为了防止这两种情况，这就需要compiler barrier和memory barrier。

Q: 单线程会发生指令重排吗(同理，运行在单个CPU core上的多线程)
A: 会，但不会影响结果

Q: 什么情况下肯定不会重排?
处理器必须能正确处理指令依赖情况保证程序能得出正确的执行结果。
例如指令1把地址A中的值加100，指令2把地址A中的值乘以7，指令3把地址B中的值减去60，则指令1和指令2是有依赖的，它们之间的顺序不能重排: (A+100)*7与A*7+100显然不相等，但指令3可以重排到指令1或指令2之前。

==== compile-time memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Compile-time_memory_ordering
编译器重排序是指编译器在将源代码翻译成目标代码（如汇编或机器码）的过程中，为了优化性能，在不改变程序单线程语义的前提下，重新排列指令的执行顺序。

==== runtime memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Runtime_memory_ordering

CPU在什么情况下会reorder呢？

对于有前后有依赖的指令，CPU一般不会reorder(Alpha架构除外)。
例如: a = 5; b = a + 1; 这两条指令存在依赖关系，不会被cpu重排顺序。

==== 体系结构的差异性
对于没有前后依赖关系的指令，CPU就有可能对这些指令进行重排(除非使用memory barrier进行一些显示控制)，具体的力度则与CPU体系结构相关:

    x86是一种strong order(也叫TSO，total store order):
        同一CPU执行的load指令后接load指令(L-L)，store指令后接store指令(S-S)，load指令后接store指令(L-S):
            均不能交换指令的执行顺序
        仅store指令后接load指令(S-L)才可以

    ARM则是一种weak order:
        只要没有依赖关系，load指令和store指令就可任意交换。

==== Why Memory Barriers
memory barriers are a necessary evil that is required to enable good performance and scalability, an evil that stems from the fact that CPUs are orders of magnitude faster than are both the interconnects between them and the memory they are attempting to access.
- 《perfbook》 Appendix C Unknown Why Memory Barriers?

===== Cache Structure
perfbook C2.1

===== Cache-Coherence Protocols
====== 概念
- 背景
在现代多核CPU中，每个核心通常都有自己的私有缓存（如L1、L2缓存）。当一个程序在运行时，它需要的数据可能会被复制到多个核心的缓存中。
这就引发了一个问题：如果其中一个核心修改了自己缓存里的数据，其他核心的缓存副本就会变成“过时”的，从而导致程序运行错误。
MESI协议就是为了解决这个问题而生的。它通过维护缓存行（Cache Line）的状态，并在不同核心之间进行通信，来保证所有缓存中的数据副本都是一致的。

- 机制
每个缓存行都有 M、E、S、I 四种状态，通过核心间的“总线嗅探”和消息传递来触发状态转换。

- 性能
MESI协议减少了对主内存的直接访问。例如，在 M 状态的数据只有在必要时才写回内存；在 S 状态的数据可以直接从其他缓存获取，这比访问内存快得多。

====== MESI States
MESI stands for “modified”, “exclusive”, “shared”, and “invalid”, the four states a given cache line can take on using this protocol. Caches using this protocol therefore maintain a two-bit state “tag” on each cacheline in addition to that line’s physical address and data.

- M - Modified (已修改)
    ** 当前缓存行中的数据已经被修改，与主内存中的数据不一致。
    ** 这个缓存是拥有该数据最新、唯一正确副本的缓存。
    ** 在某个时间点，这个被修改的数据必须被写回主内存。

- E - Exclusive (独占)
    ** 当前缓存行中的数据与主内存中的数据一致。
    ** 只有我这一个缓存拥有该数据的副本。
    ** 如果我要修改它，我可以直接进行，无需通知其他核心，因为我是唯一的拥有者。

- S - Shared (共享)
    ** 当前缓存行中的数据与主内存中的数据一致。
    ** 可能有多个缓存中都存在该数据的相同副本。
    ** 因为副本是共享的，所以我不能直接修改它。如果我想修改，必须先通知其他缓存，让它们的副本失效。

- I - Invalid (无效)
    ** 这个缓存行中的数据是过时的、不可用的。
    ** 它可能是因为其他核心修改了数据，导致本地的副本失效。
    ** 当CPU需要读取这个数据时，它不能使用这个无效的副本，而必须从其他缓存或主内存中重新获取。

====== MESI Protocol Messages
MESI 协议的消息，是缓存之间、缓存与主内存之间进行通信的语言，通过它们来协调状态的变化和数据的传输。
MESI 协议通过一个总线嗅探 机制工作，每个缓存控制器都监听总线上的所有消息。当它看到某个消息与它缓存的数据相关时，就会采取相应的行动。

一共6个消息:

Read(读):
The “read” message contains the physical address of the cache line to be read.

Read Response(读响应):
The “read response” message contains the data requested by an earlier “read” message. This “read response” message might be supplied either by memory or by one of the other caches. For example, if one of the caches has the desired data in “modified” state, that cache must supply the “read response” message.

Invalidate(使无效):
The “invalidate” message contains the physical address of the cache line to be invalidated. All other caches must remove the corresponding data from their caches and respond.

Invalidate Acknowledge(使无效应答):
A CPU receiving an “invalidate” message must respond with an “invalidate acknowledge” message after removing the specified data from its cache.

Read Invalidate(读使无效):
The “read invalidate” message contains the physical address of the cache line to be read, while at the same time directing other caches to remove the data.
Hence, it is a combination of a “read” and an “invalidate”, as indicated by its name. A “read invalidate” message requires both a “read response” and a set of “invalidate acknowledge” messages in reply.

Writeback(写回):
The “writeback” message contains both the address and the data to be written back to memory (and perhaps “snooped” into other CPUs’ caches along the way). This message permits caches to eject lines in the “modified” state as needed to make room for other data.

Q: Where does a writeback message originate from and where does it go to?
回写消息从何而来，去往何处？
回写消息可能源自某个特定的CPU，或者在某些设计中也可能源自某个CPU特定层级的缓存——甚至可能源自多个CPU共享的缓存。关键在于，某个缓存中已没有空间存放特定数据项，因此必须将其他数据驱逐出去以腾出空间。如果存在其他数据副本（位于其他缓存或内存中），那么可以直接丢弃该数据，无需发出回写消息。
然而，如果每个可能被驱逐的数据都已被修改，导致唯一的最新副本就在当前缓存中，那么就必须将这些数据项之一复制到其他地方。这个复制操作就是通过"回写消息"来完成的。
回写消息的目的地必须是能够存储新值的位置。这可能是主内存，但也可能是其他缓存。如果是其他缓存，通常会是同一CPU的更高层级缓存（例如，一级缓存可能回写到二级缓存）。不过，有些硬件设计允许跨CPU的回写操作，因此CPU 0的缓存可能会向CPU 1发送回写消息。这通常发生在CPU 1以某种方式表明了对该数据的兴趣时（例如，最近曾发出过读取请求）。
简而言之，回写消息从系统中空间不足的组件发出，由系统中能够容纳该数据的其他组件接收。

Q: What happens if two CPUs attempt to invalidate the same cache line concurrently?
One of the CPUs gains access to the shared bus first, and that CPU “wins”. The other CPU must invalidate its copy of the cache line and transmit an “invalidate acknowledge” message to the other CPU.
Of course, the losing CPU can be expected to immediately issue a “read invalidate” transaction, so the winning CPU’s victory will be quite ephemeral.

Q: When an “invalidate” message appears in a large multiprocessor, every CPU must give an “invalidate acknowledge” response. Wouldn’t the resulting “storm” of “invalidate acknowledge” responses totally saturate the system bus?
如果大规模多处理器确实以这种方式实现，这种情况确实可能发生。但大型多处理器（特别是NUMA架构机器）往往采用所谓的"基于目录"的缓存一致性协议，正是为了避免此类问题及其他相关问题。

Q: If SMP machines are really using message passing anyway, why bother with SMP at all?
既然现实中SMP机器总是会在使用消息传递，那为何还要大费周章地发展SMP技术？
过去几十年来，关于这一点确实存在一些争论。一种解释是：缓存一致性协议本身相当简洁，因此能够直接通过硬件实现，从而获得软件消息传递无法企及的带宽与延迟优势。另一种观点认为，真正原因在于经济性——大型SMP设备与小型SMP集群的成本差异决定了技术路线。亦有见解指出SMP编程模型比分布式系统更易用。但反对声音会举出HPC集群与MPI的成功案例。这场争论，至今仍在持续。

====== MESI State Diagram
12种状态转换

- (a) M->E
A cache line is written back to memory, but the CPU retains it in its cache and further retains the right to modify it. This transition requires a “writeback” message.
缓存行被写回内存，但CPU仍将其保留在缓存中，并保留修改权限。这一状态转换需要发送“写回”消息。

- (b) E->M
The CPU writes to the cache line that it already had exclusive access to. This transition does not require any messages to be sent or received.
CPU对其已有独占权的缓存行执行写入操作。此状态转换无需发送或接收任何消息。

- (c) M->I
The CPU receives a “read invalidate” message for a cache line that it has modified. The CPU must
invalidate its local copy, then respond with both a “read response” and an “invalidate acknowledge” message, both sending the data to the requesting CPU and indicating that it no longer has a local copy.
当CPU收到针对其已修改缓存行的"读无效"消息时，必须执行以下操作：首先使本地副本失效，随后同时发出"读响应"和"无效确认"消息：将数据传送至请求方CPU，表明自身不再持有本地副本。

- (d) I->M
The CPU does an atomic read-modify-write operation on a data item that was not present in its cache. It transmits a “read invalidate”, receiving the data via a “read response”. The CPU can complete the transition once it has also received a full set of “invalidate acknowledge” responses.
CPU对其缓存中不存在的数据项执行原子性的读写修改操作。它首先发出“读无效”指令，并通过“读响应”接收数据。只有在收到完整的“无效确认”响应集合后，CPU才能完成该状态转换。

- (e) S->M
The CPU does an atomic read-modify-write operation on a data item that was previously read-only in its cache. It must transmit “invalidate” messages, and
must wait for a full set of “invalidate acknowledge” responses before completing the transition.
CPU对其缓存中原本处于只读状态的数据项执行原子性读写修改操作。它必须发送"无效"消息，并且需要收齐所有"无效确认"响应后才能完成状态转换。

- (f) M->S
Some other CPU reads the cache line, and it is supplied from this CPU’s cache, which retains a readonly copy, possibly also writing it back to memory.
This transition is initiated by the reception of a “read” message, and this CPU responds with a “read response” message containing the requested data.
当其他CPU读取该缓存行时，本cpu必须以其local cacheline的数据回应，并以read response回应之前总线上的read请求。这时候该cacheline状态从Modified状态变成shared状态（有可能也会进行写回的动作）。

- (g) E->S
Some other CPU reads a data item in this cache line, and it is supplied either from this CPU’s cache or from memory. In either case, this CPU retains a readonly copy. This transition is initiated by the reception of a “read” message, and this CPU responds with a “read response” message containing the requested data.
当其他CPU读取此缓存行中的数据项时，数据可能由此CPU的缓存提供，也可能由内存提供。无论哪种情况，此CPU都会保留一份只读副本。该状态转换由接收到的"读取"消息触发，此CPU会返回包含所请求数据的"读取响应"消息。
与(f)不同，不存在写回的问题。

- (h) S->E
This CPU realizes that it will soon need to write to some data item in this cache line, and thus transmits an “invalidate” message. The CPU cannot complete the transition until it receives a full set of “invalidate acknowledge” responses, indicating that no other CPU has this cacheline in its cache. In other words, this CPU is the only CPU caching it.
此CPU预判其不久将需要修改该缓存行中的某个数据项，因而主动发出"无效"消息。在收到完整的"无效确认"响应集之前，CPU无法完成状态转换，一旦收到所有的响应，表明其他CPU的缓存中均已不存在该缓存行。换言之，此时该CPU已成为唯一缓存此数据的处理器。

- (i) E->I
Some other CPU does an atomic read-modify-write operation on a data item in a cache line held only in this CPU’s cache, so this CPU invalidates it from its cache. This transition is initiated by the reception of a “read invalidate” message, and this CPU responds with both a “read response” and an “invalidate acknowledge” message.
当其他CPU对仅存在于本CPU缓存中的缓存行内的数据项执行原子性读-修改-写操作时，本CPU会将该缓存行从自身缓存中置为无效。此状态转换由接收到“读-无效”消息触发，本CPU将同时回复“读响应”与“无效确认”消息作为响应。

- (j) I->E
This CPU does a store to a data item in a cache line that was not in its cache, and thus transmits a “read invalidate” message. The CPU cannot complete the transition until it receives the “read response” and a full set of “invalidate acknowledge” messages. The cache line will presumably transition to “modified” state via transition (b) as soon as the actual store completes.
本CPU对不在自身缓存中的缓存行数据项执行存储操作，因此发送“读-无效”消息。该CPU必须接收到“读响应”及完整的(所有其他cpu的)“无效确认”消息集合后才能完成状态转换。在实际存储操作完成后，该缓存行预计将通过(b)转换路径进入“已修改”状态。

- (k) I->S
This CPU loads a data item in a cache line that was not in its cache. The CPU transmits a “read” message, and completes the transition upon receiving the corresponding “read response”.
本CPU对不在自身缓存中的缓存行执行数据加载操作，因此发送"读"请求消息，之后接收到其他的cpu local cache或者memory的"读响应"消息，于是完成此状态转换，即将该cacheline从Invalid状态迁移到shared状态。

- (l) S->I
Some other CPU does a store to a data item in this cache line, but holds this cache line in read-only state due to its being held in other CPUs’ caches (such as the current CPU’s cache). This transition is initiated by the reception of an “invalidate” message, and this CPU responds with an “invalidate acknowledge” message.
当cacheline处于shared状态时，说明在多个cpu的local cache中存在只读副本，一旦其中一个cpu想要执行数据写入操作，必须先通过invalidate获取该数据的独占权，而其他的CPU会以invalidate acknowledge回应，并将其cacheline从shared状态修改成invalid状态。

Q: How does the hardware handle the delayed transitions described above?
A: Usually by adding additional states, though these additional states need not be actually stored with the cache line, due to the fact that only a few lines at a time will be transitioning. The need to delay transitions is but one issue that results in real-world cache coherence protocols being much more complex than the over-simplified MESI protocol described in this appendix. Hennessy and Patterson’s classic introduction to computer architecture [HP95](即《Computer Architecture: A Quantitative Approach》) covers many of these issues.

====== MESI Protocol Example
perfbook C2.4

Q: What sequence of operations would put the CPUs’ caches all back into the “invalid” state?
A: There is no such sequence, at least in absence of special “flush my cache” instructions in the CPU’s instruction set. Most CPUs do have such instructions.
问：需要怎样的操作序列才能让所有CPU缓存回到“无效”状态？
答：至少在没有CPU指令集提供的特殊“清空缓存”指令时，不存在这样的操作序列。目前大多数CPU都配备了这类专用指令。

===== Stores Result in Unnecessary Stalls
====== 背景
its performance for the first write to a given cache line is quite poor.
使无效与使无效应答之间存在延迟。

====== Store Buffers
One way to prevent this unnecessary stalling of writes is to add “store buffers” between each CPU and its cache.

Q: But then why do uniprocessors also have store buffers?
A: Because the purpose of store buffers is not just to hide acknowledgement latencies in multiprocessor cache coherence protocols, but to hide memory latencies in
general. Because memory is much slower than is cache on uniprocessors, store buffers on uniprocessors can help to hide write-miss memory latencies.
问: 那为何单处理器系统也需要存储缓冲区？
答: 因为存储缓冲区的作用不仅限于掩盖多处理器缓存一致性协议中的确认延迟，更在于普遍掩盖内存访问延迟。在单处理器系统中，由于内存速度远低于缓存速度，存储缓冲区有助于掩盖写入未命中时的内存访问延迟。

Q: So store-buffer entries are variable length? Isn’t that difficult to implement in hardware?
A: Here are two ways for hardware to easily handle variable length stores.
First, each store-buffer entry could be a single byte wide. Then an 64-bit store would consume eight store-buffer entries. This approach is simple and flexible, but one disadvantage is that each entry would need to replicate much of the address that was stored to.
Second, each store-buffer entry could be double the size of a cache line, with half of the bits containing the values stored, and the other half indicating which bits had been stored to. So, assuming a 32-bit cache line, a single-byte store of 0x5a to the low-order byte of a given cache line would result in 0xXXXXXX5a for the first half and 0x000000ff for the second half, where the values labeled X are arbitrary because they would be ignored. This approach allows multiple consecutive stores corresponding to a given cache line to be merged into a single store-buffer entry, but is space-inefficient for random stores of single bytes.
Much more complex and efficient schemes are of course used by actual hardware designers. 
问：那么存储缓冲区的条目是可变长度的？这在硬件上实现起来不是很难吗？
答：硬件可以通过以下两种方式轻松处理可变长度的存储操作：
首先，每个存储缓冲区条目可以设计为单字节宽度。这样，一次64位存储操作会占用八个存储缓冲区条目。这种方法简单灵活，但缺点在于每个条目都需要重复存储大量与目标地址相关的信息。
其次，每个存储缓冲区条目可以设为缓存行大小的两倍：其中一半比特位用于存储具体数值，另一半则用作位掩码来标识哪些位已被写入。假设采用32位缓存行，当向某缓存线低字节存储单字节数据0x5a时，前半部分会记录为0xXXXXXX5a，后半部分位掩码则记为0x000000ff（标有X的数值可任意，因为它们会被忽略）。这种方法允许将针对同一缓存行的多个连续存储操作合并到单个缓冲区条目中，但对于随机单字节存储操作则存在空间效率低下的问题。
实际硬件设计人员当然会采用更为复杂高效的实现方案。

These store buffers are local to a given CPU or, on systems with hardware multi threading, local to a given core.

====== Store Forwarding
Breaking this guarantee is violently counter-intuitive to software types, so much so that the hardware guys took pity and implemented “store forwarding”, where each CPU refers to (or “snoops”) its store buffer as well as its cache when performing loads, as shown in Figure C.6. In other words, a given CPU’s stores are directly forwarded to its subsequent loads, without having to pass through the cache.

当CPU执行一个读取操作时，它需要从内存中获取数据。但如果在它之前刚刚执行了一个写入操作到同一个内存地址，那么这个最新的数据可能还在CPU的存储缓冲区中，还没来得及被写入到缓存/内存里。
存储转发/前向存储机制就是：在这种情况下，CPU会绕过缓存，直接从自己的存储缓冲区中把这个“尚未提交”的数据转发给后续的读取操作。

作用范围：存储转发通常只在同一个CPU核心内部有效。一个核心的存储操作不能被转发到另一个核心。
存储缓冲区：这是实现该技术的关键硬件结构，用于临时存放已执行但尚未提交到缓存层的写入数据。
存储转发停顿：虽然存储转发是优化，但在某些复杂情况下它也可能导致性能下降。例如，当一次读取操作的部分数据来自存储缓冲区，而另一部分数据需要从缓存中获取时（比如读写对象地址没对齐），CPU可能不得不等待存储操作完全提交到缓存后，才能从缓存执行一个完整的读取，这个过程被称为“存储转发停顿”。

====== Store Buffers and Memory Barriers
[source, c]
----
// variables “a” and “b” initially zero
void foo(void)
{
    a=1;
    smp_mb();
    b=1;
}

void bar(void)
{
    while (b == 0) continue;
    assert(a == 1);
}
----

The memory barrier smp_mb() will cause the CPU to flush its store buffer before applying each subsequent store to its variable’s cache line. The CPU could either simply stall until the store buffer was empty before proceeding, or it could use the store buffer to hold subsequent stores until all of the prior entries in the store buffer had been applied.

===== Store Sequences Result in Unnecessary Stalls
====== 背景
Unfortunately, each store buffer must be relatively small, which means that a CPU executing a modest sequence of stores can fill its store buffer (for example, if all of them result in cache misses). At that point, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing. This same situation can arise immediately after a memory barrier, when all subsequent store instructions must wait for invalidations to complete, regardless of whether or not these stores result in cache misses.
遗憾的是，每个存储缓冲区的容量都相对有限，这意味着即使CPU仅执行数量适中的存储指令序列，也可能将其存储缓冲区填满（例如，如果所有这些存储操作均导致缓存未命中）。此时，CPU将不得不再次等待无效化操作完成，以便清空其存储缓冲区，之后才能继续执行后续指令。同样的情况会立即发生在内存屏障之后——届时所有后续存储指令都必须等待无效化操作完成，无论这些存储操作是否会引起缓存未命中。
This situation can be improved by making invalidate acknowledge messages arrive more quickly. One way of accomplishing this is to use per-CPU queues of invalidate messages, or “invalidate queues”.

====== Invalidate Queues
invalidate acknowledge不能尽快回复的主要原因:
One reason that invalidate acknowledge messages can take so long is that they must ensure that the corresponding cache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache. In addition, if a large number of invalidate messages arrive in a short time period, a given CPU might fall behind in processing them, thus possibly stalling all the other CPUs.

However, the CPU need not actually invalidate the cache line before sending the acknowledgement. It could instead queue the invalidate message with the understanding that the message will be processed before the CPU sends any further messages regarding that cache line.
但事实上，CPU其实不需要完成invalidate操作就可以回送acknowledgement消息。该CPU完全可以将无效化消息暂存于队列中，其前提条件是必须保证在后续发送涉及该缓存行的任何相关消息之前，这些暂存的invalidate消息都已被处理完毕。

====== Invalidate Queues and Invalidate Acknowledge
A CPU with an invalidate queue may acknowledge an invalidate message as soon as it is placed in the queue, instead of having to wait until the corresponding line is actually invalidated. Of course, the CPU must refer to its invalidate queue when preparing to transmit invalidation messages—if an entry for the corresponding cache line is in the invalidate queue, the CPU cannot immediately transmit the invalidate message; it must instead wait until the invalidate-queue entry has been processed.
当然，在准备发送无效化消息时，CPU 必须查询自身的无效化队列——如果队列中已存在针对该缓存行的条目，则 CPU 不能立即发送无效化消息，而必须等待队列中的对应条目被处理完毕。

Placing an entry into the invalidate queue is essentially a promise by the CPU to process that entry before transmitting any MESI protocol messages regarding that cache line. As long as the corresponding data structures are not highly contended, the CPU will rarely be inconvenienced by such a promise.
However, the fact that invalidate messages can be buffered in the invalidate queue provides additional oppor
tunity for memory-misordering, as discussed in the next section.
将条目加入无效化队列，本质上是 CPU 做出的一项承诺：在发送任何涉及该缓存行的 MESI 协议消息之前，必须先处理该队列条目。只要对应的数据结构没有处于高度竞争状态，这种承诺通常不会对 CPU 造成性能影响。
然而，正如下一节将要讨论的，无效化消息能在无效化队列中缓冲的特性，为内存乱序创造了新的可能性。

====== Invalidate Queues and Memory Barriers
Let us suppose that CPUs queue invalidation requests, but respond to them immediately. This approach minimizes the cache-invalidation latency seen by CPUs doing stores, but can defeat memory barriers, as seen in the following example.
[source, c]
----
// variables “a” and “b” initially zero
// “a” is replicated read-only (MESI “shared” state)
// “b” is owned by CPU 0 (MESI “exclusive” or “modified” state)
void foo(void) // cpu0 execute
{
    a=1;
    smp_mb();
    b=1;
}

void bar(void) // cpu1 execute
{
    while (b == 0) continue;
    assert(a == 1);
}
----

Then the sequence of operations might be as follows:

(1) CPU 0 executes a = 1. The corresponding cache line is read-only in CPU 0’s cache, so CPU 0 places the new value of “a” in its store buffer and transmits an “invalidate” message in order to flush the corresponding cache line from CPU 1’s cache.
CPU 0 执行 a = 1。对应的缓存行在 CPU 0 的缓存中处于只读状态，因此 CPU 0 将“a”的新值放入store buffer，并发送一个“invalidate即使无效”消息，以便从 CPU 1 的缓存中清除对应的缓存行。

(2) CPU 1 executes while (b == 0)continue, but the cache line containing “b” is not in its cache. It therefore transmits a “read” message.
CPU 1 执行 while (b == 0) continue，但包含“b”的缓存行不在其缓存中。因此它发送一个“读”消息。

(3) CPU 1 receives CPU 0’s “invalidate” message, queues it, and immediately responds to it.
CPU 1 收到 CPU 0 的“无效”消息，将其加入队列，并立即回复/响应该消息。

(4) CPU 0 receives the response from CPU 1, and is therefore free to proceed past the smp_mb() on line 4 above, moving the value of “a” from its store buffer to its cache line.
CPU 0 收到来自 CPU 1 的回复，因此可以继续执行第 4 行的 smp_mb() 之后的指令，将“a”的值从其存储缓冲区移动到其缓存行中。

(5) CPU 0 executes b = 1. It already owns this cache line (in other words, the cache line is already in either the “modified” or the “exclusive” state), so it stores the new value of “b” in its cache line.
CPU 0 执行 b = 1。它已经拥有该缓存行（即该缓存行已处于“修改”或“独占”状态），因此它将“b”的新值存储到其缓存行中。

(6) CPU 0 receives the “read” message, and transmits the cache line containing the now-updated value of “b” to CPU 1, also marking the line as “shared” in its own cache.
CPU 0 收到“读”消息，并将包含已更新值“b”的缓存行发送给 CPU 1，并标记该cacheline为shared状态。

(7) CPU 1 receives the cache line containing “b” and installs it in its cache.
CPU 1 收到包含“b”的缓存行，并将其将其应用到本地缓存。

(8) CPU 1 can now finish executing while (b ==0) continue, and since it finds that the value of “b” is 1, it proceeds to the next statement.
CPU 1 现在可以完成 while (b == 0) continue 的执行，由于它发现“b”的值为 1，于是继续执行下一条语句。

(9) CPU 1 executes the assert(a == 1), and, since the old value of “a” is still in CPU 1’s cache, this assertion fails.
CPU 1 执行 assert(a == 1)，由于“a”的旧值仍在 CPU 1 的缓存中，该断言失败。

(10) Despite the assertion failure, CPU 1 processes the queued “invalidate” message, and (tardily) invalidates the cache line containing “a” from its own cache.
尽管断言失败，CPU 1 仍处理队列中的“使无效”消息，并（延迟地）从其自己的缓存中使包含“a”的缓存行无效。

There is clearly not much point in accelerating invalidation responses if doing so causes memory barriers to effectively be ignored. However, the memory-barrier instructions can interact with the invalidate queue, so that when a given CPU executes a memory barrier, it marks all the entries currently in its invalidate queue, and forces any subsequent load to wait until all marked entries have been applied to the CPU’s cache.
如果加速无效响应会导致内存屏障失效，那么这样做显然没有意义。然而，内存屏障指令可以与无效队列交互，使得当某个 CPU 执行内存屏障时，它会标记当前在其无效队列中的所有条目，这些被标注的项次被称为marked entries，而随后CPU执行的任何的load操作都需要等到Invalidate Queue中所有marked entries完成对cacheline的操作之后才能进行。

因此，要想保证程序逻辑正确，需要给bar函数增加内存屏障的操作，具体如下:
[source, c]
----
// variables “a” and “b” initially zero
// “a” is replicated read-only (MESI “shared” state)
// “b” is owned by CPU 0 (MESI “exclusive” or “modified” state)
void foo(void) // cpu0 execute
{
    a=1;
    smp_mb();
    b=1;
}

void bar(void) // cpu1 execute
{
    while (b == 0) continue;
    smp_mb();
    assert(a == 1);
}
----
同上(bar函数没有加内存屏障)，前面7个步骤是一样的，到了第8步，执行开始不同了:

(8) CPU 1 can now finish executing while (b ==0) continue, and since it finds that the value of “b” is 1, it proceeds to the next statement, which is now a memory barrier.
CPU 1 此时可完成执行 while (b ==0) continue 循环，由于检测到"b"的值为1，便继续执行下一语句，此时遇到内存屏障。

(9) CPU 1 must now stall until it processes all preexisting messages in its invalidation queue.
CPU 1 必须暂停执行，直至其处理完失效队列中的所有待处理消息。

(10) CPU 1 now processes the queued “invalidate” message, and invalidates the cache line containing “a” from its own cache.
CPU 1 开始处理队列中的"失效"消息，将包含"a"的缓存行从自身缓存中置为无效。

(11) CPU 1 executes the assert(a == 1), and, since the cache line containing “a” is no longer in CPU 1’s cache, it transmits a “read” message.
CPU 1 执行 assert(a == 1) 断言，由于包含"a"的缓存行已不在其缓存中，遂发送"读"消息。

(12) CPU 0 responds to this “read” message with the cache line containing the new value of “a”.
CPU 0 响应此"读取"消息，传回包含新值"a"的缓存行。

(13) CPU 1 receives this cache line, which contains a value of 1 for “a”, so that the assertion does not trigger.
CPU 1 接收到该缓存行，其中"a"的值为1，因此断言未触发。

===== Read and Write Memory Barriers
In the previous section, memory barriers were used to mark entries in both the store buffer and the invalidate queue. But in our code fragment, foo() had no reason to
do anything with the invalidate queue, and bar() similarly had no reason to do anything with the store buffer. Many CPU architectures therefore provide weaker memory-barrier instructions that do only one or the other of these two. Roughly speaking, a “read memory barrier” marks only the invalidate queue (and snoops entries in the
store buffer) and a “write memory barrier” marks only the store buffer, while a full-fledged memory barrier does all of the above.

The software-visible effect of these hardware mechanisms is that a read memory barrier orders only loads on the CPU that executes it, so that all loads preceding the read memory barrier will appear to have completed before any load following the read memory barrier. Similarly, a write memory barrier orders only stores, again on the CPU that executes it, and again so that all stores preceding the write memory barrier will appear to have completed before any store following the write memory barrier. A full-fledged memory barrier orders both loads and stores, but again only on the CPU executing the memory barrier.

改进后的foo()和bar():
[source, c]
----
void foo(void)
{
    a=1;
    smp_wmb();
    b=1;
}

void bar(void)
{
    while (b == 0) continue;
    smp_rmb();
    assert(a == 1);
}
----
Some computers have even more flavors of memory barriers, but understanding these three variants will provide a good introduction to memory barriers in general.

===== 存储缓冲区与失效队列
- Store Buffer(存储缓冲区/写缓冲区)
是CPU核心内部的一个小型、高速的硬件队列，用于临时存放CPU核心想要写入到缓存（Cache）中的数据。
https://developer.arm.com/documentation/ddi0489/f/memory-system/l1-caches/store-buffer
https://community.intel.com/t5/Software-Tuning-Performance/Purpose-of-Load-Buffer-in-x86/td-p/1091736

- Invalidate Queue(失效队列/无效化队列)

特性	失效队列（无效化队列/Invalidate Queue）	存储缓冲区（写缓冲区/Store Buffer）
解决的问题	优化 “读” 操作，加速对缓存失效确认的响应。	优化 “写” 操作，让CPU不必等待写入完成。
工作原理	快速接收并确认其他CPU发来的“失效”消息，将其排队，稍后再处理。	CPU将“写”指令的结果先暂存于此，然后继续执行，由后台完成写入缓存。
位于何处	CPU的缓存控制器中（更靠近缓存一致性协议逻辑）。	CPU核心与缓存之间。
主要目的	隐藏读延迟，避免CPU因等待缓存行失效而停滞。	隐藏写延迟，实现写操作的非阻塞。
可能引起的问题	读取旧数据：CPU可能从自己已失效（但还在队列中）的缓存行里读取到旧数据。	看到最新写入：其他CPU可能看不到本CPU刚刚写入的值（因为还在缓冲区里）。
需要何种内存屏障	读内存屏障 确保在处理新的读操作前，先清空失效队列。	写内存屏障 确保在处理新的写操作前，先清空存储缓冲区。

Q: 存储缓冲区与失效队列有多大
大致大小	约 10 到 64 条目	约 8 到 32 条目
确定性信息	无法公开获得，是核心商业机密。	无法公开获得，是核心商业机密。
对程序员的意义
1. 理解其存在和有限性。	1. 理解其存在和有限性。
2. 明白它是写操作乱序的主要来源。	2. 明白它是读操作看到旧数据的主要来源。
3. 知道写内存屏障会作用于它。	3. 知道读内存屏障会作用于它。

Q: 满了怎么办？
CPU核心会被强制“停滞”，直到有空闲条目可用。这被称为 “流水线停滞” 或 “内存顺序停滞” ，是性能杀手。

Q: 具体来说，存储缓冲区如果满了怎么办？
场景: CPU核心正在疯狂地执行存储指令（比如，在一个紧凑的循环中修改多个变量）。
核心只能空转，等待存储缓冲区出现空位；等待期间，存储缓冲区会持续工作。

Q: 具体来说，失效队列如果满了怎么办？
场景: 系统中有多个CPU核心正在频繁地修改共享数据，导致某个核心收到了大量的“失效”消息。
必须阻塞发送方，它会延迟对新的“失效”消息的确认，直到它能在失效队列中腾出空间来处理这个新请求；为了腾出空间，缓存控制器必须加速处理队列中现有的失效条目-即真正地查找并无效化本地缓存中对应的缓存行。

===== Example Memory-Barrier Sequences
====== Ordering-Hostile Architecture
let us insteaddesign a mythical but maximally memory-ordering-hostile computer architecture.
This hardware must obey the following ordering constraints [McK05a, McK05b]:
1. Each CPU will always perceive its own memory accesses as occurring in program order.
2. CPUs will reorder a given operation with a store only if the two operations are referencing different locations.
3. All of a given CPU’s loads preceding a read memory barrier (smp_rmb()) will be perceived by all CPUs to precede any loads following that read memory barrier.
4. All of a given CPU’s stores preceding a write memory barrier (smp_wmb()) will be perceived by all CPUs to precede any stores following that write memory barrier.
5. All of a given CPU’s accesses (loads and stores) preceding a full memory barrier (smp_mb()) will be perceived by all CPUs to precede any accesses following that memory barrier.
我们来设计一个虚构的、在内存排序上极度不友好的计算机架构。
该硬件必须遵守以下排序约束:
1. 对于每个CPU而言，从它自己的角度看，其内存访问的顺序总是符合program order的。
2. 仅当两个操作访问不同地址时，CPU 才会对某个操作与一次存储进行重排序。
3. 在某个 CPU 中，位于读内存屏障（smp_rmb()）之前的所有加载操作，在所有 CPU 看来，都必须先于该屏障之后的任何加载操作。
4. 在某个 CPU 中，位于写内存屏障（smp_wmb()）之前的所有存储操作，在所有 CPU 看来，都必须先于该屏障之后的任何存储操作。
5. 在某个 CPU 中，位于全内存屏障（smp_mb()）之前的所有访问（加载和存储），在所有 CPU 看来，都必须先于该屏障之后的任何访问。

Q: Does the guarantee that each CPU sees its own memory accesses in order also guarantee that each user-level thread will see its own memory accesses in order? Why or why not?
A: No. Consider the case where a thread migrates from one CPU to another, and where the destination CPU perceives the source CPU’s recent memory operations out of order.
To preserve user-mode sanity, kernel hackers must use memory barriers in the context-switch path. However, the locking already required to safely do a context switch
should automatically provide the memory barriers needed to cause the user-level task to see its own accesses in order. That said, if you are designing a super-optimized
scheduler, either in the kernel or at user level, please keep this scenario in mind!
问题：保证每个CPU按顺序看到自己的内存访问，是否也保证每个用户级线程按顺序看到自己的内存访问？
为什么能或为什么不能？
答：不能。考虑这样一种情况：一个线程从一个CPU迁移到另一个CPU，而目标CPU可能以乱序的方式感知源CPU最近的内存操作。
为保证用户态程序的正常运行，内核开发者人员必须在上下文切换路径中使用内存屏障。然而，安全执行上下文切换所需的锁定操作通常已经自动提供了所需的内存屏障，从而使用户级任务能够按顺序看到自己的内存访问。尽管如此，如果您正在设计一个超级优化的调度器（无论是在内核层还是用户层），请务必牢记这种情况！

===== 参考
perfbook C2
《Parallel Computer Architecture A Hardware / Software Approach》
《A Primer on Memory Consistency and Cache Coherence》2nd

==== Q&A
Q: memory order vs. cache coherence
https://course.ece.cmu.edu/~ece847c/S15/lib/exe/fetch.php?media=part2_2_sorin12.pdf

Q: memory order vs. atomic
https://stackoverflow.com/questions/15056237/which-is-more-efficient-basic-mutex-lock-or-atomic-integer

==== 可见性问题

==== cpu视角
x86: https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.html

chapter8 multi-processor management
8.2 memory ordering
8.2.5 strengthening or weakening the memory-order model:

• SFENCE — Serializes all store (write) operations that occurred prior to the SFENCE instruction in the program instruction stream, but does not affect load operations.

• LFENCE — Serializes all load (read) operations that occurred prior to the LFENCE instruction in the program instruction stream, but does not affect store operations.

• MFENCE — Serializes all store and load operations that occurred prior to the MFENCE instruction in the program instruction stream.

==== kernel视角
https://github.com/orientye/understanding-the-linux-kernel/blob/main/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E5%86%85%E6%A0%B8/%E8%BF%9B%E7%A8%8B/%E5%90%8C%E6%AD%A5.asc#barrier

==== c++

===== 概念
https://en.cppreference.com/w/cpp/atomic/memory_order

windows:
https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/acquire-and-release-semantics

Acquire semantics is a property that can only apply to operations that read from shared memory, whether they are read-modify-write operations or plain loads. The operation is then considered a read-acquire. Acquire semantics prevent memory reordering of the read-acquire with any read or write operation that follows it in program order.

Release semantics is a property that can only apply to operations that write to shared memory, whether they are read-modify-write operations or plain stores. The operation is then considered a write-release. Release semantics prevent memory reordering of the write-release with any read or write operation that precedes it in program order.

Fence Semantics
A fence semantics combines both acquire and release semantics behavior.

- Sequenced-before

- Carries dependency

- Modification order

- Release sequence

- Dependency-ordered before

- Inter-thread happens-before

- Happens-before

- Visible side-effects

- Consume operation

- Acquire opertation

- Release operation

- Synchronizes-with

===== 本质
本质上两个问题:

    【1】______不可以重排到______的前面/后面
    【2】______对谁______可见

===== Q&A
Q: 如果变量是函数的参数呢？

===== relaxed
https://en.cppreference.com/w/cpp/atomic/memory_order.html#Relaxed_ordering

===== release acquire
https://en.cppreference.com/w/cpp/atomic/memory_order.html#Release-Acquire_ordering

Q: memory_order_release 与 smp_wmb()
Q: memory_order_acquire 与 smp_rmb()

===== release consume
https://en.cppreference.com/w/cpp/atomic/memory_order.html#Release-Consume_ordering
release-consume 被废弃的根本原因是其设计复杂性（对编译器和程序员而言）与其实践中的实际收益（性能优势）严重不匹配。它为一个在大多数硬件上难以实现的、微小的优化，引入了巨大的正确性风险和维护负担。最终，C++ 标准委员会选择了安全和简单，而不是极致的、脆弱的性能。

===== sequentially consistent
Q: 上述例子如果换成acquire/release，结果?
Q: seq_cst做了什么? 什么情况下使用?

===== thread_fence
std::atomic_thread_fence

extern "C" void atomic_thread_fence( std::memory_order order ) noexcept;

Establishes memory synchronization ordering of non-atomic and relaxed atomic accesses, as instructed by order, without an associated atomic operation.

===== implement
以memory_order_seq_cst为例:
Ubuntu(g++, VM, Intel i5 4 core):    汇编指令mfence
Mac OSX(g++,  Intel i5 2 core):      汇编指令xchgl(= lock xchgl)
Win10(VS2015, Intel i5 4 core):      _ReadWriteBarrier, _InterlockedExchange

is_lock_free

===== 应用示例
https://github.com/facebook/rocksdb/blob/master/memtable/skiplist.h
https://github.com/apache/incubator-brpc/blob/master/src/bthread/work_stealing_queue.h

===== 参考
https://en.cppreference.com/w/cpp/language/memory_model

==== java
https://github.com/orientye/understand/blob/main/lan/java.asc#Java-Memory-Model-and-Thread

==== 正确性
===== ThreadSanitizer
https://clang.llvm.org/docs/ThreadSanitizer.html

===== relacy
https://github.com/dvyukov/relacy

===== cppmem
http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/

===== 形式化验证

==== 参考
perfbook: Chapter 15 Advanced Synchronization: Memory Ordering
