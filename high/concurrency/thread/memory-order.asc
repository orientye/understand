:toc:
:toclevels: 5
:hardbreaks-option:

=== memory order

==== reorder
考虑如下情形:
(1) 编译器在编译程序的过程中，对代码会进行调整；
(2) CPU在执行指令的过程中，对指令会进行重排。
编译器重排序：在将源代码编译成机器码时，编译器会进行优化，调整指令顺序，前提是保证在单线程上下文中的最终结果不变。
CPU指令级重排序：CPU在执行时，动态地调整指令的执行顺序。这是最核心的重排序。由于存在多级缓存，一个CPU核心对数据的修改，在最终写入主内存并被其他核心看到之前，其顺序可能对其他核心来说是被打乱的。
显然，有时候这些优化并不符合预期(第一种情况可能发生编译乱序，第二种情况可能发生执行乱序)，为了防止这两种情况，这就需要compiler barrier和memory barrier。

Q: 单线程会发生指令重排吗(同理，运行在单个CPU core上的多线程)
A: 会，但不会影响结果

Q: 什么情况下肯定不会重排?
处理器必须能正确处理指令依赖情况保证程序能得出正确的执行结果。
例如指令1把地址A中的值加100，指令2把地址A中的值乘以7，指令3把地址B中的值减去60，则指令1和指令2是有依赖的，它们之间的顺序不能重排: (A+100)*7与A*7+100显然不相等，但指令3可以重排到指令1或指令2之前。

==== compile-time memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Compile-time_memory_ordering
编译器重排序是指编译器在将源代码翻译成目标代码（如汇编或机器码）的过程中，为了优化性能，在不改变程序单线程语义的前提下，重新排列指令的执行顺序。

==== runtime memory ordering
https://en.wikipedia.org/wiki/Memory_ordering#Runtime_memory_ordering

CPU在什么情况下会reorder呢？

对于有前后有依赖的指令，CPU一般不会reorder(Alpha架构除外)。
例如: a = 5; b = a + 1; 这两条指令存在依赖关系，不会被cpu重排顺序。

对于没有前后依赖关系的指令，CPU就有可能对这些指令进行重排(除非使用memory barrier进行一些显示控制)，具体的力度则与CPU体系结构相关:

    x86是一种strong order(也叫TSO，total store order):
        同一CPU执行的load指令后接load指令(L-L)，store指令后接store指令(S-S)，load指令后接store指令(L-S):
            均不能交换指令的执行顺序
        仅store指令后接load指令(S-L)才可以

    ARM则是一种weak order:
        只要没有依赖关系，load指令和store指令就可任意交换。

==== Store Buffer（存储缓冲区/写缓冲区）
是CPU核心内部的一个小型、高速的硬件队列，用于临时存放CPU核心想要写入到缓存（Cache）中的数据。
https://developer.arm.com/documentation/ddi0489/f/memory-system/l1-caches/store-buffer
https://community.intel.com/t5/Software-Tuning-Performance/Purpose-of-Load-Buffer-in-x86/td-p/1091736

==== 示例

    // 初始： x = 0, y = 0
    // CPU 0 (Thread 1)        // CPU 1 (Thread 2)
    x = 1;                    y = 1;
    int r1 = y;               int r2 = x;
    可能的结果：从逻辑上看，(r1, r2) 不可能是 (0, 0)，但实际情况却有可能。

- 为什么
    ** 在CPU 0上：
        *** x = 1; 被执行。这个写操作被放入了CPU 0的Store Buffer，但还没提交到缓存。此时，对于其他核心（包括CPU 1）来说，x 的值仍然是 0。
        *** int r1 = y; 被执行。CPU 0去读 y。假设此时CPU 1的 y=1 也还在它的Store Buffer里，那么CPU 0读到的 y 就是旧值 0。所以 r1 = 0。
    ** 在CPU 1上：发生着对称的过程。
        *** y = 1; 进入Store Buffer。
        *** int r2 = x; 读 x，此时CPU 0的 x=1 还在Store Buffer里，所以读到 0。r2 = 0。
    ** 最终，两个线程都读到了对方的旧值 0。
    ** 从程序顺序看：每个线程都是先Store后Load。
    ** 从实际结果看：仿佛是Load操作越过了还在Store Buffer中的Store操作先执行了。这就是 StoreLoad 重排序。

- 解决方案：内存屏障
    ** 为了解决Store Buffer带来的可见性和顺序问题，CPU提供了内存屏障指令。
    ** 写屏障（Store Barrier / SFENCE）：
        *** 清空Store Buffer。
        *** 在写屏障之前的所有Store操作，都必须被刷入Store Buffer（并开始提交流程）。
        *** 在写屏障之后的Store操作，必须等到写屏障执行完后才能进入Store Buffer。
        *** 这保证了写屏障之前的Store操作，一定先于之后的Store操作对其他核心可见。（解决了StoreStore重排序）
    ** 全能屏障（Full Barrier / MFENCE）：
        *** 功能更强，通常包括清空Store Buffer和等待Load Buffer（另一个用于优化读的组件）。
        *** 它能防止StoreLoad重排序，即确保屏障之前的所有Store操作都对其他核心可见之后，才执行屏障之后的Load操作。

==== memory barrier
memory barrier就像一个栅栏一样，隔开了在其前面和后面的指令。
"barrier"前面的指令不能与后面的指令进行调换；
如果指令均处在其前面，或者均处在其后面，只要没有违反当前CPU的memory order的规则，则是可以调换的。

memory barrier约束了CPU的行为，同时也约束了编译器的行为，即memory barrier也隐含了compiler barrier语义。

==== Q&A
Q: memory order vs. cache coherence
https://course.ece.cmu.edu/~ece847c/S15/lib/exe/fetch.php?media=part2_2_sorin12.pdf

Q: memory order vs. atomic
https://stackoverflow.com/questions/15056237/which-is-more-efficient-basic-mutex-lock-or-atomic-integer

==== 可见性问题

==== cpu视角
x86: https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.html

chapter8 multi-processor management
8.2 memory ordering
8.2.5 strengthening or weakening the memory-order model:

• SFENCE — Serializes all store (write) operations that occurred prior to the SFENCE instruction in the program instruction stream, but does not affect load operations.

• LFENCE — Serializes all load (read) operations that occurred prior to the LFENCE instruction in the program instruction stream, but does not affect store operations.

• MFENCE — Serializes all store and load operations that occurred prior to the MFENCE instruction in the program instruction stream.

==== kernel视角
https://github.com/orientye/understanding-the-linux-kernel/blob/main/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E5%86%85%E6%A0%B8/%E8%BF%9B%E7%A8%8B/%E5%90%8C%E6%AD%A5.asc#barrier

==== c++

===== 概念
https://en.cppreference.com/w/cpp/atomic/memory_order

Acquire semantics is a property that can only apply to operations that read from shared memory, whether they are read-modify-write operations or plain loads. The operation is then considered a read-acquire. Acquire semantics prevent memory reordering of the read-acquire with any read or write operation that follows it in program order.

Release semantics is a property that can only apply to operations that write to shared memory, whether they are read-modify-write operations or plain stores. The operation is then considered a write-release. Release semantics prevent memory reordering of the write-release with any read or write operation that precedes it in program order.

Fence Semantics
A fence semantics combines both acquire and release semantics behavior.

- Sequenced-before

- Carries dependency

- Modification order

- Release sequence

- Dependency-ordered before

- Inter-thread happens-before

- Happens-before

- Visible side-effects

- Consume operation

- Acquire opertation

- Release operation

- Synchronizes-with

===== 本质
本质上两个问题:

    【1】______不可以重排到______的前面/后面
    【2】______对谁______可见

===== Q&A
Q: 如果变量是函数的参数呢？

===== relaxed

===== release acquire

===== release consume

===== sequentially consistent
Q: 上述例子如果换成acquire/release，结果?
Q: seq_cst做了什么? 什么情况下使用?

===== thread_fence
std::atomic_thread_fence

extern "C" void atomic_thread_fence( std::memory_order order ) noexcept;

Establishes memory synchronization ordering of non-atomic and relaxed atomic accesses, as instructed by order, without an associated atomic operation.

===== implement
以memory_order_seq_cst为例:
Ubuntu(g++, VM, Intel i5 4 core):    汇编指令mfence
Mac OSX(g++,  Intel i5 2 core):      汇编指令xchgl(= lock xchgl)
Win10(VS2015, Intel i5 4 core):      _ReadWriteBarrier, _InterlockedExchange

is_lock_free

===== 应用示例
https://github.com/facebook/rocksdb/blob/master/memtable/skiplist.h
https://github.com/apache/incubator-brpc/blob/master/src/bthread/work_stealing_queue.h

===== 参考
https://en.cppreference.com/w/cpp/language/memory_model

==== java
https://github.com/orientye/understand/blob/main/lan/java.asc#Java-Memory-Model-and-Thread
