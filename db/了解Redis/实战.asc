:toc:
:toclevels: 5
:hardbreaks-option:

== 实战

=== 缓存与DB
==== 读流程

    hit: 返回数据
    否则miss: 从DB中读取, 然后放入缓存

==== 写流程

    更新缓存:
        特点: 数据库和缓存都要写入
        优点: 不会增加一次miss, 效率可能会高一些
        缺点: 从一致性的角度, 有时候淘汰缓存可能会更好些

    淘汰缓存/删除缓存:
        特点: 只会写入数据库
        优点: 简单些
        缺点: 会增加一次miss

    先操作数据库，还是先操作缓存？
    更新缓存，还是淘汰/删除缓存？
    需要根据具体的场景综合考虑一致性及性能问题，具体参考下面的一致性问题:

==== 一致性问题

    ▪ 什么是一致
    cache里有数据: cache和db里的数据是相同的
    cache里无数据: db里是最新的

    ▪ 有两种情况需要考虑:
    读写并发
    Cache/DB其中一个更新失败

    模式:
    ▪ Cache Aside Pattern
        先更新数据库，成功后让缓存失效
        依然存在问题，只是降低了概率
    ▪ Read/Write Through Pattern
        可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache
        也就是读写都落到一个DB节点上
        单一的存储保证一致性
    ▪ Write Behind Caching Pattern
        即write back回写/write deferred
        只更新缓存，不更新数据库，缓存会异步地批量更新数据库
        优点: 性能
        缺点: 数据不是强一致性的，而且可能会丢失

    可选方案:
    方案1:
    ID取模从服务service连接池选取服务连接，保证同一个数据的读写都落在同一个后端服务上
    ID取模从数据库DB连接池中选取DB连接，保证同一个数据的读写在数据库层面是串行的
    这个类似Read/Write Through Pattern的思想

==== 只读缓存与读写缓存
只读缓存可视作Cache Aside Pattern。
读写缓存可以分为同步直写和异步回写。
同步直写的读写缓存可视作Read/Write Through Pattern。
异步回写的读写缓存可视作Write Behind Caching Pattern。

只读缓存:

    优点:
        一致性较好
    缺点:
        每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失
    适用场景:
        读多写少

直写策略的读写缓存:

    优点:
        被修改后的数据在缓存中存在，不必重新加载
    缺点:
        如果写db成功，写缓存失败，造成数据不一致
        高并发场景下如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致
    适用场景:
        读多写少
        相比于只读缓存，性能上有些优势，但一致性方面会差些

回写策略的读写缓存:

    优点:
        写效率较高
    缺点:
        丢失数据的风险
    适用场景:
        读多写多

==== Q&A
Q1: 先删除/淘汰缓存，然后更新数据库，会有什么问题？
Q2: Cache Aside Pattern里，如果是先更新数据库，然后是更新缓存而不是删除缓存，会有什么问题？
Q3: Cache Aside Pattern存在什么问题？
Q4: 某个步骤失败了怎么办？

==== 参考
注意，以下参考中的某些方案及细节未必正确:
https://coolshell.cn/articles/17416.html
https://www.zhihu.com/question/27738066
https://www.zhihu.com/question/319817091
https://m.w3cschool.cn/architectroad/architectroad-consistency-of-cache-with-database.html
https://m.w3cschool.cn/architectroad/architectroad-cache-architecture-design.html

=== 缓存穿透
- 缓存和数据库中都没有数据，而用户不断发起请求，这时的用户很可能是攻击者，攻击会导致数据库压力过大

- 接口层增加校验, 如用户鉴权校验

- 将key-value对写为key-null，缓存有效时间可以设置短一点，如30秒(设置太长会导致正常情况也没法使用)

=== 缓存击穿
- 缓存击穿是指缓存中没有但数据库中有数据(一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

- 击穿与雪崩的区别: 击穿是特定的热点数据，雪崩是全部数据。

- 二级缓存：对于热点数据进行二级缓存，并对于不同级别的缓存设定不同的失效时间

- 热点数据永不过期

=== 缓存雪崩
- 当缓存服务器重启或者大量缓存集中在某一个时间段失效，会给后端系统(比如DB)带来很大压力，造成数据库后端故障，从而引起应用服务器雪崩

- 交错失效时间

- 提高HA

- 控制请求，重建缓存

- 熔断 隔离 限流

=== 数据类型
https://redis.io/docs/data-types/

=== 命令
https://redis.io/commands/

==== info
https://redis.io/commands/info/
例如可以看到memory: mem_allocator:jemalloc-3.6.0，即使用jemalloc进行内存分配。

==== memory
MEMORY USAGE key [SAMPLES count]
MEMORY STATS等
https://redis.io/commands/?alpha=mem

==== config
config get *
https://github.com/redis/redis/blob/unstable/redis.conf

==== Q&A
Q1: scan vs. keys
https://stackoverflow.com/questions/32603964/scan-vs-keys-performance-in-redis
SCAN SSCAN HSCAN ZSCAN也都比较慢

Q2: JSON representation
https://stackoverflow.com/questions/16375188/redis-strings-vs-redis-hashes-to-represent-json-efficiency

Q3: 阻塞操作
https://redis.io/docs/reference/modules/modules-blocking-ops/

=== 配置
https://redis.io/docs/management/config/
https://redis.io/docs/management/config-file/

=== pattern
https://redis.io/docs/manual/patterns/

==== bulk loading
https://redis.io/docs/manual/patterns/bulk-loading/

==== distributed locks
https://redis.io/docs/manual/patterns/distributed-locks/

redlock算法:
https://redis.io/docs/manual/patterns/distributed-locks/#the-redlock-algorithm

参考:
https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html
http://antirez.com/news/101

==== secondary indexing
https://redis.io/docs/manual/patterns/indexes/

==== pattern example
https://redis.io/docs/manual/patterns/twitter-clone/

=== 查询与索引

==== 自建索引
https://redis.io/docs/manual/patterns/indexes/

secondary indexing:
Sorted sets to create secondary indexes by ID or other numerical fields.
Sorted sets with lexicographical ranges for creating more advanced secondary indexes, composite indexes and graph traversal indexes.
Sets for creating random indexes.
Lists for creating simple iterable indexes and last N items indexes.

==== Redis Search
https://redis.io/docs/interact/search-and-query/
https://redis.io/docs/stack/search/reference/query_syntax/

Redis Search:
https://github.com/RediSearch/RediSearch
https://github.com/RediSearch/redisearch-getting-started/
注意事项:
RediSearch 2.0: It works only with Redis 6 and above.

Commands:
https://redis.io/commands/?group=search
FT: full text

==== Q&A
Q: 缓存粒度: 全部列还是部分列？
Q: 如何支持主键索引？
Q: 如何支持非主键索引？
Q: 如何支持组合索引？
Q: 如何支持非唯一索引？
Q: 如何支持降序索引？

例如组合索引:
Composite indexes: https://redis.io/docs/manual/patterns/indexes/

Q: 如果表非常大，可能会遇到大key的问题，如何解决呢？

==== 参考
https://prasannahn.hashnode.dev/building-a-secondary-index-of-15-million-words-for-search-and-auto-complete-using-redis-cache

=== 关系型数据库
https://redis.com/blog/get-sql-like-experience-redis/

=== 工具
RedisInsight: https://redis.io/docs/ui/insight/
Redis Stack: https://redis.io/docs/about/about-stack/

=== 模块
since 5.0: https://docs.redis.com/latest/rs/release-notes/legacy-release-notes/redis-enterprise-5/
https://redis.io/resources/modules/

源码:
https://github.com/redis/redis/blob/unstable/src/redismodule.h
https://github.com/redis/redis/blob/unstable/src/module.c

==== redis search
<<Redis Search, Redis Search>>

==== redis-cell
限流
https://github.com/brandur/redis-cell
https://redis.com/blog/redis-cell-rate-limiting-redis-module/

==== 编写
https://redis.io/docs/reference/modules/

=== 消息队列
相较于Kafka、RabbitMQ、RocketMQ，比较轻量级

==== 基于List的实现
==== 基于Streams的实现

=== 分布式锁
==== 基于单个redis节点的实现
- 简单实现:

    // 加锁
    SETNX lock_key 1
    // 逻辑
    // 释放锁
    DEL lock_key

- 问题一
某个客户端在加锁后进行逻辑时发生了异常，从而没有机会执行DEL命令释放锁，这样导致其它客户端无法拿到锁。
解决方式:

    给锁变量设置一个过期时间。

- 问题二
客户端A持有锁期间，客户端B删除了lock_key，客户端C此时也可以获取到锁，锁失去了意义。
解决方式:

    标识客户端:

    // 加锁, clientid_value作为客户端唯一性的标识
    SET lock_key clientid_value NX PX 8000

    // 释放锁 比较unique_value是否相等，避免误释放
    // redis-cli  --eval  unlock.script  lock_key,  clientid_value
    // lua脚本以原子性的方式执行，保证锁释放操作的原子性

    // lua伪代码: KEYS[1]表示lock_key，ARGV[1]表示客户端id即clientid_value
    if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
    else
        return 0
    end

- 方案缺陷
redis实例发生故障宕机了，锁变量就没有了。
解决: 基于多个redis节点实现分布式锁。

==== 基于多个redis节点的实现
为了避免redis实例故障而导致的锁无法工作的问题，redis作者antirez提出了分布式锁算法redlock。

redlock算法基本思想:
让客户端和多个redis实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么就可以认为客户端成功地获得了分布式锁，否则加锁失败。这样，即使有单个实例发生故障，客户端也依然可以正常进行锁操作，因为锁变量在其它实例上也有保存。

=== 参考项目
https://github.com/redisson/redisson
https://github.com/OpenAtomFoundation/pika