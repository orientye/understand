:toc:
:toclevels: 5
:hardbreaks-option:

== 性能

=== pipeline
原生命令: 例如mget、mset。
非原生命令: 可以使用pipeline提高效率。
但要注意控制一次批量操作的元素个数(例如500以内, 实际也和元素字节数有关)。

注意两者不同:
mget和mset是原子操作, pipeline是非原子操作。
pipeline可以打包不同的命令, mget和mset做不到。
pipeline需要客户端和服务端同时支持。

redis-benchmark -t set -P 2 -q
管道选项-P参数，表示单个管道内并行的请求数量。

参考:
https://redis.io/docs/manual/pipelining/
https://stackoverflow.com/questions/29327544/pipelining-vs-transaction-in-redis

=== 非阻塞
UNLINK:
https://redis.io/commands/unlink/
不是所有的unlink操作都会延后处理，如果对应key所占用的内存很小，延后处理就没有必要了，此时redis会将对应的key内存立即回收，与del指令一样。

FLUSHALL ASYNC:
https://redis.io/commands/flushall/

FLUSHDB ASYNC:
https://redis.io/commands/flushdb/

=== 延迟
https://redis.io/topics/latency

=== 慢查询日志
==== 命令与配置
- SLOWLOG GET
- CONFIG SET slow-log-slower-than 0  (u seconds)
- CONFIG SET slowlog-max-len 5

==== 实现
https://github.com/redis/redis/blob/unstable/src/slowlog.h
https://github.com/redis/redis/blob/unstable/src/slowlog.c

=== 大key问题

==== 什么是大key
字符串类型: big体现在单个value值很大，一般认为超过10KB就是bigkey
非字符串类型: 哈希、列表、集合、有序集合，big体现在元素个数太多(超过10000个?)或者value总大小较大(超过100KB?)

==== 产生原因
1. 程序设计不当
2. 数据规模预估不足

==== 危害
1. 内存空间不均匀
不利于集群对内存的统一管理，存在丢失数据的隐患。

2. 超时阻塞
由于redis单线程的特性，操作bigkey的通常比较耗时，也就意味着阻塞redis可能性越大。

3. 网络拥塞
bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其它实例造成影响，其后果不堪设想。

4. 过期删除
过期删除，如果没有使用redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞redis的可能性，而且这个过期删除不会从主节点的慢查询发现(因为这个删除不是客户端产生的，是内部循环事件，但可以从latency命令中获取或者从slave节点慢查询发现)。

5. 迁移困难
当需要对bigkey进行迁移(例如redis cluster的迁移slot)，实际上是通过migrate命令来完成的，migrate实际上是通过dump + restore + del三个命令组合成原子命令完成，如果是bigkey，可能会使迁移失败，而且较慢的migrate会阻塞redis。

==== 如何检测大key
redis-cli -h 127.0.0.1 -p 7001 –-bigkeys
该指令会大幅抬升redis的ops导致线上报警，可以增加一个休眠参数:
redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1
该指令每隔100条scan指令就会休眠0.1s，ops就不会剧烈抬升，但是扫描的时间会变长

--bigkeys注意事项:
1. 建议在从节点执行，因为--bigkeys也是通过scan完成的
2. 建议在节点本机执行，这样可以减少网络开销
3. 如果没有从节点，可以使用--i参数
4. --bigkeys只能计算每种数据结构的top 1，对于存在非常多的bigkey的数据结构是不适用的

==== 如何解决
unlink命令(since 4.0)

==== 参考
https://mp.weixin.qq.com/s?__biz=Mzg2NTEyNzE0OA==&mid=2247483677&idx=1&sn=5c320b46f0e06ce9369a29909d62b401&chksm=ce5f9e9ef928178834021b6f9b939550ac400abae5c31e1933bafca2f16b23d028cc51813aec&scene=21#wechat_redirect
https://www.getui.com/college/2019100911

=== 内存碎片
info memory
mem_fragmentation_ratio: 1.2

mem_fragmentation_ratio = used_memory_rss/ used_memory
used_memory_rss是操作系统实际分配给redis的物理内存空间(包含了碎片)
used_memory是redis为了保存数据实际申请使用的空间

推荐阈值:

    mem_fragmentation_ratio小于1.5: 合理
    mem_fragmentation_ratio大于1.5: 需要降低内存碎片率

自动清理机制:
since 4.0:
config set activedefrag yes

=== 硬件架构
- 多核CPU
CPU亲和性:
https://github.com/redis/redis/blob/unstable/src/setcpuaffinity.c

- NUMA架构

- NVM

=== client-side-caching
since 6.0
https://redis.io/docs/manual/client-side-caching/
https://redis.io/commands/client-tracking/

=== cluster
https://redis.io/topics/cluster-tutorial
https://redis.io/topics/cluster-spec

=== 参考
https://redis.io/docs/management/optimization/
