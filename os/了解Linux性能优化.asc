= 了解Linux性能优化
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:homepage: http://orientye.com

<<<

== 概述
=== 性能指标
https://github.com/orientye/understand/blob/main/high/%E4%BA%86%E8%A7%A3concurrency/high-concurrency.asc#%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87

=== 理论延迟
In 2020:
    L1 cache reference: 1 ns
    L2 cache reference: 4 ns
    Branch mispredict: 3 ns
    Mutex lock/unlock: 17 ns
    Main memory reference: 100 ns
    Compress 1K bytes with Zippy: 2000 ns
    Send 2K bytes over commodity network: 44 ns
    Read 1 MB sequentially from memory: 3000 ns
    Round trip within same datacenter: 500,000 ns
    Disk seek: 2,000,000 ns
    Read 1 MB sequentially from disk: 825,000 ns
    Read 1 MB sequentially from SSD: 49000 ns

https://colin-scott.github.io/personal_website/research/interactive_latency.html

== CPU

[format="csv", options="header", separator=#]
|===
指标#工具#说明
平均负载  #  top,uptime,cat /proc/loadavg  #  主要使用top
系统CPU使用率  #  vmstat,mpstat,top,sar,/proc/stat  #  sar可以记录历史数据
进程CPU使用率  #  top,ps,pidstat,htop,atop  #  htop和atop更直观
系统上下文切换  #  vmstat  #  
进程上下文切换  #  pidstat  #  注意加上-w选项
软中断  #  top,mpstat,/proc/softirqs  #  top提供了软中断CPU使用率,/proc/softirqs和mpstat提供了各种软中断在每个CPU上的运行次数
硬中断  #  vmstat,/proc/interrupts  #  vmstat提供了总的中断次数,而/proc/interrupts提供各种中断在每个CPU上运行的累计次数
CPU缓存  #  perf  #  perf stat子命令
CPU数  #  lscpu,/proc/cpuinfo  #  
事件剖析  #  perf,火焰图,execsnoop  #  perf和火焰图用来分析热点函数以及调用栈,execsnoop用来监测短时进程
动态追踪  #  fstrace,bcc,systeminfo  #  ftrace用于跟踪内核函数调用栈,bcc和systeminfo用于跟踪内核或应用程序执行过程
|===

TIP: perf可以使用perf + gprof2dot + graphviz输出调用关系图, 从而迅速理清核心链路

=== 指标

==== 平均负载

平均负载

    System load averages is the average number of processes that are either in a runnable or uninterruptable state.  
    A process in a runnable state is either using the CPU or waiting to use the CPU(也就是R状态).
    A process in uninterruptable state is waiting for some I/O access, eg waiting for disk(也就是D状态).
    (man uptime)

多少合适

    平均负载可以简单地理解为平均活跃进程数，理想情况下等于CPU(核心)个数(lscpu或者grep 'model name' /proc/cpuinfo | wc -l)
    当平均负载高于CPU数量70%的时候，可以认为负载过高 或者监控看历史数据变化

vs. CPU使用率

    平均负载还包括D uninterruptible sleep (usually IO)以及R running or runnable (on run queue)中的runnable状态
    因此，没有对应关系
    例如IO密集型进程，可能导致平均负载较高，但CPU利用率较低
    例如大量进程，有些进程等待CPU调度(pidstat %wait列查看?)

原因分析

    借助mpstat, pidstat等命令分析

=== 工具

==== top

== 内存

[format="csv", options="header", separator=#]
|===
指标#工具#说明
系统已用,可用,剩余内存  #  free,vmstat,sar,cat /proc/meminfo  #  vmstat,sar比较全面
进程虚拟内存,常驻内存,共享内存  #  ps,top,pidstat,/proc/pid/stat(us)  #  pidstat -r
进程内存分布  #  pmap,/proc/pid/maps  #  
进程swap换出内存  #  top,/proc/pid/status  #  
进程缺页异常  #  ps,top,pidstat  #  pidstat -r
系统换页情况  #  sar  #  sar -B
缓存/缓冲区用量  #  free,vmstat,sar,cachestat  #  vmstat最常用,cachestat需要安装bcc
缓存/缓冲区命中率  #  cachetop  #  cachetop需要安装bcc
swap已用空间和剩余空间  #  free,sar  #  
swap换入换出  #  vmstat,sar  #  
内存泄漏检测  #  memleak,valgrind  #  memleak需要安装bcc
指定文件的缓存大小  #  pcstat  #  
|===

=== 指标
- 系统内存指标

    已用内存
    剩余内存
    可用内存
    缺页异常: 主缺页异常, 次缺页异常
    缓存/缓冲区: 使用量, 命中率
    Slabs

- 进程内存指标

    虚拟内存(VSS)
    常驻内存(RSS)
    按比例分配共享内存后的物理内存(PSS)
    独占内存(USS)
    共享内存
    SWAP内存
    缺页异常: 主缺页异常, 次缺页异常

- SWAP

    已用空间
    剩余空间
    换入速度
    换出速度

=== 工具

==== free
total = used + free + buffers + cache
available表示新进程可以使用多少内存，它不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。

==== vmstat
buff是对磁盘数据的缓存: 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”
cache是对文件数据的缓存: 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存”
它们既会用在读请求中，也会用在写请求中
buff和cache单位: KB

bi和bo则分别表示块设备读取和写入的大小，单位为块/秒。因为Linux中块的大小是1KB，所以等价于KB/s

=== 优化

==== OOM(Out of Memory)
OOM是内核的一种保护机制。它监控进程的内存使用情况，并且使用om_score为每个进程的内存使用情况进行评分：
一个进程消耗的内存越大，oom_score就越大
一个进程占用的CPU越多，oom_score就越小

进程的oom_score越大，代表消耗的内存越多，也就越容易被杀死，从而可以更好保护系统。
为了实际工作的需要，可以通过/proc文件系统，设置进程的oom_adj ，从而调整进程的oom_score。

== 文件

[format="csv", options="header", separator=#]
|===
指标#工具#说明
文件系统空间容量,使用量,剩余空间  #  df  # 
索引节点容量,使用量,剩余量  #  df  #  使用-i选项
页缓存,可回收slab缓存  #  /proc/meminfo,sar,vmstat  #  使用sar -r选项
缓冲区  #  /proc/meminfo,sar,vmstat  #  使用sar -r选项
目录项,索引节点及文件系统的缓存  #  /proc/slabinfo,slabtop  #  slabtop更直观
磁盘IO使用率,IOPS,吞吐量响应时间,IO平均大小及等待队列长度  #  iostat,sar,dstat  #  iostat -d -x或sar -d
进程IO大小以及IO延迟  #  pidstat,iotop  #  使用pidstat -d选项
块设备IO事件跟踪  #  blktrace  #  
进程IO系统调用跟踪  #  strace  #  
进程块设备IO大小跟踪  #  biosnoop,biotop  #  bcc
|===

=== 指标
- 磁盘性能基本指标

    使用率: 磁盘处理IO的时间百分比
    饱和度: 磁盘处理IO的繁忙程度
    IOPS: 每秒的IO请求数
    吞吐量: 每秒的IO请求大小
    响应时间

=== 工具
top
iostat
pidstat
iotop
bcc(filetop, opensnoop)
strace
lsof

=== 优化
==== IO基准测试
fio

==== 硬件层优化
SSD
RAID

==== 系统层优化
▪ 选择适合的文件系统。
比如Ubuntu默认使用ext4文件系统，而CentOS 7默认使用xfs文件系统。相比于ext4，xfs支持更大的磁盘分区和更大的文件数量，如xfs支持大于16TB的磁盘。xfs的缺点在于无法收缩，ext4则可以。

▪ 优化文件系统的配置选项
包括文件系统的特性(ext_attr、dir_index)、日志模式(如 journal、ordered、writeback)、挂载选项(如 noatime)等。

▪ 优化文件系统的缓存
比如pdflush脏页的刷新频率(如设置dirty_expire_centisecs和dirty_writeback_centisecs)以及脏页的限额(如调整dirty_background_ratio和dirty_ratio等)。再如，可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整vfs_cache_pressure，数值越大，就表示越容易回收。

▪ 在不需要持久化时，用内存文件系统tmpfs可以获得更好的I/O性能。
tmpfs把数据直接保存在内存中，而不是磁盘中。比如/dev/shm/就是大多数Linux默认配置的一个内存文件系统，其大小默认为总内存的一半。

==== 应用层优化
▪ 顺序写代替随机写
▪ 缓存
▪ C标准库提供的fopen/fread等库函数，都会利用标准库的缓存，减少磁盘的操作。而直接使用open/read等系统调用时，就只能利用操作系统提供的页缓存和缓冲区等，而没有库函数的缓存可用
▪ 需要频繁读写同一块磁盘空间时，可以用mmap代替read/write，减少内存的拷贝次数
▪ 在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用fsync()取代O_SYNC
▪ 在多个应用程序共享磁盘时，为保证I/O不被某个应用完全占用，推荐使用cgroups的I/O子系统来限制进程/进程组的IOPS以及吞吐量
▪ 在使用CFQ调度器时，可以用ionice来调整进程的I/O调度优先级，特别是提高核心应用的I/O优先级
▪ io_uring

== 网络
https://github.com/orientye/understand/blob/main/network/%E4%BA%86%E8%A7%A3Network/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.asc

== 参考
倪鹏飞《Linux性能优化实战》