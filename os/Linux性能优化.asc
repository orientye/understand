= Linux性能优化
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:homepage: http://orientye.com

<<<

== 概述
=== 性能指标
https://github.com/orientye/understand/blob/main/high/high-concurrency.asc#%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87

=== 理论延迟
In 2020:

    L1 cache reference: 1 ns
    L2 cache reference: 4 ns
    Branch mispredict: 3 ns
    Mutex lock/unlock: 17 ns
    Main memory reference: 100 ns
    Compress 1K bytes with Zippy: 2000 ns
    Send 2K bytes over commodity network: 44 ns
    Read 1 MB sequentially from memory: 3000 ns
    Round trip within same datacenter: 500,000 ns
    Disk seek: 2,000,000 ns
    Read 1 MB sequentially from disk: 825,000 ns
    Read 1 MB sequentially from SSD: 49000 ns

https://colin-scott.github.io/personal_website/research/interactive_latency.html

== CPU

[format="csv", options="header", separator=#]
|===
指标#工具#说明
平均负载  #  top,uptime,cat /proc/loadavg  #  主要使用top
系统CPU使用率  #  vmstat,mpstat,top,sar,/proc/stat  #  sar可以记录历史数据
进程CPU使用率  #  top,ps,pidstat,htop,atop  #  htop和atop更直观
系统上下文切换  #  vmstat  #  
进程上下文切换  #  pidstat  #  注意加上-w选项
软中断  #  top,mpstat,/proc/softirqs  #  top提供了软中断CPU使用率,/proc/softirqs和mpstat提供了各种软中断在每个CPU上的运行次数
硬中断  #  vmstat,/proc/interrupts  #  vmstat提供了总的中断次数,而/proc/interrupts提供各种中断在每个CPU上运行的累计次数
性能统计信息  #  perf  #  perf stat子命令
CPU数  #  lscpu,/proc/cpuinfo  #  
事件剖析  #  perf,火焰图,execsnoop  #  perf和火焰图用来分析热点函数以及调用栈,execsnoop用来监测短时进程
动态追踪  #  fstrace,bcc,systeminfo  #  ftrace用于跟踪内核函数调用栈,bcc和systeminfo用于跟踪内核或应用程序执行过程
|===

TIP: perf可以使用perf + gprof2dot + graphviz输出调用关系图, 从而迅速理清核心链路

=== 指标

==== 平均负载
- 平均负载

    System load averages:
    is the average number of processes that are either in a runnable or uninterruptable state.
    A process in a runnable state is either using the CPU or waiting to use the CPU(也就是R状态).
    A process in uninterruptable state is waiting for some I/O access, eg waiting for disk(也就是D状态).
    (man uptime)

- 命令

    top命令里的第一行: load average, 表示system load avg over the last 1, 5 and 15 minutes
    htop命令更为直观，与top不同的是，htop默认显示线程

- 多少合适

    平均负载可以简单地理解为平均活跃进程数，理想情况下等于CPU(核心)个数(lscpu或者grep 'model name' /proc/cpuinfo | wc -l)

    Q: 当平均负载为4时，意味着什么呢？
    在拥有4个CPU的系统上，意味着CPU刚好被完全占用；
    在拥有8个CPU的系统上，意味着CPU有50%的空闲；
    在只有2个CPU的系统上，意味着有一半的进程竞争不到CPU。

    当平均负载高于CPU数量70%的时候，可以认为负载过高

- vs. CPU使用率

    平均负载还包括D uninterruptible sleep (usually IO)以及R running or runnable (on run queue)中的runnable状态
    因此，平均负载与CPU使用率没有对应关系:
    例如IO密集型进程，可能导致平均负载较高，但CPU利用率较低
    例如大量进程，有些进程等待CPU调度(pidstat %wait列查看?)
    而CPU密集型进程，使用大量CPU会导致平均负载升高，此时两者会一致

- 原因分析

    借助mpstat, pidstat等命令分析

==== CPU使用率
- CPU使用率(CPU Usage)

    CPU使用率的本质是时间累计:
        操作系统计算的是进程消耗的总CPU时间（无论发生在哪个核心上）。例如：
        进程在 1秒内 在 CPU0 上运行了 0.3秒 → 在 CPU1 上运行了 0.2秒
        总CPU时间 = 0.5秒
        CPU使用率 = (0.5秒 / 1秒) × 100% = 50%
        即跨核心切换不会改变使用率的计算逻辑，系统会累加所有核心上的执行时间。
    多核系统的百分比表示:
        单核系统：最大100%（一个核心满载）
        N核系统：最大N × 100%
        （例如：4核系统最大400%，表示进程完全占满4个核心）

- 命令

    top与ps命令里的%CPU
    工具给出的都是间隔一段时间的平均CPU使用率，因此要注意间隔时间的设置
    例如，top, htop, ps这几个命令报告的CPU使用率，默认的结果很可能不一样:
    因为默认分别使用3秒间隔(top)/2秒间隔(htop)/进程的整个生命周期(ps)

- 原因分析

    用户CPU和NiceCPU高，说明用户态进程占用了较多的 CPU，应该着重排查进程的性能问题
    系统CPU高，说明内核态占用了较多的CPU，应该着重排查内核线程或者系统调用的性能问题
    I/O等待CPU高，说明等待I/O的时间比较长，应该着重排查系统存储是不是出现了I/O问题
    软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的CPU，应该着重排查内核中的中断服务程序

    查看函数/事件:
    perf top -g -p $PID    #-g开启调用关系分析，-p指定进程ID

    还有概率较小的短时应用导致的问题:
    例如应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过top等工具也不容易发现
    再例如应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU
    对于这类进程，可以用pstree或者execsnoop找到父进程，再从父进程所在的应用入手，排查问题的根源

==== 上下文切换
- 上下文切换

    进程上下文切换
    线程上下文切换
    中断上下文切换

    自愿上下文切换
        进程无法获取所需资源，导致的上下文切换。
        例如，I/O或内存等系统资源不足时，容易发生自愿上下文切换。
    非自愿上下文切换
        进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。
        例如，大量进程在争抢CPU时，容易发生非自愿上下文切换。

- 命令

    pidstat -w
        cswch/s列: 每秒自愿上下文切换(voluntary context switches)的次数
        nvcswch/s列: 每秒非自愿上下文切换(non voluntary context switches)的次数

    top命令里的hi, si可以查看整体的硬件中断，软中断的情况，按1键可以具体到每个CPU。
    watch -d cat /proc/softirqs可以查看到软中断的具体类型:
        例如如果是网络接收软中断，则可以通过sar, tcpdump等命令继续分析

    top里的iowait%则表示等待I/O的CPU时间百分比；此时进程处于不可中断睡眠态。
    pidstat里的%wait表示进程等待CPU的时间百分比；此时进程是运行状态。

- 多少合适

    取决于系统本身的CPU性能
    如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。
    但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。
    这时，需要根据上下文切换的类型，再做具体分析。
    例如自愿上下文切换变多了，说明进程都在等待资源，有可能发生了I/O等其他问题；
    非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢CPU，说明CPU的确成了瓶颈；
    中断次数变多了，说明CPU被中断处理程序占用，可以查看/proc/interrupts文件来分析具体的中断类型。

=== 工具

==== top
可以获取各CPU使用率以及僵尸进程和平均负载等信息。

注意:
top命令里默认显示的是进程，如果该进程有多个子线程，显示的CPU占用率是所有子线程之和

可以使用命令top -d 2 -Hp $PID 以2秒的频率显示PID所有子线程

==== pidstat
可以获取进程的用户CPU使用率、系统CPU使用率、以及自愿上下文切换和非自愿上下文切换等信息。

注意:
pidstat命令里默认显示进程，加上-t参数后，才会输出线程的指标，且一些指标并是不子线程之和

==== vmstat
可以获取上下文切换次数、中断次数、运行状态和不可中断状态的进程数等信息。

==== 父子关系
pstree
ps -ef里会显示PPID

==== perf
perf是动态追踪工具，会给系统带来一定的性能损失。
vmstat、pidstat直接读取proc文件系统来获取指标，不会带来性能损失。

== 内存

[format="csv", options="header", separator=#]
|===
指标#工具#说明
系统已用,可用,剩余内存  #  free,vmstat,sar,cat /proc/meminfo  #  vmstat,sar比较全面
进程虚拟内存,常驻内存,共享内存  #  ps,top,pidstat,/proc/pid/stat(us)  #  pidstat -r
进程内存分布  #  pmap,/proc/pid/maps  #  
进程swap换出内存  #  top,/proc/pid/status  #  
进程缺页异常  #  ps,top,pidstat  #  pidstat -r
系统换页情况  #  sar  #  sar -B
缓存/缓冲区用量  #  free,vmstat,sar,cachestat  #  vmstat最常用,cachestat需要安装bcc
缓存/缓冲区命中率  #  cachetop  #  cachetop需要安装bcc
swap已用空间和剩余空间  #  free,sar  #  
swap换入换出  #  vmstat,sar  #  
内存泄漏检测  #  memleak,valgrind  #  memleak需要安装bcc
指定文件的缓存大小  #  pcstat  #  
|===

=== 指标
==== 系统内存
- 系统内存

    已用内存
    剩余内存
    可用内存
    缺页异常: 主缺页异常, 次缺页异常
    缓存/缓冲区: 使用量, 命中率
    Slabs

    buff是对磁盘数据的缓存: 既可以用作"要写入磁盘数据的缓存"，也可以用作"从磁盘读取数据的缓存"
    cache是对文件数据的缓存: 既可以用作"从文件读取数据的页缓存"，也可以用作"写文件的页缓存"
    它们既会用在读请求中，也会用在写请求中
    man free可以看到buff与cache的初步解释
    进而通过man proc里的meminfo看到进一步的解释

==== 进程内存
- 进程内存

    虚拟内存(VSS)
    常驻内存(RSS)
    按比例分配共享内存后的物理内存(PSS)
    独占内存(USS)
    共享内存
    SWAP内存
    缺页异常: 主缺页异常, 次缺页异常

==== SWAP
- swap

    已用空间
    剩余空间
    换入速度
    换出速度

    在内存资源紧张时，Linux会通过Swap，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。

- 命令

    可以通过设置/proc/sys/vm/min_free_kbytes来调整系统定期回收内存的阈值；
    可以通过设置/proc/sys/vm/swappiness来调整文件页和匿名页的回收倾向。

    swap变高时，可以用sar、/proc/zoneinfo、/proc/pid/status等方法查看系统和进程的内存使用情况。

    通常，降低swap的使用，可以提高系统的整体性能:
    禁止Swap，现在服务器的内存足够大，除非有必要，禁用Swap就可以了，且大部分云平台中的虚拟机都默认禁止Swap了。
    实在需要用到Swap，可以尝试降低swappiness的值，减少内存回收时Swap的使用倾向。
    响应延迟敏感的应用，可能在开启Swap的服务器中运行，还可以用库函数mlock()或者mlockall()锁定内存，阻止其内存换出。
    许多java的应用都建议关swap，因为这与JVM的gc有关:
    java在gc的时候会遍历所有用到的堆的内存，如果这部分内存是被swap出去了，遍历的时候就会有磁盘IO
    参考:
    https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html
    https://dzone.com/articles/just-say-no-swapping

==== 缓存命中率
- 命令

    cachestat: 整个系统缓存的读写命中情况
    cachetop: 每个进程的缓存命中情况
    两个工具都是bcc软件包的一部分，基于eBPF机制。

==== 内存泄漏

=== 工具

==== 常用步骤
1. 先使用free和top，查看系统整体的内存使用情况；
2. 然后使用vmstat和pidstat，查看一段时间的趋势，从而判断出内存问题的类型；
3. 最后进行详细分析，比如内存分配分析、缓存/缓冲区分析、具体进程的内存使用分析等。

==== free
total 约= used + free + buffers + cache
available表示新进程可以使用多少内存，它不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。
-b(字节为单位) -k(K为单位, 默认) -m(M为单位), -g(G为单位)

vs. top
top里其实已经包含了free的功能，并且除了整体内存，还能看到每个进程的内存情况。

==== vmstat
bi和bo则分别表示块设备读取和写入的大小，单位为块/秒。因为Linux中块的大小是1KB，所以等价于KB/s

   Procs
       r: The number of runnable processes (running or waiting for run time).
       b: The number of processes blocked waiting for I/O to complete.

   Memory
       These are affected by the --unit option.
       swpd: the amount of swap memory used.

   Memory
       These are affected by the --unit option.
       swpd: the amount of swap memory used.
       free: the amount of idle memory.
       buff: the amount of memory used as buffers.
       cache: the amount of memory used as cache.
       inact: the amount of inactive memory.  (-a option)
       active: the amount of active memory.  (-a option)

   Swap
       These are affected by the --unit option.
       si: Amount of memory swapped in from disk (/s).
       so: Amount of memory swapped to disk (/s).

   IO
       bi: Blocks received from a block device (blocks/s).
       bo: Blocks sent to a block device (blocks/s).

   System
       in: The number of interrupts per second, including the clock.
       cs: The number of context switches per second.

   CPU
       These are percentages of total CPU time.
       us: Time spent running non-kernel code.  (user time, including nice time)
       sy: Time spent running kernel code.  (system time)
       id: Time spent idle.  Prior to Linux 2.5.41, this includes IO-wait time.
       wa: Time spent waiting for IO.  Prior to Linux 2.5.41, included in idle.
       st: Time stolen from a virtual machine.  Prior to Linux 2.6.11, unknown.

==== memleak(bcc)

==== sar

=== 优化

==== OOM(Out of Memory)
OOM是内核的一种保护机制。它监控进程的内存使用情况，并且使用om_score为每个进程的内存使用情况进行评分：
一个进程消耗的内存越大，oom_score就越大
一个进程占用的CPU越多，oom_score就越小

进程的oom_score越大，代表消耗的内存越多，也就越容易被杀死，从而可以更好保护系统。
为了实际工作的需要，可以通过/proc文件系统，设置进程的oom_adj，从而调整进程的oom_score。

== 文件

[format="csv", options="header", separator=#]
|===
指标#工具#说明
文件系统空间容量,使用量,剩余空间  #  df  # 
索引节点容量,使用量,剩余量  #  df  #  使用-i选项
页缓存,可回收slab缓存  #  /proc/meminfo,sar,vmstat  #  使用sar -r选项
缓冲区  #  /proc/meminfo,sar,vmstat  #  使用sar -r选项
目录项,索引节点及文件系统的缓存  #  /proc/slabinfo,slabtop  #  slabtop更直观
磁盘IO使用率,IOPS,吞吐量响应时间,IO平均大小及等待队列长度  #  iostat,sar,dstat  #  iostat -d -x或sar -d
进程IO大小以及IO延迟  #  pidstat,iotop  #  使用pidstat -d选项
块设备IO事件跟踪  #  blktrace  #
进程IO系统调用跟踪  #  strace  #
进程块设备IO大小跟踪  #  biosnoop,biotop  #  bcc
|===

=== 指标
- 磁盘性能基本指标

    使用率: 磁盘处理IO的时间百分比
    饱和度: 磁盘处理IO的繁忙程度
    IOPS: 每秒的IO请求数
    吞吐量: 每秒的IO请求大小
    响应时间

- 文件系统基本指标

    容量、使用量以及剩余空间等
    不过要注意，这些只是文件系统向外展示的空间使用，而非磁盘空间的真实用量，因为文件系统的元数据也会占用磁盘空间。
    而且，如果配置了RAID，从文件系统看到的使用量跟实际磁盘的占用空间，也会因为RAID级别的不同而不一样。
    例如，配置RAID10后，从文件系统最多也只能看到所有磁盘容量的一半。
    另外一个容易忽略的是索引节点的使用情况，也包括容量、使用量以及剩余空间等指标。
    如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题。

    除此，缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统(如 ext4、XFS等)的缓存。

    此外，文件I/O也是很重要的性能指标，包括IOPS(包括r/s和w/s)、响应时间(延迟)以及吞吐量(B/s)等。

=== 工具
==== iostat
iostat是最常用的磁盘I/性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标(这些指标实际上来自/proc/diskstats)。

vmstat比iostat有时候可能更全面。

==== top
可以先用top，来观察CPU和内存的使用情况；然后再用iostat，来观察磁盘的I/O情况。

==== iotop
似于top，可以按照I/O大小对进程排序。

==== pidstat
pidstat加上-d参数，就可以看到进程的I/O情况。

==== bcc(filetop, opensnoop)
filetop能看到线程相关
strace -p PID后加上-f，多进程和多线程都可以跟踪。

==== strace
strace -p $PID

可以使用strace、lsof等工具来定位狂打日志的进程，找出相应的日志文件。

strace万能命令:
strace -T -f -tt -e trace=all -p pid -o output.txt

==== lsof
lsof -p $PID

=== 优化
==== IO基准测试
fio

==== 硬件层优化
SSD
RAID

==== 系统层优化
▪ 选择适合的文件系统
比如Ubuntu默认使用ext4文件系统，而CentOS 7默认使用xfs文件系统。相比于ext4，xfs支持更大的磁盘分区和更大的文件数量，如xfs支持大于16TB的磁盘。xfs的缺点在于无法收缩，ext4则可以。

▪ 优化文件系统的配置选项
包括文件系统的特性(ext_attr、dir_index)、日志模式(如 journal、ordered、writeback)、挂载选项(如 noatime)等。

▪ 优化文件系统的缓存
比如pdflush脏页的刷新频率(如设置dirty_expire_centisecs和dirty_writeback_centisecs)以及脏页的限额(如调整dirty_background_ratio和dirty_ratio等)。再如，可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整vfs_cache_pressure，数值越大，就表示越容易回收。

▪ 在不需要持久化时，用内存文件系统tmpfs可以获得更好的I/O性能
tmpfs把数据直接保存在内存中，而不是磁盘中。比如/dev/shm/就是大多数Linux默认配置的一个内存文件系统，其大小默认为总内存的一半。

==== 应用层优化
▪ 顺序写代替随机写
▪ 缓存
▪ C标准库提供的fopen/fread等库函数，都会利用标准库的缓存，减少磁盘的操作。而直接使用open/read等系统调用时，就只能利用操作系统提供的页缓存和缓冲区等，而没有库函数的缓存可用
▪ 需要频繁读写同一块磁盘空间时，可以用mmap代替read/write，减少内存的拷贝次数
▪ 在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用fsync()取代O_SYNC
▪ 在多个应用程序共享磁盘时，为保证I/O不被某个应用完全占用，推荐使用cgroups的I/O子系统来限制进程/进程组的IOPS以及吞吐量
▪ 在使用CFQ调度器时，可以用ionice来调整进程的I/O调度优先级，特别是提高核心应用的I/O优先级
▪ io_uring

== 网络
https://github.com/orientye/understand/blob/main/network/Network/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.asc

== 参考
倪鹏飞《Linux性能优化实战》