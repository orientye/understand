= 线性代数(Linear Algebra)
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:stem: latexmath
:homepage: http://orientye.com

<<<

== 标量
标量(scalar)是一个单独的数值，它只有大小，没有方向。
在线性代数中，标量指向量空间中的基本数值（如实数或复数），用于与向量（如矢量或矩阵）区分。

Q: 复数(complex number)是标量吗? 
复数是标量的一种，虽然复数可以在复平面上用向量表示，但复数本身不是向量，因为它不遵循向量加法和数乘的完整规则(如点积、叉积等)。
在数学上，复数属于域(Field): 满足加、减、乘、除运算，而向量属于向量空间(Vector Space): 需要额外定义线性运算。

== 向量
=== 概念
向量是一组有序的数，它既有大小又有方向。向量可以被视为标量值组成的列表。

实向量与复向量: 如果向量的分量是实数，则称为实向量；如果是复数，则称为复向量。

=== 范数(Vector Norm)
==== 概念
向量大小: 通常指向量唯一的几何长度(默认L2范数)。
向量范数: 数学上存在多种定义(L1, L2, L∞...)，对应不同的测量规则。

日常语言中的向量大小通常对应数学中的欧几里得范数(L2范数)，特别是在物理和几何背景下。比如向量(3,4)的大小是5，这正是L2范数的计算结果。
但严格来说，“大小”这个说法在数学中不够精确，因为向量可以有不同定义方式的“大小”（即不同范数）。例如在数据科学中，有时会用L1范数作为“大小”。

=== 线性相关性

=== 向量空间

== 矩阵
=== 概念
向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。

=== 乘法
vs. Hadamard乘积(也称为逐元素乘积或Schur乘积)

[options="header"]
|===
| 运算 | python函数 | 说明
| 矩阵乘法 | `@` or `np.matmul` | 标准行×列乘法
| 点积(高维) | `np.dot` | 行为复杂，推荐用@
| 逐元素乘法 | `*` or `np.multiply` | Hadamard乘积
|===

=== 秩
- 概念
矩阵的秩(Rank)是线性代数中的一个重要概念，表示矩阵中线性无关的行或列的最大数目。
矩阵的秩反映了矩阵所包含的信息量，是矩阵的一个重要特征。

- 定义
对于一个 m×n 的矩阵 A，其秩定义为：
行秩：矩阵中线性无关的行向量的最大数目。
列秩：矩阵中线性无关的列向量的最大数目。
行秩和列秩是相等的，因此统称为矩阵的秩，记作 rank(A)。

- 计算方法
初等行变换法:
    通过初等行变换将矩阵化为行阶梯形（Row Echelon Form），非零行的数目即为矩阵的秩。
子式法: 矩阵的秩等于其最高阶非零子式的阶数。

- 性质
对于 m×n 矩阵 A，有 rank(A)≤min(m,n)。
若 A 是方阵且满秩（即 rank(A)=n），则 A 可逆。
矩阵的秩在初等变换下不变。
对于矩阵 A 和 B，有 rank(A+B)≤rank(A)+rank(B)。
对于矩阵 A 和 B，有 rank(AB)≤min(rank(A),rank(B))。

- 应用
矩阵的秩在许多领域有广泛应用，如线性方程组的求解、矩阵分解、机器学习中的特征选择等。

- 参考
https://www.zhihu.com/question/21605094

=== 逆

=== 范数(Matrix Norm)
==== 概念
矩阵范数是矩阵的一种度量方式。通过不同类型的范数（如Frobenius范数、谱范数、列/行范数等），可以从不同角度分析矩阵的性质。矩阵范数在优化、机器学习、数值计算等领域有着重要的应用。

==== 矩阵范数的定义
==== 常见的矩阵范数
==== 矩阵范数的几何意义
==== 矩阵范数的应用
==== 矩阵范数的计算

=== 特征值(eigenvalues)与特征向量(eigenvectors)
==== 概念
- 概念
特征值是描述矩阵在线性变换中的缩放因子的标量。
特征向量是与特征值相关联的非零向量，它表示在线性变换中受到特征值缩放的方向。

- 参考
https://tracholar.github.io/math/2018/01/28/matrix.html
https://zhuanlan.zhihu.com/p/165382601

- 向量特征-vs-特征向量
向量特征(vector features):
向量特征是指一个向量所具有的能够描述其某种性质或特点的属性。这些属性可以是向量的长度、方向、元素之间的关系、在某个坐标系下的坐标值等。
特征向量(feature vector):
在机器学习中，样本数据通常用向量的形式表示，称为特征向量(feature vector)，用于描述样本的特征。
不要将样本的特征向量与矩阵的特征向量混淆，二者是不同的概念。
特征向量(eigenvector):
在矩阵和线性变换的背景下，设A是一个nxn的一个的方阵，若存在非零向量和实数，使得Ax=bx，则向量x称为矩阵A的属于特征值b的特征向量。

==== 定义
对于一个 *n×n* 的方阵A，如果存在一个 *非零向量* v 和一个 *标量* λ，使得: Av=λv
则称：
- λ 为矩阵 A 的 *特征值* (eigenvalue)。
- v 为对应于 λ 的 *特征向量* (eigenvector)。

==== 几何意义
- 特征向量: v 在经过矩阵 A 的线性变换后，方向不变（或反向），仅长度缩放 λ 倍。
- 特征值: 衡量特征向量在变换中被拉伸或压缩的程度:
    ** λ > 1 表示拉伸
    ** 0 < λ <1 表示压缩
    ** λ < 0 表示反向
    ** λ = 0 表示 v 在 A 的作用下被压缩到零(即 v ∈ Null(A))

==== 计算方法

==== 性质
===== 特征值的性质
- 特征值的和 = 矩阵的迹(Trace)
- 特征值的积 = 矩阵的行列式
- 对角矩阵和三角矩阵的特征值:
    ** 对角矩阵 D=diag(d1,d2,...,dn) 的特征值就是d1,d2,...,dn。
    ** 三角矩阵的特征值也是其对角线元素。
- 相似矩阵的特征值相同

===== 特征向量的性质
- 线性无关性
    ** 不同特征值对应的特征向量线性无关。
    ** 如果 A 有 n 个不同的特征值，那么它有 n 个线性无关的特征向量(此时 A 可对角化)。
- 对称矩阵的特征向量正交
    ** 如果 A 是实对称矩阵，那么它的特征向量可以选为正交的(即可以找到一组标准正交基)。

==== 应用
- 系统稳定分析
特征值可以帮助分析系统的稳定性，例如，如果所有的特征值都小于零，则系统是稳定的。

- 主成分分析(PCA)
PCA是数据降维的一种常用方法，它利用特征向量来构建新的坐标系。

- 矩阵分解
特征分解可以将矩阵分解为特征向量和特征值的组合，有助于分析矩阵的结构。

- 微分方程的解
特征值和特征向量可以用于求解微分方程。

- 对角化

- 振动分析
特征值表示系统的固有频率，特征向量表示振型。

- 图论(图的谱分析)
图的邻接矩阵或拉普拉斯矩阵的特征值可以反映图的结构性质(如连通性、聚类等)。

==== 注意事项
- 特征向量必须是非零向量。
- 复数矩阵可能有复数特征值和特征向量。
- 不是所有矩阵都有足够的线性无关特征向量(即不一定可对角化)。

==== 参考
https://immersivemath.com/ila/ch10_eigen/ch10.html

=== 矩阵分解

=== 特殊矩阵
==== 正交矩阵(Orthogonal Matrix)
- 概念
正交矩阵 Q 是一个满足 QᵀQ = QQᵀ = I 或等价地其列(行)向量构成标准正交基的实方阵。
它代表的线性变换是保持向量长度和夹角的刚性运动（旋转和反射）。
正交矩阵具有非常好的数值性质（条件数为1），在坐标变换、计算机图形学、数值计算（如QR分解）和物理学等领域有极其广泛的应用。

- 定义
一个 n × n 的实方阵 Q 被称为 正交矩阵，如果它满足以下等价条件之一:
  1、QᵀQ = QQᵀ = I(其中 Qᵀ 是 Q 的转置矩阵，I 是 n × n 的单位矩阵)，即矩阵的转置等于其逆矩阵。
  2、Q 的列向量构成一组标准正交基
  3、Q 的行向量构成一组标准正交基

- 几何意义
正交矩阵表示的线性变换是 Rⁿ 空间中的 刚性运动 (Rigid Motion) 或 等距同构 (Isometry)。这种变换只包含：
旋转 (Rotation)
反射 (Reflection)
旋转和反射的组合
它不改变空间中点与点之间的距离、向量之间的角度以及向量的长度。整个空间的形状和大小保持不变，只有方向（或定向）可能改变。

- 性质
    ** 可逆性 (Invertibility):
        *** 所有正交矩阵都是可逆的。
        *** 逆矩阵就是其转置矩阵：Q⁻¹ = Qᵀ。
        *** 求逆非常容易，只需要转置即可。
    ** 保持向量长度不变 (Preserves Vector Length):
        *** 对于任意向量 x ∈ Rⁿ，乘以正交矩阵 Q 后，其长度不变：||Qx|| = ||x|| 这是正交矩阵最重要的几何性质之一。
    ** 保持向量夹角不变 (Preserves Angles Between Vectors):
        *** 对于任意两个向量 x, y ∈ Rⁿ，它们之间的夹角在乘以正交矩阵 Q 后保持不变。点积关系满足：(Qx) · (Qy) = x · y
        *** 这是因为 ||Qx|| = ||x||, ||Qy|| = ||y||, 且 (Qx)·(Qy) = (Qx)ᵀ(Qy) = xᵀQᵀQy = xᵀIy = xᵀy = x·y。
    ** 行列式 (Determinant):
        *** 正交矩阵的行列式值只能是 +1 或 -1：det(Q) = ±1
        *** 证明：由 QᵀQ = I 得 det(QᵀQ) = det(I) => det(Qᵀ)det(Q) = 1 => [det(Q)]² = 1 => det(Q) = ±1。
        *** det(Q) = 1：代表 Q 是一个旋转操作（保持空间定向）。
        *** det(Q) = -1：代表 Q 是一个旋转加反射的操作（反转空间定向）。
    ** 特征值 (Eigenvalues):
        *** 正交矩阵的特征值 λ 的模都是 1：|λ| = 1。也就是说，所有特征值都落在复平面的单位圆上。
        *** 实特征值只能是 +1 或 -1。
    ** 乘积保持正交性 (Product is Orthogonal):
        *** 如果 Q₁ 和 Q₂ 都是正交矩阵，那么它们的乘积 Q₁Q₂ 也是正交矩阵。
        *** 证明：(Q₁Q₂)ᵀ(Q₁Q₂) = Q₂ᵀQ₁ᵀQ₁Q₂ = Q₂ᵀIQ₂ = Q₂ᵀQ₂ = I。
    ** 条件数 (Condition Number):
        *** 正交矩阵的（关于 2-范数的）条件数为 1：cond₂(Q) = ||Q||₂ ||Q⁻¹||₂ = 1 * 1 = 1。
        *** 这意味着正交矩阵是数值稳定的，用它进行线性变换或求解线性方程组时，不会放大输入数据的误差或扰动。这是正交矩阵在数值计算中非常重要的原因。

- 拓展
在复数域上，对应的概念是酉矩阵(Unitary Matrix)，它满足 UᴴU = UUᴴ = I，其中 Uᴴ 是共轭转置。正交矩阵是酉矩阵在实数域上的特例。

==== 对称矩阵(Symmetric Matrix)
- 性质
    ** 特征值与特征向量
        *** 对称矩阵的所有特征值均为实数（即使矩阵元素是实数）。
        *** 特征向量可以选为两两正交的（适用于不同特征值对应的特征向量）。

- 拓展
在复数域上，对应的概念是Hermitian矩阵(厄米特矩阵)。

==== 正定矩阵(Positive Definite Matrix)
- 概念
正定矩阵是线性代数中一类重要的对称矩阵(或Hermitian矩阵)。
其核心性质是所有非零向量的二次型均为正。

- 实对称正定矩阵
设 A 是一个 n×n 的实对称矩阵(即 A = Aᵀ)，如果对任意非零实向量 x∈Rⁿ ，有: xᵀAx > 0，则称 A 为正定矩阵。

- 复Hermitian正定矩阵
设 A 是一个 n×n 的Hermitian矩阵(即 A = Aᴴ，共轭转置），如果对任意非零复向量 x∈Cⁿ ，有: xᴴAx > 0，则称 A 为正定矩阵。

==== Jacobian矩阵(雅克比矩阵)
===== 概念
Jacobian矩阵是描述多元向量函数一阶偏导数的核心工具，是向量微积分中的重要概念，用于描述一个向量值函数的一阶偏导数。

Q: Jacobian矩阵 vs. 梯度
梯度是标量函数的一阶导数（输出为向量）。
Jacobian是向量函数的一阶导数（输出为矩阵）。

===== 示例
ifndef::env-github[]
latexmath:[设函数 \mathbf{F}(x, y) = \begin{bmatrix} x^2 y \\ 5x + \sin y \end{bmatrix}，其雅可比矩阵为：J = \begin{bmatrix}2xy & x^2 \\5 & \cos y\end{bmatrix}]
endif::[]

ifdef::env-github[]
```math
设函数 \mathbf{F}(x, y) = \begin{bmatrix} x^2 y \\ 5x + \sin y \end{bmatrix} ，其雅可比矩阵为：J = \begin{bmatrix}2xy & x^2 \\5 & \cos y\end{bmatrix}
```
endif::[]

==== Hessian矩阵(黑塞矩阵)
===== 概念
Hessian矩阵是一个由多变量函数的二阶偏导数组成的方阵，用于描述函数的局部曲率。它在优化、机器学习和数值分析中具有重要作用，尤其是在判断临界点的性质时。

Hessian矩阵可以看做是一元函数的二阶导数对多元函数的推广。

Q: Hessian矩阵与梯度的区别是什么？
Hessian = 梯度的雅可比矩阵：H(f)=J(∇f)

Q: 如何计算Hessian矩阵？
Q: 如何解决奇异Hessian矩阵问题？

参考:
https://en.wikipedia.org/wiki/Hessian_matrix

===== 定义
Hessian 矩阵是多元函数二阶偏导数构成的方阵。
ifndef::env-github[]
对于标量函数 latexmath:[$f: \mathbb{R}^n \to \mathbb{R}$]，其定义如下：
endif::[]
ifdef::env-github[]
对于标量函数 $f: \mathbb{R}^n \to \mathbb{R}$，其定义如下：
endif::[]

ifndef::env-github[]
[latexmath]
++++
\mathbf{H}(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \vdots \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
++++
endif::[]
ifdef::env-github[]
```math
\mathbf{H}(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \vdots \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
```
endif::[]

===== 性质
====== 对称性
若函数二阶偏导数连续(Clairaut 定理)，则 Hessian 对称:
ifndef::env-github[]
    latexmath:[\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}]
endif::[]
ifdef::env-github[]
    $\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}$
endif::[]

====== 优化中的判定
ifndef::env-github[]
在临界点 \(\nabla f = 0\) 处：
正定 \(\lambda_i > 0\) → 局部最小值
负定 \(\lambda_i < 0\) → 局部最大值
不定 → 鞍点
endif::[]
ifdef::env-github[]
在临界点 $\nabla f = 0$ 处：
正定 $\lambda_i > 0$ → 局部最小值
负定 $\lambda_i < 0$ → 局部最大值
不定 → 鞍点
endif::[]

这与一元函数的结果类似，Hessian矩阵可以看做是一元函数的二阶导数对多元函数的推广:

    一元函数的极值判别法为，假设在某点处导数等于0，则:
        如果二阶导数大于0，函数有极小值
        如果二阶导数小于0，函数有极大值
        如果二阶导数等于0，情况不定

====== 凸性
ifndef::env-github[]
若 latexmath:[$\mathbf{H} \succeq 0$] 对所有 latexmath:[$\mathbf{x}$] 成立，则 latexmath:[$f$] 是凸函数。
endif::[]
ifdef::env-github[]
若 $\mathbf{H} \succeq 0$ 对所有 $\mathbf{x}$ 成立，则 $f$ 是凸函数。
endif::[]

===== 关系
* 与雅可比矩阵的关系
ifndef::env-github[]
latexmath:[\mathbf{H}(f) = \mathbf{J}(\nabla f)]
endif::[]
ifdef::env-github[]
$\mathbf{H}(f) = \mathbf{J}(\nabla f)$
endif::[]

* 泰勒二阶展开
ifndef::env-github[]
latexmath:[
f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f^\top (\mathbf{x}-\mathbf{x}_0) + \frac{1}{2} (\mathbf{x}-\mathbf{x}_0)^\top \mathbf{H} (\mathbf{x}-\mathbf{x}_0)]
endif::[]
ifdef::env-github[]
$f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f^\top (\mathbf{x}-\mathbf{x}_0) + \frac{1}{2} (\mathbf{x}-\mathbf{x}_0)^\top \mathbf{H} (\mathbf{x}-\mathbf{x}_0)$
endif::[]

===== 示例
ifndef::env-github[]
函数 \(f(x, y) = 3x^2 + 2xy + y^2\) 的 Hessian：
latexmath:[\mathbf{H} = \begin{bmatrix} 6 & 2 \\ 2 & 2 \end{bmatrix}]
特征值 \(\lambda_1 = 5+\sqrt{5}\), \(\lambda_2 = 5-\sqrt{5}\) → 正定 → 凸函数。
endif::[]
ifdef::env-github[]
函数 $f(x, y) = 3x^2 + 2xy + y^2$ 的 Hessian：
```math
\mathbf{H} = \begin{bmatrix} 6 & 2 \\ 2 & 2 \end{bmatrix}
```
特征值 $\lambda_1 = 5+\sqrt{5}$, $\lambda_2 = 5-\sqrt{5}$ → 正定 → 凸函数。
endif::[]

===== 应用
|===
| **领域**       | **用途**
| 优化算法       | 牛顿法、拟牛顿法（BFGS/L-BFGS）
| 机器学习       | 损失函数曲率分析、二阶优化
| 经济学         | 生产函数最优性评估
| 物理模拟       | 能量场稳定性判断
|===

== 行列式(Determinant)

== 线性方程组
=== 概念
- 线性方程
线性方程，也称为一次方程，是指在方程中，未知数的最高次数为1的方程。
其基本形式是ax+by+...+cz+d=0，其中a,b,c,d是常数，而x,y,z是未知数。
线性方程的特点是，在平面直角坐标系中，它的图像是一条直线。

- 非线性方程
非线性方程是指因变量与自变量之间的关系不是线性关系的方程，即方程中至少存在一个非线性项（如高次项、乘积项、超越函数等）。
与线性方程不同，非线性方程的解通常无法通过简单的代数叠加或比例关系直接求得，其解的性质也更加复杂。
关键特征:

    非线性项
        方程中可能包含:
            高次幂: 如x的平方、x的立方等
            变量乘积：如xy、x⋅y′(微分方程中)
            超越函数: 如sin(x)、ln(x)等
    不满足叠加性
        线性方程的解满足叠加原理(解的线性组合仍是解)，而非线性方程的解不满足这一性质。
    解的多重性与复杂性
        非线性方程可能有多个解、无解，甚至存在混沌现象。解的形式可能为数值解或特殊函数，而非解析解。

== 二次型(Quadratic form)

== 参考
《Introduction to Linear Algebra, 5th/6th》Gilbert Strang https://math.mit.edu/%7Egs/linearalgebra/ila6/indexila6.html
https://www.bilibili.com/video/BV1QS4y177Lg/
Essence of linear algebra: https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab
《Linear Algebra and Its Applications, 5th》
https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra
《Linear Algebra with Applications, 9th》 Steve J. Leon 中: 线性代数第9版
《Introduction to Applied Linear Algebra - Vectors, Matrices, and Least Squares》 中: 应用线性代数-向量、矩阵及最小二乘
《Matrix Analysis, 2nd》 中:《矩阵分析》第二版
The Matrix Cookbook, Version: November 15, 2012 https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf