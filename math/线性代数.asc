= 线性代数
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:stem: latexmath
:homepage: http://orientye.com

<<<

== 标量
标量(scalar)是一个单独的数值，它只有大小，没有方向。

== 向量
向量是一组有序的数，它既有大小又有方向。向量可以被视为标量值组成的列表。

== 矩阵
向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。

=== 乘法
vs. Hadamard乘积(也称为逐元素乘积或Schur乘积)

[options="header"]
|===
| 运算 | python函数 | 说明
| 矩阵乘法 | `@` or `np.matmul` | 标准行×列乘法
| 点积(高维) | `np.dot` | 行为复杂，推荐用@
| 逐元素乘法 | `*` or `np.multiply` | Hadamard乘积
|===


=== 秩
- 概念
矩阵的秩(Rank)是线性代数中的一个重要概念，表示矩阵中线性无关的行或列的最大数目。
矩阵的秩反映了矩阵所包含的信息量，是矩阵的一个重要特征。

- 定义
对于一个 m×n 的矩阵 A，其秩定义为：
行秩：矩阵中线性无关的行向量的最大数目。
列秩：矩阵中线性无关的列向量的最大数目。
行秩和列秩是相等的，因此统称为矩阵的秩，记作 rank(A)。

- 计算方法
初等行变换法:
    通过初等行变换将矩阵化为行阶梯形（Row Echelon Form），非零行的数目即为矩阵的秩。
子式法: 矩阵的秩等于其最高阶非零子式的阶数。

- 性质
对于 m×n 矩阵 A，有 rank(A)≤min(m,n)。
若 A 是方阵且满秩（即 rank(A)=n），则 A 可逆。
矩阵的秩在初等变换下不变。
对于矩阵 A 和 B，有 rank(A+B)≤rank(A)+rank(B)。
对于矩阵 A 和 B，有 rank(AB)≤min(rank(A),rank(B))。

- 应用
矩阵的秩在许多领域有广泛应用，如线性方程组的求解、矩阵分解、机器学习中的特征选择等。

- 参考
https://www.zhihu.com/question/21605094

=== 特征值(eigenvalues)与特征向量(eigenvectors)
==== 概念
- 概念
特征值是描述矩阵在线性变换中的缩放因子的标量。
特征向量是与特征值相关联的非零向量，它表示在线性变换中受到特征值缩放的方向。
https://tracholar.github.io/math/2018/01/28/matrix.html
https://zhuanlan.zhihu.com/p/165382601

- 向量特征-vs-特征向量
向量特征(vector features):
向量特征是指一个向量所具有的能够描述其某种性质或特点的属性。这些属性可以是向量的长度、方向、元素之间的关系、在某个坐标系下的坐标值等。
特征向量(eigenvector):
在矩阵和线性变换的背景下，设A是一个nxn的一个的方阵，若存在非零向量和实数，使得Ax=bx，则向量x称为矩阵A的属于特征值b的特征向量。

==== 定义
对于一个 *n×n* 的方阵 \(A\)，如果存在一个 *非零向量* \(\mathbf{v}\) 和一个 *标量* \(\lambda\)，使得：
\[ A \mathbf{v} = \lambda \mathbf{v} \]
则称：
- \(\lambda\) 为矩阵 \(A\) 的*特征值*（eigenvalue）。
- \(\mathbf{v}\) 为对应于 \(\lambda\) 的*特征向量*（eigenvector）。

==== 几何意义
- 特征向量 \(\mathbf{v}\) 在经过矩阵 \(A\) 的线性变换后，方向不变（或反向），仅长度缩放 \(\lambda\) 倍。
- 特征值 \(\lambda\) 表示缩放的比例。

==== 计算方法
==== 1. 求特征值
解特征方程：
\[ \det(A - \lambda I) = 0 \]
其中：
- \(I\) 是单位矩阵。
- \(\det\) 表示行列式。
这是一个关于 \(\lambda\) 的多项式方程（称为*特征多项式*），其根即为特征值。

==== 2. 求特征向量
对每个特征值 \(\lambda\)，解齐次线性方程组：
\[ (A - \lambda I) \mathbf{v} = 0 \]
非零解即为对应于 \(\lambda\) 的特征向量。

==== 示例
设矩阵：
\[ A = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} \]

==== 步骤 1：求特征值
计算行列式：
\[ \det(A - \lambda I) = \det \begin{pmatrix} 2 - \lambda & 1 \\ 1 & 2 - \lambda \end{pmatrix} = (2 - \lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = 0 \]
解得：
\[ \lambda_1 = 1, \quad \lambda_2 = 3 \]

==== 步骤 2：求特征向量
- 对于 \(\lambda = 1\)：
  \[ (A - I) \mathbf{v} = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = 0 \]
  解得：\(v_1 = -v_2\)，特征向量为 \(\mathbf{v} = k \begin{pmatrix} 1 \\ -1 \end{pmatrix}\)（\(k \neq 0\)）。
  
- 对于 \(\lambda = 3\)：
  \[ (A - 3I) \mathbf{v} = \begin{pmatrix} -1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = 0 \]
  解得：\(v_1 = v_2\)，特征向量为 \(\mathbf{v} = k \begin{pmatrix} 1 \\ 1 \end{pmatrix}\)（\(k \neq 0\)）。

==== 重要性质
- 矩阵的迹（trace）等于特征值之和：
  \[ \text{tr}(A) = \lambda_1 + \lambda_2 + \cdots + \lambda_n \]
- 矩阵的行列式等于特征值之积：
  \[ \det(A) = \lambda_1 \lambda_2 \cdots \lambda_n \]
- 不同特征值对应的特征向量线性无关。
- 实对称矩阵的特征向量可以选为正交的。

==== 应用
- *对角化*：若矩阵有 \(n\) 个线性无关的特征向量，则可对角化为 \(A = P D P^{-1}\)，其中 \(D\) 是对角矩阵。
- *主成分分析（PCA）*：通过协方差矩阵的特征值和特征向量降维。
- *振动分析*：特征值表示系统的固有频率，特征向量表示振型。

==== 注意事项
- 特征向量必须是非零向量。
- 复数矩阵可能有复数特征值和特征向量。
- 不是所有矩阵都有足够的线性无关特征向量（即不一定可对角化）。

==== 参考
https://immersivemath.com/ila/ch10_eigen/ch10.html

=== 正交矩阵(Orthogonal Matrix)

=== 正定矩阵(Positive Definite Matrix)

== 张量
向量是标量的推广，矩阵是向量的推广，张量是描述具有任意数量轴的n维数组的通用方法。

任何按元素的一元运算都不会改变其操作数的形状。同样，给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。

== 范数
范数是定义在向量空间（或矩阵）上的一个函数，用于衡量向量或矩阵的大小或长度。

深度学习中常见的范数:
L1范数：向量x的L1范数定义为向量各元素绝对值之和，即∥x∥1=∑|xi|。L1范数对异常值（离群点）的敏感度较低，常用于正则化项中，以促进模型的稀疏性。
L2范数：向量x的L2范数定义为向量各元素平方和的平方根，即∥x∥2=√(∑xi2，以避免根号运算。
Lp范数：Lp范数是L1范数和L2范数的推广，定义为∥x∥p=(∑|xi|(1/p)。当p取不同值时，可以得到不同的范数。
L∞范数：向量x的L∞范数定义为向量各元素绝对值的最大值，即∥x∥∞=max(|xi|)。L∞范数常用于衡量向量的最大元素值。
Frobenius范数：对于矩阵X，其Frobenius范数定义为矩阵各元素平方和的平方根，即∥X∥F=√(∑xij^2)。Frobenius范数满足向量范数的所有性质，常用于衡量矩阵的“大小”。

== 参考
《Introduction to Linear Algebra, 5th/6th》 https://math.mit.edu/%7Egs/linearalgebra/ila6/indexila6.html
Essence of linear algebra: https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab
《Linear Algebra and Its Applications, 5th》
https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra