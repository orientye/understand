= 程序员数学
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:homepage: http://orientye.com

<<<

== 位运算

=== 与运算&
判断是否为2次幂

    NO: if (n & (n - 1))

2次幂的性质: % -> &

    ringbuffer(如kfifo): in % size 可以转化为 in & (size – 1), 其中size为2次幂

=== 异或运算^
x ^ x = 0
x ^ 0 = x

== unsigned

=== kfifo
自动溢出结果依然正确:
数据长度: in - out
空闲长度: size - in + out
缓冲区空: in == out
缓冲区满: size == (in - out)

=== bsearch/bsort/pivot
http://orientye.com/go-sort/

== 随机数

== 傅里叶变换(Fourier Transform)
http://www.dspguide.com/pdfbook.htm
https://www.cnblogs.com/v-July-v/archive/2011/02/20/1983676.html
https://tracholar.github.io/math/2017/03/12/fourier-transform.html
https://github.com/Jezzamonn/fourier

== 微积分
=== 导数
导数可以被解释为函数相对于其变量的瞬时变化率，它也是函数曲线的切线的斜率。

=== 微分
- 微分在深度学习中的应用
微分(differential calculus)最重要的应用是优化问题，即考虑如何把事情做到最好。
在深度学习中，训练模型，不断更新它们，使它们在看到越来越多的数据时变得越来越好。通常情况下，变得更好意味着最小化一个损失函数(loss function)，即一个衡量模型有多糟糕这个问题的分数。最终，真正关心的是生成一个模型，它能够在从未见过的数据上表现良好。但训练模型只能将模型与实际能看到的数据相拟合。因此，可以将拟合模型的任务分解为两个关键问题：
    优化(optimization): 用模型拟合观测数据的过程；
    泛化(generalization): 生成出有效性超出用于训练的数据集本身的模型。

- 自动微分
深度学习框架通过自动计算导数，即自动微分(automatic differentiation)来加快求导。

=== 偏导数
https://zh.wikipedia.org/wiki/%E5%81%8F%E5%AF%BC%E6%95%B0

=== 梯度
梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数。

=== 链式法则
链式法则可以用来微分复合函数。

=== 积分
integral calculus

=== 应用

==== 参考
https://www.cnblogs.com/edward-bian/p/5237962.html

=== 参考

== 线性代数
=== 标量
=== 向量
=== 矩阵
==== 特征值与特征向量
https://tracholar.github.io/math/2018/01/28/matrix.html
=== 张量
=== 范数

== 概率论
=== 基本概率论
概率论公理
随机变量
=== 处理多个随机变量
联合概率
条件概率
贝叶斯定理
边际化
独立性
=== 期望和方差

== 统计分析
