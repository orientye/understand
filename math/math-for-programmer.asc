= 程序员数学
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:homepage: http://orientye.com

<<<

== 数学简史
《数学历史的启示》龚昇
《数学简史》莫里斯·克莱因

== 位运算

=== 与运算&
判断是否为2次幂

    NO: if (n & (n - 1))

2次幂的性质: % -> &

    ringbuffer(如kfifo): in % size 可以转化为 in & (size – 1), 其中size为2次幂

=== 异或运算^
x ^ x = 0
x ^ 0 = x

== unsigned

=== kfifo
自动溢出结果依然正确:
数据长度: in - out
空闲长度: size - in + out
缓冲区空: in == out
缓冲区满: size == (in - out)

=== bsearch/bsort/pivot
http://orientye.com/go-sort/

== 随机数

== 傅里叶变换(Fourier Transform)
http://www.dspguide.com/pdfbook.htm
https://www.cnblogs.com/v-July-v/archive/2011/02/20/1983676.html
https://tracholar.github.io/math/2017/03/12/fourier-transform.html
https://github.com/Jezzamonn/fourier

== 微积分
=== 导数
导数可以被解释为函数相对于其变量的瞬时变化率，它也是函数曲线的切线的斜率。

=== 微分
- 微分在深度学习中的应用
微分(differential calculus)最重要的应用是优化问题，即考虑如何把事情做到最好。
在深度学习中，训练模型，不断更新它们，使它们在看到越来越多的数据时变得越来越好。通常情况下，变得更好意味着最小化一个损失函数(loss function)，即一个衡量模型有多糟糕这个问题的分数。最终，真正关心的是生成一个模型，它能够在从未见过的数据上表现良好。但训练模型只能将模型与实际能看到的数据相拟合。因此，可以将拟合模型的任务分解为两个关键问题：
    优化(optimization): 用模型拟合观测数据的过程；
    泛化(generalization): 生成出有效性超出用于训练的数据集本身的模型。

- 自动微分
深度学习框架通过自动计算导数，即自动微分(automatic differentiation)来加快求导。

=== 偏导数
https://zh.wikipedia.org/wiki/%E5%81%8F%E5%AF%BC%E6%95%B0

=== 梯度
梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数。

=== 链式法则
链式法则可以用来微分复合函数。

=== 积分
integral calculus

=== 应用

==== 参考
https://www.cnblogs.com/edward-bian/p/5237962.html

=== 参考

== 线性代数
=== 标量
标量(scalar)是一个单独的数值，它只有大小，没有方向。

=== 向量
向量是一组有序的数，它既有大小又有方向。向量可以被视为标量值组成的列表。

=== 矩阵
向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。

==== 特征值与特征向量
https://tracholar.github.io/math/2018/01/28/matrix.html

=== 张量
向量是标量的推广，矩阵是向量的推广，张量是描述具有任意数量轴的n维数组的通用方法。

任何按元素的一元运算都不会改变其操作数的形状。同样，给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。

=== 范数
范数是定义在向量空间（或矩阵）上的一个函数，用于衡量向量或矩阵的大小或长度。

深度学习中常见的范数:
L1范数：向量x的L1范数定义为向量各元素绝对值之和，即∥x∥1=∑|xi|。L1范数对异常值（离群点）的敏感度较低，常用于正则化项中，以促进模型的稀疏性。
L2范数：向量x的L2范数定义为向量各元素平方和的平方根，即∥x∥2=√(∑xi2，以避免根号运算。
Lp范数：Lp范数是L1范数和L2范数的推广，定义为∥x∥p=(∑|xi|(1/p)。当p取不同值时，可以得到不同的范数。
L∞范数：向量x的L∞范数定义为向量各元素绝对值的最大值，即∥x∥∞=max(|xi|)。L∞范数常用于衡量向量的最大元素值。
Frobenius范数：对于矩阵X，其Frobenius范数定义为矩阵各元素平方和的平方根，即∥X∥F=√(∑xij^2)。Frobenius范数满足向量范数的所有性质，常用于衡量矩阵的“大小”。

== 概率论与数理统计
=== 基本概率论
概率论公理

=== 随机变量
random variable
离散(discrete)随机变量(如骰子的每一面)、连续(continuous)随机变量(如人的体重和身高)

正态分布(normal distribution):
也称为高斯分布(gaussian distribution)

=== 处理多个随机变量
联合概率
条件概率
贝叶斯定理
边际化
独立性

=== 期望和方差

=== 参数估计
==== 点估计
==== 矩估计
==== 最大似然估计
==== 最小方差无偏估计
==== 贝叶斯估计
==== 区间估计

== 参考
《Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning》
《南开讲义》陈省身
《Linear Algebra and Its Applications》
《The Probability Lifesaver》