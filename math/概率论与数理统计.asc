= 概率论与数理统计
:hardbreaks-option:
:revnumber: 0.0.1
:author: orient
:toc:
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:stem: latexmath
:homepage: http://orientye.com

<<<

== 基本概率论
概率论公理

== 随机变量(random variable)
离散(discrete)随机变量(如骰子的每一面)、连续(continuous)随机变量(如人的体重和身高)

正态分布(normal distribution):
也称为高斯分布(gaussian distribution)
https://en.wikipedia.org/wiki/Normal_distribution
正态分布的前世今生:
https://cosx.org/2013/01/story-of-normal-distribution-1
https://cosx.org/2013/01/story-of-normal-distribution-2

== 处理多个随机变量
联合概率
条件概率
贝叶斯定理
边际化
独立性

== 期望和方差

== 参数估计
=== 点估计
=== 矩估计
=== 最大似然估计
Q: 什么是似然(likelihood)？似然 vs. 概率(probability)

极大似然估计（Maximum Likelihood Estimation，简称 MLE）是一种统计推断方法，用于根据样本数据来估计概率分布的参数。其核心思想是：在给定样本数据的情况下，寻找使得样本出现概率最大的参数值。

基本原理:
假设有一个统计模型，其参数为θ，并且有一组观察数据X。最大似然估计的目标是找到使模型产生这组观察数据的概率最大的参数θ:
1. 定义似然函数：似然函数L(θ|X)表示在给定参数θ下，模型产生观察数据X的概率。通常，会使用概率密度函数（对于连续数据）或概率质量函数（对于离散数据）来定义似然函数。
2. 最大化似然函数：通过求解使似然函数达到最大值的参数θ，得到最大似然估计值。这通常涉及到对似然函数求导，并找到其导数为0的点（即极值点），然后检查这些点以确定哪个是最大值。
3. 求解参数：对于某些模型，似然函数的最大化可能涉及复杂的数学运算，如数值优化方法。

最大似然估计的结果依赖于观察数据的数量和质量。
对于某些模型，最大似然估计可能不是唯一的，或者可能不存在（如当似然函数没有最大值时）。
最大似然估计通常不提供关于参数估计不确定性的直接信息。为了评估这种不确定性，可能需要使用其他方法，如贝叶斯估计或置信区间。
总的来说，最大似然估计是一种强大且广泛使用的统计方法，用于从观察数据中估计模型参数。

参考:
https://www.zhihu.com/question/54082000

=== 最小方差无偏估计
=== 贝叶斯估计
=== 区间估计

=== 差分方程、马尔可夫过程和概率论
==== 马尔可夫过程
一般的马尔可夫过程:
马尔可夫过程本质上是这样一个系统：为了预测n + 1时刻的行为，关键是看它在 n 时刻的状态。换句话说，知道如何到达 n 时刻的状态并不能为预测下一刻会发生什么提供任何额外的信息。

=== 最小二乘法
最小二乘法是确定数据最佳拟合线的一种方法，其证明会用到微积分和线性代数。

== 参考
《The Probability Lifesaver》中文: 普林斯顿概率论读本
《Introduction to Probability》中文: 概率导论(第2版·修订版)
《Probability Theory》中文: 概率论沉思录
《伊藤清概率论》