:toc:
:toclevels: 5
:hardbreaks-option:

== TCP

=== 格式

==== 定义
https://en.wikipedia.org/wiki/Transmission_Control_Protocol#TCP_segment_structure

header长度:
与IP header类似，tcp header一般也是20字节，如果有Options数据，最大会到60字节(由4个bits的Data Offset决定)。

TCP Header Format:

    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |          Source Port          |       Destination Port        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                        Sequence Number                        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                    Acknowledgment Number                      |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |  Data |           |U|A|P|R|S|F|                               |
   | Offset| Reserved  |R|C|S|S|Y|I|            Window             |
   |       |           |G|K|H|T|N|N|                               |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |           Checksum            |         Urgent Pointer        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                    Options                    |    Padding    |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                             data                              |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

参考: https://www.rfc-editor.org/rfc/rfc793#section-3.1

IPv6: https://www.ietf.org/rfc/rfc2460.txt

==== Sequence number
32 bits

Has a dual role:
If the SYN flag is set (1), then this is the initial sequence number. The sequence number of the actual first data byte and the acknowledged number in the corresponding ACK are then this sequence number plus 1.
If the SYN flag is clear (0), then this is the accumulated sequence number of the first data byte of this segment for the current session.

用来解决乱序问题。

序列号(SEQ):
在建立连接时由计算机生成的随机数作为其初始值，通过SYN包传给接收端主机，每发送一次数据，就累加一次该数据字节数的大小。
为了保证消息的顺序性和可靠性，TCP为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。序列号是一个32位的无符号数，因此在到达4G之后再循环回到 0。

初始值(ISN):
The synchronization requires each side to send it's own initial sequence number and to receive a confirmation of it in acknowledgment from the other side.  Each side must also receive the other side's initial sequence number and send a confirming acknowledgment.
在TCP建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。
ISN会和一个假的时钟绑在一起, 这个时钟会在每4微秒对ISN做加一操作, 直到超过2^32, 又从0开始。这样, 一个ISN的周期大约是4.55个小时。因为, 假设TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime(MSL), 所以, 只要MSL的值小于4.55小时, 那么, 就不会重用到ISN。
一般来说, 各个OS实现不一样, It is a random number between 0 and 4,294,967,295。
Wireshark为了显示更友好, 使用了Relative SeqNum相对序号, 只要在右键菜单中的protocol preference中取消掉就可以看到"Absolute SeqNum"。

序列号回绕(PAWS):
PROTECT AGAINST WRAPPED SEQUENCE NUMBERS
尽管通过每次建立连接时初始化不同的序列号，以及关闭时TIME_WAIT状态持续2MSL时长(但不一定能正常关闭)，极大降低了历史报文被相同四元组的连接接收的概率。但是，序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据，历史报文仍然存在被接收的可能。
为此，rfc1323引入了TCP timestamps选项(位于Options里)来解决这一问题:
https://www.rfc-editor.org/rfc/rfc1323#page-17
[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/net/tcp.h
----
static inline bool tcp_paws_check(const struct tcp_options_received *rx_opt,
				  int paws_win)
{
      //...
	if (unlikely(!time_before32(ktime_get_seconds(),
				    rx_opt->ts_recent_stamp + TCP_PAWS_24DAYS)))
		return true;
      //...
	return false;
}
----

参考: https://www.rfc-editor.org/rfc/rfc793#section-3.3

==== Acknowledgment number
32 bits
If the ACK flag is set then the value of this field is the next sequence number that the sender of the ACK is expecting. This acknowledges receipt of all prior bytes (if any). The first ACK sent by each end acknowledges the other end's initial sequence number itself, but no data.

确认应答号:
指下一次期望收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。
用来解决丢包的问题。

==== TCP Flags
8bits

SYN - The SYN, or Synchronisation flag, is used as a first step in establishing a 3-way handshake between two hosts. Only the first packet from both the sender and receiver should have this flag set. The following diagram illustrates a 3-way handshake process.

ACK - The ACK flag, which stands for "Acknowledgment", is used to acknowledge the successful receipt of a packet. As we can see from the diagram above, the receiver sends an ACK as well as a SYN in the second step of the 3-way handshake process to tell the sender that it received its initial packet.

FIN - The FIN flag, which stands for "Finished", means there is no more data from the sender. Therefore, it is used in the last packet sent from the sender.

URG - The URG flag is used to notify the receiver to process the urgent packets before processing all other packets. The receiver will be notified when all known urgent data has been received. See RFC 6093 for more details.

PSH - The PSH flag, which stands for "Push", is somewhat similar to the URG flag and tells the receiver to process these packets as they are received instead of buffering them.

RST - The RST flag, which stands for "Reset", gets sent from the receiver to the sender when a packet is sent to a particular host that was not expecting it.  

ECE - This flag is responsible for indicating if the TCP peer is ECN capable. See RFC 3168 for more details.

CWR - The CWR flag, which stands for Congestion Window Reduced, is used by the sending host to indicate it received a packet with the ECE flag set. See RFC 3168 for more details.

NS (experimental) - The NS flag, which stands for Nonce Sum, is still an experimental flag used to help protect against accidental malicious concealment of packets from the sender. See RFC 3540 for more details.

==== Window size
16 bits

The size of the receive window, which specifies the number of window size units that the sender of this segment is currently willing to receive.
用来解决流控问题。

==== Options

===== TCP timestamps
作用:
1、两端往返时延测量(RTTM)
2、序列号回绕(PAWS)

TCP timestamps are enabled by default in Linux(不过一些linux云服务器会设置成disable), and disabled by default in Windows Server 2008, 2012 and 2016.

命令: cat /proc/sys/net/ipv4/tcp_timestamps 默认值为1

参考:
https://en.wikipedia.org/wiki/Transmission_Control_Protocol#TCP_timestamps
https://datatracker.ietf.org/doc/html/rfc1323

=== 状态

==== 概要

      CLOSE
            The socket is not being used.

      LISTEN 
            The socket is listening for incoming connections. 
            Such sockets are not included in the output unless you specify the --listening (-l) or --all (-a) option.

      SYN_SENT
            The socket is actively attempting to establish a connection.

      SYN_RECV
            A connection request has been received from the network.

      ESTABLISHED
            The socket has an established connection.

      FIN_WAIT1
            The socket is closed, and the connection is shutting down.

      FIN_WAIT2
            Connection is closed, and the socket is waiting for a shutdown from the remote end.

      TIME_WAIT
            The socket is waiting after close to handle packets still in the network.

      CLOSE_WAIT
            The remote end has shut down, waiting for the socket to close.

      LAST_ACK
            The remote end has shut down, and the socket is closed. Waiting for acknowledgement.

      CLOSING
            Both sockets are shut down but we still don't have all our data sent.

参考: https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Protocol_operation

==== 三次握手

      client                                               server
      CLOSED                                               LISTEN
      SYN-SENT    --> <SEQ=100><CTL=SYN>               --> SYN-RECEIVED
      ESTABLISHED <-- <SEQ=300><ACK=101><CTL=SYN,ACK>  <-- SYN-RECEIVED
      ESTABLISHED --> <SEQ=101><ACK=301><CTL=ACK>      --> ESTABLISHED

第三次握手是可以携带数据的，前两次握手不可以携带数据。

为什么两次握手不行?
The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.

参考: https://www.rfc-editor.org/rfc/rfc793#section-3.4

==== 四次挥手
NOTE: CLOSE is an operation meaning "I have no more data to send."

NOTE: 调用close()与CLOSE状态是两回事，进入CLOSE状态是有一个过程的。

Normal Close Sequence:

        TCP A                                                TCP B
    1.  ESTABLISHED                                          ESTABLISHED
    2.  (Close)
        FIN-WAIT-1  --> <SEQ=100><ACK=300><CTL=FIN,ACK>  --> CLOSE-WAIT
    3.  FIN-WAIT-2  <-- <SEQ=300><ACK=101><CTL=ACK>      <-- CLOSE-WAIT
    4.                                                       (Close)
        TIME-WAIT   <-- <SEQ=300><ACK=101><CTL=FIN,ACK>  <-- LAST-ACK
    5.  TIME-WAIT   --> <SEQ=101><ACK=301><CTL=ACK>      --> CLOSED
    6.  (2 MSL)
        CLOSED

Simultaneous Close Sequence:

        TCP A                                                TCP B
    1.  ESTABLISHED                                          ESTABLISHED
    2.  (Close)                                              (Close)
        FIN-WAIT-1  --> <SEQ=100><ACK=300><CTL=FIN,ACK>  ... FIN-WAIT-1
                    <-- <SEQ=300><ACK=100><CTL=FIN,ACK>  <--
                    ... <SEQ=100><ACK=300><CTL=FIN,ACK>  -->
    3.  CLOSING     --> <SEQ=101><ACK=301><CTL=ACK>      ... CLOSING
                    <-- <SEQ=301><ACK=101><CTL=ACK>      <--
                    ... <SEQ=101><ACK=301><CTL=ACK>      -->
    4.  TIME-WAIT                                            TIME-WAIT
        (2 MSL)                                              (2 MSL)
        CLOSED                                               CLOSED

参考: https://www.rfc-editor.org/rfc/rfc793#section-3.5

NOTE: 为什么挥手需要四次？
关闭连接时，客户端向服务端发送FIN时，仅仅表示客户端不再发送数据了但是还能接收数据。
服务端收到客户端的FIN报文时，先应答一个ACK报文，此时服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送FIN报文给客户端表示服务器现在关闭连接。
也就是说，服务端通常需要等待完成数据的发送和处理，因此服务端的ACK和FIN一般都会分开发送，这也就需要四次挥手。

==== sync
▪ 建立连接时SYN超时
如果server端接到了clien发的SYN后回了SYN-ACK后, client掉线了, server端没有收到client回来的ACK, 那么, 这个连接处于一个中间状态, 即没成功, 也没失败。于是, server端如果在一定时间内没有收到的TCP会重发SYN-ACK。Linux下默认重试次数为5次, 5次的重试时间间隔为1s, 2s, 4s, 8s, 16s, 总共31s, 第5次发出后还要等32s都知道第5次也超时了, 因此，总共需要1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s, TCP才会把断开这个连接。

▪ SYN Flood攻击
一些恶意的人就为此制造了SYN Flood攻击: 给服务器发了一个SYN后就下线了, 于是服务器需要默认等63s才会断开连接, 这样, 攻击者就可以把服务器的syn连接的队列耗尽, 让正常的连接请求不能处理。于是, Linux下给了一个叫tcp_syncookies的参数来应对这个事: 当SYN队列满了后, TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去(又叫cookie), 如果是攻击者则不会有响应, 如果是正常连接, 则会把这个SYN Cookie发回来, 然后服务端可以通过cookie建连接(即使你不在SYN队列中)。请注意, 请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为, synccookies是妥协版的TCP协议, 并不严谨。对于正常的请求, 应该调整三个TCP参数: tcp_synack_retries用来减少重试次数; tcp_max_syn_backlog用来增大SYN连接数; tcp_abort_on_overflow处理不过来干脆就直接拒绝连接。 

▪ tcp_syncookies
Only valid when the kernel was compiled with CONFIG_SYN_COOKIES Send out syncookies when the syn backlog queue of a socket overflows. This is to prevent against the common 'SYN flood attack' Default: 1
Note, that syncookies is fallback facility. It MUST NOT be used to help highly loaded servers to stand against legal connection rate. If you see SYN flood warnings in your logs, but investigation shows that they occur because of overload with legal connections, you should tune another parameters until this warning disappear. See: tcp_max_syn_backlog, tcp_synack_retries, tcp_abort_on_overflow.
syncookies seriously violate TCP protocol, do not allow to use TCP extensions, can result in serious degradation of some services (f.e. SMTP relaying), visible not by you, but your clients and relays, contacting you. While you see SYN flood warnings in logs not being really flooded, your server is seriously misconfigured.
If you want to test which effects syncookies have to your network connections you can set this knob to 2 to enable unconditionally generation of syncookies.
cat /proc/sys/net/ipv4/tcp_syncookies 默认值为1
开启tcp_syncookies后:
在SYN队列(半连接对接)满了的情况下，服务端收到SYN包，不会丢弃，而是计算出一个cookie值，并将cookie值放到第二次握手报文的序列号里，然后返回第二次握手给客户端；
之后服务端接收到客户端的应答报文时，服务端会检查ACK包的合法性。如果合法，将该连接放入到Accept队列(全连接队列)。
服务器通过调用accpet()接口，从Accept队列中取出连接。
参考: https://www.kernel.org/doc/html/latest/networking/ip-sysctl.html#tcp-variables

参考: https://coolshell.cn/articles/11564.html

==== time_wait
===== Why TIME_WAIT state
To implement TCP's full-duplex connection termination reliably
To allow old duplicate segments to expire in the network

第一点: 保证TCP协议的全双工连接能够可靠关闭:
由于IP协议的不可靠性或者是其它网络原因，导致了Server端没有收到Client端的ACK报文，那么Server端就会在超时之后重新发送FIN，如果此时Client端的连接已经关闭处于CLOESD状态，那么重发的FIN就找不到对应的连接了，从而导致连接错乱，所以，Client端发送完最后的ACK不能直接进入CLOSED状态，而要保持TIME_WAIT，当再次收到FIN的收，能够保证对方收到ACK，最后正确关闭连接。
第二点: 保证这次连接的重复数据段从网络中消失
如果Client端发送最后的ACK直接进入CLOSED状态，然后又再向Server端发起一个新连接，这时不能保证新连接的与刚关闭的连接的端口号是不同的，也就是新连接和老连接的端口号可能一样了，那么就可能出现问题:如果前一次的连接某些数据滞留在网络中，这些延迟数据在建立新连接后到达Client端，由于新老连接的端口号和IP都一样，TCP协议就认为延迟数据是属于新连接的，新连接就会接收到脏数据，这样就会导致数据包混乱。所以TCP连接需要在TIME_WAIT状态等待2倍MSL，才能保证本次连接的所有数据在网络中消失。

The first reason can be explained by looking at Figure 2.5 and assuming that the final ACK is lost. The server will resend its final FIN, so the client must maintain state information, allowing it to resend the final ACK. If it did not maintain this information, it would respond with an RST (a different type of TCP segment), which would be interpreted by the server as an error. If TCP is performing all the work necessary to terminate both directions of data flow cleanly for a connection (its full-duplex close), then it must correctly handle the loss of any of these four segments. This example also shows why the end that performs the active close is the end that remains in the TIME_WAIT state: because that end is the one that might have to retransmit the final ACK.

To understand the second reason for the TIME_WAIT state, assume we have a TCP connection between 12.106.32.254 port 1500 and 206.168.112.219 port 21. This connection is closed and then sometime later, we establish another connection between the same IP addresses and ports: 12.106.32.254 port 1500 and 206.168.112.219 port 21. This latter connection is called an incarnation of the previous connection since the IP addresses and ports are the same. TCP must prevent old duplicates from a connection from reappearing at some later time and being misinterpreted as belonging to a new incarnation of the same connection. To do this, TCP will not initiate a new incarnation of a connection that is currently in the TIME_WAIT state. Since the duration of the TIME_WAIT state is twice the MSL, this allows MSL seconds for a packet in one direction to be lost, and another MSL seconds for the reply to be lost. By enforcing this rule, we are guaranteed that when we successfully establish a TCP connection, all old duplicates from previous incarnations of the connection have expired in the network.

===== Why 2MSL
参考:《Unix Networking Programming Volume 1, 3rd》2.7

===== 大量time_wait连接问题
如果存在大量的time_wait连接, 会影响新的连接的创建: 因为该socket需2MSL即2*(30s-2min)才会完全关闭释放。

- 首选方法
尽量让客户端主动关闭
Q: 哪些情况下需要服务器主动关闭呢？

- 方法二
There's another way to terminate a TCP connection and that's by aborting the connection and sending an RST rather than a FIN. This is usually achieved by setting the SO_LINGER socket option to 0.
https://stackoverflow.com/questions/3757289/when-is-tcp-option-so-linger-0-required

- 不太好的方式
tcp_tw_recycle
tcp_tw_reuse or SO_REUSEADDR(Q: vs. SO_REUSEPORT)
tcp_max_tw_buckets(控制并发的TIME_WAIT的数量)
tcp_fin_timeout
命令:
例如 cat /proc/sys/net/ipv4/tcp_max_tw_buckets

===== 服务端会主动断开连接的情况(需要避免!)
- HTTP没有使用长连接
HTTP/1.1开始默认开启了Keep-Alive，大多数浏览器也都默认使用HTTP/1.1。
但如果客户端与服务器任意一方没有开启HTTP Keep-Alive(在HTTP请求或者响应的header里添加Connection:close信息)，均会导致服务器在处理完HTTP请求后主动关闭连接，此时服务器上就会出现大量的TIME_WAIT状态的连接。

- HTTP长连接超时
Web服务器一般会提供一个参数来指定HTTP长连接的超时时间，如果客户端在完后一个HTTP请求后，在设定时间例如60秒内没有再发起新的请求，服务器就会主动关闭该连接。例如nginx提供的keepalive_timeout参数。

- HTTP长连接的请求数量达到上限
Web服务器一般会提供一个参数来指定HTTP长连接上最大能处理的请求数量，当超过最大限制时，服务器就会主动关闭连接。例如nginx提供的keepalive_requests参数。

- 不合理的程序写法

===== 配置相关
- tcp_tw_recycle
The net.ipv4.tcp_tw_recycle has been removed from Linux 4.12 on 2017.
参考: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc

- tcp_tw_reuse
默认值为2:  0 - disable    1 - global enable    2 - enable for loopback traffic only
命令: cat /proc/sys/net/ipv4/tcp_tw_reuse
参考: https://www.xiaolincoding.com/network/3_tcp/tcp_tw_reuse_close.html

==== close_wait
▪ 问题: 如果存在大量的close_wait连接
▪ 解决: 通常是代码问题, 即被动关闭方未关闭socket造成

参考: https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&mid=2247486020&idx=1&sn=f7cf41aec28e2e10a46228a64b1c0a5c&scene=21#wechat_redirect

==== RST
▪ 什么情况下发生
1、目标端口未打开/目的主机或者网络路径中防火墙拦截: 目标会向对方发送RST
2、socket接收缓冲取Recv-Q中的数据未完全被应用程序读取时关闭该socket: 会向对方发送RST
3、向对端已关闭的socket发送数据: 对端会向发送方发送RST
4、使用SO_LINGER规定close()行为是发送RST, 而不是发送FIN
5、向对端已经消逝的连接中发送数据
消逝连接指的是, 当前这个连接状态操作系统已经不再维护, 其数据结构内核已经注销。
比如对端FIN_WAIT2超时后, 其实该连接已经不存在;
比如半打开(Half Open)连接的对端, 由于某种原因已经不存在;
比如服务器重启, 端口号不变, 此时客户端没有检测到服务器重启仍向服务器发送数据, 则收到服务器发来的RST;
比如客户端断网, 重新连接网络, 但是没有连接服务器, 此时服务器没有检测到客户端断网重连仍向客户端发送数据, 则收到客户端发来的RST;

另: https://stackoverflow.com/questions/251243/what-causes-a-tcp-ip-reset-rst-flag-to-be-sent

▪ 处理:
在TCP协议中, rst段标识复位(ECONNRESET), 用来异常的关闭连接。
1. 发送RST包关闭连接时, 不必等缓冲区的包都发出去, 直接就丢弃缓冲区中的包, 发送RST。
2. 收到RST包后, 也不必发送ACK包来确认。接收端收到RST知道发送端是异常关闭。
ECONNRESET: https://man7.org/linux/man-pages/man3/errno.3.html

RFC793(page36, section3.4)

Reset Processing
In all states except SYN-SENT, all reset (RST) segments are validated by checking their SEQ-fields.  A reset is valid if its sequence number is in the window.  In the SYN-SENT state (a RST received in response to an initial SYN), the RST is acceptable if the ACK field acknowledges the SYN.

The receiver of a RST first validates it, then changes state.  If the receiver was in the LISTEN state, it ignores it.  If the receiver was in SYN-RECEIVED state and had previously been in the LISTEN state,then the receiver returns to the LISTEN state, otherwise the receiver aborts the connection and goes to the CLOSED state.  If the receiver was in any other state, it aborts the connection and advises the user and goes to the CLOSED state.

▪ 实现:
tcp_v4_send_reset(): https://elixir.bootlin.com/linux/latest/source/net/ipv4/tcp_ipv4.c

▪ RST攻击与防御

==== 异常行为
▪ 对端程序异常结束
      崩溃/断电/重启
            一段时间内重连         本端有/无操作分别会发生什么
            一段时间内未重连       本端有/无操作分别会发生什么
            始终没有重连           本端有/无操作分别会发生什么

▪ 对端程序程序未结束
      拔掉网线/中间路径超时
            一段时间内             本端有/无操作分别会发生什么
            超过一段时间           本端有/无操作分别会发生什么

=== 超时与重传
==== ARQ(Automatic Repeat Request)
==== 基于计时器的重传
==== 快速重传
==== 带选择确认的重传(SACK, Selective Acknowledgment)
只重传丢失的片段
需要设备同时支持SACK才可以
https://www.youtube.com/watch?v=VERgI8QaYPY
https://datatracker.ietf.org/doc/html/rfc2018

==== 伪超时重传
- DSACK
重复SACK
https://datatracker.ietf.org/doc/html/rfc2883

- Eifel检测算法
- Forward-RTO Recovery
- Eifel响应算法

=== 流控与拥塞
==== 概念
===== 流量控制(点对点通信控制)

让发送方发送速率不要太快, 使接收方来得及接收。
基于滑动窗口的流量控制机制: 接收方根据接收缓存的大小动态控制发送方的发送窗口大小(调整TCP首部"窗口"字段值), 限制发送方网络注入报文的速率, 同时根据网络拥塞程度估计窗口值。

===== 拥塞控制(全局, 涉及全网络主机、路由器等)

防止过多的数据注入网络, 可以使网络中的路由器或链路不致于过载。
算法: 慢开始、拥塞避免、快重传、快恢复

发送方维持一个拥塞窗口(cwnd)的状态变量, 该大小取决于网络拥塞程度, 并动态变化
变化原则: 网络无拥塞, 窗口增大;网络拥塞则减小

新建立的连接不能够一开始就大量发送数据包, 而是根据网络情况逐步增加每次发送的数量。
为防止cwnd增长过大引起网络阻塞, 设置慢开始门限ssthresh状态变量选择慢开始算法与拥塞避免算法

拥塞窗口缓慢增长, 每经过一个往返时间RTT就把发送发的拥塞窗口+1, 而不是加倍。
(以上两个阶段若出现拥塞, 门限设置为出现拥塞时发送窗口的一半, 窗口值设为1, 执行慢开始算法)

▪ 慢开始与拥塞避免

▪ 慢开始(cwnd指数型增长)

▪ 拥塞避免(cwnd线性增长)

▪ 快重传与快恢复

▪ 快重传
接收方在收到一个失序的报文段后立即发出重复确认, 发送方只要收到三个重复确认就应当立即重传尚未收到的报文段, 不必等待设置的重传计时器时间到期。

▪ 快恢复
发送方收到三个重复确认时, ssthresh门限减半, 然后执行拥塞避免算法。

==== 流控
▪ Flow Control解决的问题

▪ 延时确认(Delayed Acknowledgments)

The Nagle algorithm says that when a TCP connection has outstanding data that has not yet been acknowledged, small segments (those smaller than the SMSS) cannot be sent until all outstanding data is acknowledged. Instead, small amounts of data are collected by TCP and sent in a single segment when an acknowledg- ment arrives. 

▪ Nagle算法

禁用Nagle算法: TCP_NODELAY

vs TCP_CORK aggressively accumulates data. If TCP_CORK is enabled in a socket, it will not send data until the buffer fills to a fixed limit. Similar to Nagle's algorithm, it also accumulates data from user but until the buffer fills to a fixed limit not until receiving ACK. This will be useful while sending multiple blocks of data. But you have to be more careful while using TCP_CORK.Until 2.6 kernel, both of these options are mutually exclusive. But in later kernel, both of them can exist together. In such case, TCP_CORK will be given more preference.

TCP_CORK (or TCP_NOPUSH in FreeBSD)
If set, don't send out partial frames. All queued partial frames are sent when the option is cleared again. This is useful for prepending headers before calling sendfile(2), or for throughput optimization. As currently implemented, there is a 200-millisecond ceiling on the time for which output is corked by TCP_CORK. If this ceiling is reached, then queued data is automatically transmitted. This option can be combined with TCP_NODELAY only since Linux 2.5.71. This option should not be used in code intended to be portable.

tcp_nodelay on;  (nginx, go等默认)
dotnet: 默认不开启tcp_nodelay https://learn.microsoft.com/en-us/dotnet/api/system.net.sockets.tcpclient.nodelay
tcp_nopush off;  (nginx默认)

▪ 窗口大小
TCP头部的窗口大小表明接收端可以缓存空间的大小, 该字段为16位, 也就是64K, RFC 1323扩展之后, 就可以使用32位的值来表示窗口的大小了

▪ 滑动窗口

▪ 零窗口

▪ 糊涂窗口综合症(Silly Window Syndrome)

▪ Large Buffers and Auto-Tuning:

    net.core.rmem_max = 131071
    net.core.wmem_max = 131071
    net.core.rmem_default = 110592
    net.core.wmem_default = 110592
    In addition, the auto-tuning parameters are given by the following variables:
    net.ipv4.tcp_rmem = 4096 87380 174760
    net.ipv4.tcp_wmem = 4096 16384 131072

==== 拥塞
===== 概念
▪ Congestion
when a router is forced to discard data because it cannot handle the arriving traffic rate, is called congestion.

▪ 命令

    查看支持的拥塞算法: sysctl net.ipv4.tcp_available_congestion_control
    查看使用的拥塞算法: sysctl net.ipv4.tcp_congestion_control

▪ 注意: 拥塞控制算法只与局部有关, 两端可以使用不同的拥塞算法

▪ 拥塞检测
丢包可能由拥塞(主要是有线网络)引起, 也可能由传输和接收错误(主要是无线网络)引起

▪ 显式拥塞通知
ECN允许拥塞控制的端对端通知而避免丢包。ECN为一项可选功能，如果底层网络设施支持，则可能被启用ECN的两个端点使用。
通常来说，TCP/IP网络通过丢弃数据包来表明信道阻塞。在ECN成功协商的情况下，ECN感知路由器可以在IP头中设置一个标记来代替丢弃数据包，以标明阻塞即将发生。数据包的接收端回应发送端的表示，降低其传输速率，就如同在往常中检测到包丢失那样。
https://en.wikipedia.org/wiki/Explicit_Congestion_Notification

▪ 减缓TCP发送
The sender’s actual (usable) window W is then written as the minimum of the receiver’s advertised window awnd and the congestion window: W = min(cwnd, awnd) 

▪ 1988年TCP Tahoe 提出了1)慢启动, 2)拥塞避免, 3)拥塞发生时的快速重传 
▪ 1990年TCP Reno 在Tahoe的基础上增加了4)快速恢复

▪ 对标准算法的改进
New Reno
SACK        FACK  限制传输   CWV(Congestion Window Validation)拥塞窗口校验

▪ 其它
HSTCP     BIC和CUBIC(linux2.6.18起默认)  Vegas  FAST CTCP(compound tcp 复合tcp)

▪ 常见的拥塞算法可以分为三类:
▪ 基于路径时延(如Vegas、Westwood)
▪ 基于丢包(如Cubic、NewReno)
将路径时延上升作为发生拥塞的信号, 在单一的网络环境下(所有连接都使用基于路径时延的拥塞算法)是可行的, 但是在复杂的网络环境下, 带宽容易被其他算法抢占, 带宽利用率最低。
将丢包作为发生拥塞的信号, 其背后的逻辑是路由器、交换机的缓存都是有限的, 拥塞会导致缓存用尽, 进而队列中的一些报文会被丢弃。
拥塞会导致丢包, 但是丢包却不一定拥塞导致的。事实上, 丢包可以分为两类, 一类是拥塞丢包, 另一类是噪声丢包, 特别是在无线网络环境中, 数据以无线电的方式进行传递, 无线路由器信号干扰、蜂窝信号不稳定等都会导致信号失真, 最终数据链路层 CRC 校验失败将报文丢弃。
基于丢包的拥塞算法容易被噪声丢包干扰, 在高丢包率高延迟的环境中带宽利用率较低。
▪ 基于带宽时延探测(如BBR)
既然无法区分拥塞丢包和噪声丢包, 那么就不以丢包作为拥塞信号, 而是通过探测最大带宽和最小路径时延来确定路径的容量。抗丢包能力强, 带宽利用率高。

三种类型的拥塞算法没有谁好谁坏, 都是顺应当时的网络环境的产物, 随着路由器、交换机缓存越来越大, 无线网络的比例越来越高, 基于路径时延和基于丢包的的拥塞算法就显得不合时宜了。对于流媒体、文件上传等对带宽需求比较大的场景, BBR成为更优的选择。

参考: https://www.infoq.cn/article/SY0KFJ2pyJomB6sAkqls

===== 慢启动(slow start)
1) 连接建好的开始先初始化cwnd = 1, 表明可以传一个MSS大小的数据(准确来说是smss, 发送方最大段大小, 大部分情况下, smss为接收方mss和路径mtu两者中较小值)
2) 每当收到一个ACK, cwnd++; 呈线性上升
3) 每当过了一个RTT, cwnd = cwnd*2; 呈指数上升
4) 上限ssthresh(slow start threshold), 当cwnd >= ssthresh时, 就会进入拥塞避免算法
因此, 如果网速很快的话, ACK也会返回得快, RTT也会短, 那么, 这个慢启动就一点也不慢。

Google的论文《An Argument for Increasing TCP’s Initial Congestion Window》Linux 3.0后采用了这篇论文的建议: 把cwnd初始化成了10个MSS。
而Linux 3.0以前, 比如2.6, Linux采用了RFC3390, cwnd是跟MSS的值来变的, 如果MSS < 1095则cwnd = 4;如果MSS > 2190则cwnd = 2; 其它情况下则为3。

===== 拥塞避免(Congestion Avoidance)
一般来说ssthresh的值是65535, 单位是字节, 当cwnd达到这个值时后, 算法如下:
1) 收到一个ACK时, cwnd = cwnd + 1 / cwnd
2) 当每过一个RTT时, cwnd = cwnd + 1
这样就可以避免增长过快导致网络拥塞, 慢慢的增加调整到网络的最佳值。很明显, 是一个线性上升的算法。
注: ssthresh是变化的 ssthresh = max(flight size/2, 2*SMSS)
In Microsoft’s most recent ("Next Generation") TCP/IP stack, this equation is reportedly changed to the somewhat more conservative relationship: ssthresh = max(min(cwnd, awnd)/2, 2*SMSS) 

===== 拥塞发生时的快速重传(Congestion Avoidance)
当丢包的时候, 会有两种情况:
1) 等到RTO超时, 重传数据包。TCP认为这种情况太糟糕, 反应也很强烈。
sshthresh = cwnd / 2    cwnd重置为1, 进入慢启动过程
2) Fast Retransmit算法, 也就是在收到3个duplicate ACK时就开启重传, 而不用等到RTO超时。
TCP Tahoe的实现和RTO超时一样。
TCP Reno的实现是:
cwnd = cwnd / 2    sshthresh = cwnd    进入快速恢复算法-Fast Recovery

===== 快速恢复(Fast Recovery)
TCP Reno, RFC5681
快速重传和快速恢复算法一般同时使用。
快速恢复算法是认为, 还有3个Duplicated Acks说明网络也不那么糟糕, 因此没有必要像RTO超时那么强烈。
注意, 正如前面所说, 进入Fast Recovery之前, cwnd和sshthresh已被更新:
cwnd = cwnd / 2
sshthresh = cwnd
然后, 真正的Fast Recovery算法如下:
cwnd = sshthresh + 3 * MSS (3的意思是确认有3个数据包被收到了)
重传Duplicated ACKs指定的数据包
如果再收到duplicated Acks, 那么cwnd = cwnd + 1
如果收到了新的Ack, 那么cwnd = sshthresh , 然后就进入了拥塞避免的算法了。
这个算法也有问题, 那就是它依赖于3个重复的Acks。注意, 3个重复的Acks并不代表只丢了一个数据包, 很有可能是丢了好多包。但这个算法只会重传一个, 而剩下的那些包只能等到RTO超时, 于是, 进入了恶梦模式: 超时一个窗口就减半一下, 多个超时会超成TCP的传输速度呈级数下降, 而且也不会触发Fast Recovery算法了。

通常来说, 正如我们前面所说的, SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些, 但是并不是所有的TCP的实现都支持SACK(SACK需要两端都支持), 因此, 需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK。

TCP New Reno
于是, 1995年, TCP New Reno(RFC 6582)算法提出来, 主要就是在没有SACK的支持下改进Fast Recovery算法: 当sender这边收到了3个Duplicated Acks, 进入Fast Retransimit模式, 开发重传重复Acks指示的那个包。如果只有这一个包丢了, 那么, 重传这个包后回来的Ack会把整个已经被sender传输出去的数据ack回来。如果没有的话, 说明有多个包丢了。我们叫这个ACK为Partial ACK。
一旦Sender这边发现了Partial ACK出现, 那么, sender就可以推理出来有多个包被丢了, 于是乎继续重传sliding window里未被ack的第一个包。直到再也收不到了Partial Ack, 才真正结束Fast Recovery。这个过程我们可以看到, 这个"Fast Recovery的变更"是一个非常激进的玩法, 其同时延长了Fast Retransmit和Fast Recovery的过程。

===== BBR
▪ Google BBR(Bottleneck Bandwidth and Round-trip propagation time)
谷歌在2016年开发的一种新型的TCP拥塞控制算法
Linux kernel 4.9

主要思想:
经典的拥塞控制算法比如reno/newReno/Cubic无一例外都是将丢包作为拥塞的信号, 然后降低发送速率。而在BBR中, 不考虑丢包, 而是基于这样一个定义: 当网络上的包数大于BDP(带宽时延乘积)时, 就认为出现了拥塞, 因此重点就在于如何准确地测量出瓶颈链路的带宽和整个链路的传播时延。

TCP BBR解决带宽和延迟无法同时测准的方法是:
交替测量带宽和延迟;
用一段时间内的带宽极大值(max bandwidth)和延迟极小值(min RTT)作为估计值。

BBR为什么快:
https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster
在此以前，互联网主要使用基于丢包的拥塞控制策略，只依靠丢失数据包的迹象作为减缓发送速率的信号。这样做的的效果还是不错的，但随着全球化互联网的迅速普及，网络已经发生了巨大的变化。我们拥有了越来越大的带宽，而现在的互联网质量也越来越好。于是我们观察到了一些新的问题，比如影响延迟的缓冲区膨胀的问题。BBR尝试通过使用全新的拥塞控制来解决这个问题，它使用基于延迟而不是丢包作为决定发送速率的主要因素。
使用BBR，可以获得显著的网络吞吐量的提升和延迟的降低。吞吐量的改善在远距离路径上尤为明显，比如跨太平洋的文件或者大数据的传输，尤其是在有轻微丢包的网络条件下。延迟的改善主要体现在最后一公里的路径上，而这一路径经常受到缓冲膨胀(Bufferbloat)的影响。所谓"缓冲膨胀"指的网络设备或者系统不必要地设计了过大的缓冲区。当网络链路拥塞时，就会发生缓冲膨胀，从而导致数据包在这些超大缓冲区中长时间排队。在先进先出队列系统中，过大的缓冲区会导致更长的队列和更高的延迟，并且不会提高网络吞吐量。由于BBR并不会试图填满缓冲区，所以在避免缓冲区膨胀方面往往会有更好的表现。

优点:
网络在没有丢包的情况下，Cubic和BBR对于这些较长时延的链路都有很好的表现。
在中度丢包的情况下，BBR的表现就非常突出了。为什么这一点很重要呢？或者换一个说法，为什么要针对丢包情况而进行优化？
考虑一下这样的场景: 在不同的地方放置有服务器，在系统间有源源不断的数据传输。例如日志文件、数据库同步、业务数据的异地备份等。在复杂的网络环境下，会因为各种原因而出现丢包的情况。在这种场景下，BBR将会有更好的网络传输。
显而易见，BBR对所谓的"长肥网络"(带宽延迟积大、丢包率高的网络)非常有效，在CDN和视频应用等场景下也被证明有很好的表现。事实上，Youtube、Spotify和Dropbox大规模应用BBR已经有了很多的积累。这主要是因为BBR会积极地提升到最佳发送速率，使视频流加载或者文件下载速度更快。

缺点:
首先, 倾向于抢占cubic算法的带宽, 在网络公平性上略显不足
其次, BBR的机制会导致高重传率
再者, 在WIFI环境下用户的网速明显变慢

BBRv2:
解决第一版中存在的主要缺点:
使用聚合/运行中的参数增强了网络建模
增加了对ECN(显示拥塞通知)的支持等

参考: https://aws.amazon.com/cn/blogs/china/talking-about-network-optimization-from-the-flow-control-algorithm/

===== 参考
https://zh.wikipedia.org/zh-hans/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6

=== keepalive
▪ 设置
setsockopt(sock, SOL_SOCKET, SO_KEEPALIVE, (char*)&value, sizeof(long));
setsockopt(sock, SOL_TCP, TCP_KEEPCNT, (char*)&value, sizeof(long));
setsockopt(sock, SOL_TCP, TCP_KEEPIDLE, (char*)&value, sizeof(long));
setsockopt(sock, SOL_TCP, TCP_KEEPINTVL, (char*)&value, sizeof(long));

▪ TCP与Keep-Alive
TCP协议的实现中，提供了KeepAlive报文，用来探测连接的对端是否存活。在应用交互的过程中，可能存在以下几种情况:
客户端或服务器意外断电，死机，崩溃，重启;
中间网络已经中断，而客户端与服务器并不知道;
利用保活探测功能，可以探知这种对端的意外情况，从而保证在意外发生时，可以释放半打开的TCP连接。

▪ 应用层心跳保活
虽然TCP提供了KeepAlive机制，但是并不能替代应用层心跳保活。原因主要如下:
(1) Keep Alive机制开启后，TCP层将在定时时间到后发送相应的KeepAlive探针以确定连接可用性。默认时间为7200s(两小时)，失败后重试10次，每次超时时间75s。显然默认值无法满足移动网络下的需求;
tips: sudo sysctl -a | grep keepalive
// net.ipv4.tcp_keepalive_time = 7200 每隔7200s检测一次
// net.ipv4.tcp_keepalive_probes = 9 一次最多重传9个包
// net.ipv4.tcp_keepalive_intvl = 75 每个包的间隔重传间隔75s
(2) 即便修改了(1)中的默认值，也不能很好的满足业务需求。TCP的KeepAlive用于检测连接的死活而不能检测通讯双方的存活状态。比如某台服务器因为某些原因导致负载超高，无法响应任何业务请求，但是使用TCP探针则仍旧能够确定连接状态，这就是典型的连接活着但业务提供方已死的状态，对客户端而言，这时的最好选择就是断线后重新连接其他服务器，而不是一直认为当前服务器是可用状态，一直向当前服务器发送些必然会失败的请求。
(3) socks代理会让Keep Alive失效。socks协议只管转发TCP层具体的数据包，而不会转发TCP协议内的实现细节的包。因此，一个应用如果使用了socks代理，那么TCP的KeepAlive机制就失效了。
(4) 部分复杂情况下Keep Alive会失效，如路由器挂掉，网线直接被拔除等
因此，KeepAlive并不适用于检测双方存活的场景，这种场景还得依赖于应用层的心跳。
应用层心跳也具备着更大的灵活性，可以控制检测时机，间隔和处理流程，甚至可以在心跳包上附带额外信息。

▪ HTTP与Keep-Alive
实现HTTP/1.0 keep-alive连接的客户端可以通过包含Connection:Keep-Alive首部请求将一条连接保持在打开状态，如果服务器愿意为下一条请求将连接保持在打开状态，就在响应中包含相同的首部。如果响应中没有Connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。HTTP/1.1以后Keep-Alive是默认打开的。

Q: 应用层心跳是客户端主动发送, 还是服务器主动发送呢? 
A: 通常由客户端主动发起，https://www.zhihu.com/question/35896874
通常做法:
1 客户端每隔一个时间间隔发生一个探测包给服务器，同时启动一个超时定时器
2 服务器端接收到检测包，返回一个应答包，同时也会启动一个超时定时器
3 如果客户机:
3.1 正常收到服务器的应答包，说明正常，删除超时定时器，继续步骤1
3.2 接收服务器的应答包超时，说明出问题了，通常需要销毁连接
4 如果服务器:
4.1 正常收到客户端的探测包，则说明正常，重新启动超时定时器 
4.2 接受客户端的探测包超时，也说明出问题了，通常需要销毁连接

=== 参考
https://en.wikipedia.org/wiki/Transmission_Control_Protocol
https://www.rfc-editor.org/rfc/rfc9293
https://www.kernel.org/doc/html/latest/networking/ip-sysctl.html
https://www.kernel.org/doc/html/latest/networking/ip-sysctl.html#tcp-variables