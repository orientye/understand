:toc:
:toclevels: 5
:hardbreaks-option:

== API

=== socket setsockopt/getsockopt
man socket
https://linux.die.net/man/7/tcp
https://linux.die.net/man/7/udp

=== bind
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);

bind之前一般都会setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, …)

SO_REUSEADDR vs. SO_REUSEPORT
https://stackoverflow.com/questions/14388706/how-do-so-reuseaddr-and-so-reuseport-differ

=== listen
int listen(int sockfd, int backlog);

server建立连接会维护两个队列:
一个存放SYN的队列(即半连接队列) - 对应SYN_REVD状态(pending socket queue)
一个存放完成连接的队列(即全连接队列) - 对应ESTABELLISHED状态(established socket queue)

全连接队列长度 = min(backlog, 内核参数net.core.somaxconn(默认为128));
半连接队列长度 = min(backlog, 内核参数net.core.somaxconn, 内核参数tcp_max_syn_backlog)
当使用SYNCookie时(即内核参数 net.ipv4.tcp_syncookies=1), tcp_max_syn_backlog无效

example:

    Redis:  #define CONFIG_DEFAULT_TCP_BACKLOG       511    /* TCP listen backlog. */
    LibUV: 大部分是128
    Nginx: #define NGX_LISTEN_BACKLOG  -1

=== accept
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags);

非阻塞accept:
    If the socket is marked nonblocking and no pending connections are present on the queue, accept() fails with the error EAGAIN or EWOULDBLOCK

https://stackoverflow.com/questions/7003234/which-systems-define-eagain-and-ewouldblock-as-different-values

accept惊群

example:

redis:
[source,c]
.https://github.com/redis/redis/blob/unstable/src/socket.c
----
static void connSocketAcceptHandler(aeEventLoop *el, int fd, void *privdata, int mask) {
    int cport, cfd, max = MAX_ACCEPTS_PER_CALL;
    char cip[NET_IP_STR_LEN];
    UNUSED(el);
    UNUSED(mask);
    UNUSED(privdata);

    while(max--) {
        cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), &cport);
        if (cfd == ANET_ERR) {
            if (errno != EWOULDBLOCK)
                serverLog(LL_WARNING,
                    "Accepting client connection: %s", server.neterr);
            return;
        }
        serverLog(LL_VERBOSE,"Accepted %s:%d", cip, cport);
        acceptCommonHandler(connCreateAcceptedSocket(cfd, NULL),0,cip);
    }
}
----

nginx:
[source,c]
.https://github.com/nginx/nginx/blob/master/src/event/ngx_event_accept.c
----
void
ngx_event_accept(ngx_event_t *ev)
{
    //...
#if (NGX_HAVE_ACCEPT4)
        if (use_accept4) {
            s = accept4(lc->fd, &sa.sockaddr, &socklen, SOCK_NONBLOCK);
        } else {
            s = accept(lc->fd, &sa.sockaddr, &socklen);
        }
#else
        s = accept(lc->fd, &sa.sockaddr, &socklen);
#endif

        if (s == (ngx_socket_t) -1) {
            err = ngx_socket_errno;

            if (err == NGX_EAGAIN) {
                ngx_log_debug0(NGX_LOG_DEBUG_EVENT, ev->log, err,
                               "accept() not ready");
                return;
            }
            //...
        }
    //...
}
----

=== getaddrinfo

问题: getaddrinfo_a

example:

    libuv

=== connect

int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 

非阻塞Connect：

linux:  EINPROGRESS

The socket is non-blocking and the connection cannot be completed immediately.  It is possible to select(2) or poll(2) for completion by  selecting the  socket  for  writing.   After  select(2) indicates writability, use getsockopt(2) to read the SO_ERROR option at level 
SOL_SOCKET to determine whether connect() completed successfully (SO_ERROR is zero) or unsuccessfully (SO_ERROR is one of the usual error codes listed here, explaining the reason for the failure).

其它类型的失败需要close socket

example:
redis:
[source,c]
----
    if (connect(s,(struct sockaddr*)&sa,sizeof(sa)) == -1) {                                                                                                                     
            if (errno == EINPROGRESS &&
    390             flags & ANET_CONNECT_NONBLOCK)
    391             return s;
    392 
    393         anetSetError(err, "connect: %s", strerror(errno));
    394         close(s);
    395         return ANET_ERR;
    396     }
----
nginx: core/ngx_resolver.c/ngx_tcp_connect

UDP:
https://stackoverflow.com/questions/6189831/whats-the-purpose-of-using-sendto-recvfrom-instead-of-connect-send-recv

=== send
write/writev/send/sendto/sendmsg

    ssize_t write(int fd, const void *buf, size_t count);
    ssize_t writev(int fd, const struct iovec *iov, int iovcnt);
    ssize_t send(int sockfd, const void *buf, size_t len, int flags);
    ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen);
    ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);

阻塞/非阻塞

    send实质上仅仅是把数据放入发送缓冲区而已。
    阻塞和非阻塞区别在于是否等待发送缓冲区腾出足够的空间。

Q: 阻塞下的write/read表现

Q: why sendmsg/recvmsg

    A few things recvmsg and sendmsg can do:
    You can do scatter/gather buffers. For example, let's day you want to receive exactly 1MB of data, but you only have 10 buffers that are each 100KB, then you can fill up each in a single recvmsg call.
    Access to Control flags, ancillary data, and IP packet header fields. For example, for UDP, you can get the destination IP/port address that the packet was addressed by enumerating the control data (with certain ioctls enabled) returned from recvmsg.

example:

    redis: networking.c/writeToClient
    nginx: src/os/unix/ngx_unix_send

SIGPIPE一般为什么要忽略

    A SIGPIPE is sent to a process if it tried to write to a socket that had been shutdown for writing or isn't connected (anymore).
    UNNP 5.13：When a process writes to a socket that has received an RST, the SIGPIPE signal is sent to the process

=== recv
read/readv/recv/recvfrom/recvmsg 

    ssize_t read(int fd, void *buf, size_t count);
    ssize_t readv(int fd, const struct iovec *iov, int iovcnt);
    ssize_t recv(int sockfd, void *buf, size_t len, int flags);
    ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
    ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);

阻塞/非阻塞

example:

redis:networking.c/readQueryFromClient
[source,c]
----
    if (nread == -1) {
        if (errno == EAGAIN) {
            return;
        } else {
            serverLog(LL_VERBOSE, "Reading from client: %s",strerror(errno));
            freeClient(c);
            return;
        }
    } else if (nread == 0) {
        serverLog(LL_VERBOSE, "Client closed connection");
        freeClient(c);
        return;
    } else
----
nginx:os/unix/ngx_send.c/ngx_recv.c

=== blocking
https://stackoverflow.com/questions/5407182/blocking-sockets-when-exactly-does-send-return

=== close
int close(int fd); 

https://github.com/torvalds/linux/blob/master/net/ipv4/tcp.c  tcp_close

Q: close之前本端发送的数据, 能成功发送出去吗？
Q: close之后本端能发送数据吗？对端呢？
Q: close之后本端能接受数据吗？对端呢？

异常释放

    但也有可能发送一个复位报文段而不是FIN来释放一个连接, 这成为异常释放(ahortive release)。
    异常终止一个连接对应用程序来说有两个优点:
    (1)丢弃任何待发数据并立即发送复位报文段;
    (2)RST的接收方会区分另一端执行的是异常关闭还是正常关闭。
    应用程序使用的API必须提供产生异常关闭而不是正常关闭的手段。
    SocketAPI通过lingeronclose选项(SO_LINGER)提供了这种异常关闭的能力: 停留时间设为0。

SO_LINGER

    struct linger{
        int l_onoff;
        int l_linger;
    };
    注意: 需要考虑平台(以及阻塞/非阻塞?)
    l_onoff = 0
    l_onoff != 0, l_linger = 0
    l_onoff !=0, l_linger > 0

https://github.com/torvalds/linux/blob/master/net/ipv4/tcp.c

[source,c]
----
    void tcp_close(struct sock *sk, long timeout)	

        } else if (sock_flag(sk, SOCK_LINGER) && !sk->sk_lingertime) {
            /* Check zero linger _after_ checking for unread data. */
            sk->sk_prot->disconnect(sk, 0);
            NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
----

https://github.com/torvalds/linux/blob/master/net/ipv4/af_inet.c

[source,c]
----
int inet_release(struct socket *sock)
    /* If linger is set, we don't return until the close
        * is complete.  Otherwise we return immediately. The
        * actually closing is done the same either way.
        *
        * If the close is due to the process exiting, we never
        * linger..
        */
    timeout = 0;
    if (sock_flag(sk, SOCK_LINGER) &&
        !(current->flags & PF_EXITING))
        timeout = sk->sk_lingertime;
    sk->sk_prot->close(sk, timeout);
    sock->sk = NULL;
----

▪ vs. shutdown：
close-----关闭本进程的socket id, 但链接还是开着的, 用这个socket id的其它进程还能用这个链接, 能读或写这个socket id。
shutdown--破坏了socket 链接, 读的时候可能侦探到EOF结束符, 写的时候可能会收到一个SIGPIPE信号, 这个信号可能直到socket buffer 被填充了才收到, shutdown有一个关闭方式的参数, 0不能再读, 1不能再写, 2读写都不能。

▪ socket多进程中的shutdown、close的使用
　　当所有的数据操作结束以后, 可以调用close()函数来释放该socket, 从而停止在该socket上的任何数据操作：close(sockfd);使用close中止一个连接, 但它只是减少描述符的参考数, 并不直接关闭连接, 只有当描述符的参考数为0时才关闭连接。所以在多进程/线程程序中, close只是确保了对于某个特定的进程或线程来说, 该连接是关闭的。使用client_fd = accept()后fork()以在子进程中处理请求, 此时在父进程中使用close()关闭该连接, 子进程仍可以继续使用该连接。

　　也可以调用shutdown()函数来关闭该socket。该函数允许你只停止在某个方向上的数据传输, 而一个方向上的数据传输继续进行。如你可以关闭某socket的写操作而允许继续在该socket上接受数据, 直至读入所有数据。int shutdown(int sockfd,int how);shutdown可直接关闭描述符, 不考虑描述符的参考数, 可选择中止一个方向的连接。

▪ 注意
　　1.如果有多个进程共享一个套接字, close每被调用一次, 计数减1, 直到计数为0时, 也就是所用进程都调用了close, 套接字将被释放。
　　2.在多进程中如果一个进程中shutdown(sfd, SHUT_RDWR)后其它的进程将无法进行通信。如果一个进程close(sfd)将不会影响到其它进程, 得自己理解引用计数的用法了。

▪ 更多关于close和shutdown的说明
　　1.只要TCP栈的读缓冲里还有未读取(read)数据, 则调用close时会直接向对端发送RST。
　　2.shutdown与socket描述符没有关系, 即使调用shutdown(fd, SHUT_RDWR)也不会关闭fd, 最终还需close(fd)。
　　3.可以认为shutdown(fd, SHUT_RD)是空操作, 因为shutdown后还可以继续从该socket读取数据, 这点也许还需要进一步证实。在已发送FIN包后write该socket描述符会引发EPIPE/SIGPIPE。
　　4.当有多个socket描述符指向同一socket对象时, 调用close时首先会递减该对象的引用计数, 计数为0时才会发送FIN包结束TCP连接。shutdown不同, 只要以SHUT_WR/SHUT_RDWR方式调用即发送FIN包。
　　5.SO_LINGER与close, 当SO_LINGER选项开启但超时值为0时, 调用close直接发送RST(这样可以避免进入TIME_WAIT状态, 但破坏了TCP协议的正常工作方式), SO_LINGER对shutdown无影响。
　　6.TCP连接上出现RST与随后可能的TIME_WAIT状态没有直接关系, 主动发FIN包方必然会进入TIME_WAIT状态, 除非不发送FIN而直接以发送RST结束连接。

参考: https://blog.codingnow.com/2021/02/skynet_tcp_halfclose.html

=== shutdown
int shutdown(int sockfd, int how); 
     
     how-The constants SHUT_RD, SHUT_WR, SHUT_RDWR have the value 0, 1, 2

场景:
1.当你想要确保所有写好的数据已经发送成功时。如果在发送数据的过程中, 网络意外断开或者出现异常, 系统不一定会返回异常, 这是你可能以为对端已经接收到数据了。这时需要用shutdown()来确定数据是否发送成功, 因为调用shutdown()时只有在缓存中的数据全部发送成功后才会返回。
2.想用一种方法来捕获程序潜在的错误, 这错误可能是因为往一个不能写的socket上写数据, 也有可能是在一个不该读操作的socket上读数据。当程序尝试这样做时, 将会捕获到一个异常, 捕获异常对于程序排错来说是相对简单和省劲的。
3.当您的程序使用了fork()或者使用多线程时, 你想防止其他线程或进程访问到该资源, 又或者你想立刻关闭这个socket, 那么可以用shutdown()来实现。

example:
redis:
[source,c]
----
    927         /* In the case of diskless replication the fork is writing to the
    928          * sockets and just closing the fd isn't enough, if we don't also
    929          * shutdown the socket the fork will continue to write to the slave
    930          * and the salve will only find out that it was disconnected when
    931          * it will finish reading the rdb. */
    932         if ((c->flags & CLIENT_SLAVE) &&
    933             (c->replstate == SLAVE_STATE_WAIT_BGSAVE_END)) {
    934             shutdown(c->fd, SHUT_RDWR);
    935         }
----

=== select/poll
- select
- poll 
- 场景: 跨平台, 对效率要求不高的场景

pselect vs select:
    
    超时精度
        select使用的是struct timeval结构体，精确到微秒
        pselect使用的是struct timespec结构体，精确到纳秒
    超时参数
        select可能会更新其超时参数timeout
        pselect6系统调用可能会更新其超时参数，glibc的封装pselect不会更新其超时参数
    信号掩码
        pselect可以设置信号掩码，若其为NULL，则行为与select相同

ppoll vs poll:

    超时精度
        poll使用的超时精度为毫秒
        ppoll使用的是struct timespec结构体，精确到纳秒
    信号掩码
        ppoll可以设置信号掩码，若其为NULL，则行为与poll相同

=== epoll/kqueue/evport
- epoll_create/epollcreate1
- epoll_ctrl
- epoll_wait
- LT/ET

- example:
Redis/src/ae_poll.c
[source,c]
----
    if (e->events & EPOLLIN) mask |= AE_READABLE;
    if (e->events & EPOLLOUT) mask |= AE_WRITABLE;
    if (e->events & EPOLLERR) mask |= AE_WRITABLE|AE_READABLE;
    if (e->events & EPOLLHUP) mask |= AE_WRITABLE|AE_READABLE;
----

Q: why EPOLLOUT

- epoll惊群
EPOLLEXCLUSIVE(since Linux 4.5): https://man7.org/linux/man-pages/man2/epoll_ctl.2.html
参考: https://zhuanlan.zhihu.com/p/359774959

=== iocp

=== io_uring